2022-06-22 20:18:09.672697: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 20:18:09.674145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-22 20:18:09.708455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 20:18:09.708926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 20:18:09.708960: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 20:18:09.711790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 20:18:09.711861: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 20:18:09.714497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 20:18:09.715063: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 20:18:09.717340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 20:18:09.718587: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 20:18:09.722996: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 20:18:09.724101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 20:18:09.724513: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-22 20:18:09.724601: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 20:18:09.899227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 20:18:09.899471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 20:18:09.899493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 20:18:09.899517: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 20:18:09.899526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 20:18:09.899536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 20:18:09.899547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 20:18:09.899556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 20:18:09.899565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 20:18:09.899574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 20:18:09.900252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 20:18:09.900279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 20:18:10.675525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-22 20:18:10.675568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-22 20:18:10.675581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-22 20:18:10.675586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-22 20:18:10.676586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-22 20:18:10.677640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-22 20:18:10.920324: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-22 20:18:10.920790: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-22 20:18:11.509834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 20:18:11.706688: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 20:18:12.306110: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-22 20:18:12.343247: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 16)      448
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 16)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 16)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 32)      4640
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 16)      4624
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 16)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 16)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 32)        4640
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 32)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 32)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 32)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 132
=================================================================
Total params: 14,484
Trainable params: 14,484
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100







280/280 [==============================] - 22s 57ms/step - loss: 1.4027 - accuracy: 0.2440 - val_loss: 1.3789 - val_accuracy: 0.2727
Epoch 2/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3857 - accuracy: 0.2640 - val_loss: 1.3693 - val_accuracy: 0.2727
Epoch 3/100






280/280 [==============================] - 16s 56ms/step - loss: 1.3810 - accuracy: 0.2873 - val_loss: 1.3698 - val_accuracy: 0.3333
Epoch 4/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3797 - accuracy: 0.2632 - val_loss: 1.3725 - val_accuracy: 0.2727
Epoch 5/100






280/280 [==============================] - 16s 57ms/step - loss: 1.3868 - accuracy: 0.2391 - val_loss: 1.3702 - val_accuracy: 0.2727
Epoch 6/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3819 - accuracy: 0.2744 - val_loss: 1.3693 - val_accuracy: 0.2727
Epoch 7/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3869 - accuracy: 0.2585 - val_loss: 1.3736 - val_accuracy: 0.2727
Epoch 8/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3834 - accuracy: 0.2645 - val_loss: 1.3711 - val_accuracy: 0.2727
Epoch 9/100






280/280 [==============================] - 16s 56ms/step - loss: 1.3804 - accuracy: 0.2873 - val_loss: 1.3766 - val_accuracy: 0.2727
Epoch 10/100








280/280 [==============================] - 16s 56ms/step - loss: 1.3832 - accuracy: 0.2812 - val_loss: 1.3700 - val_accuracy: 0.2727
Epoch 11/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3803 - accuracy: 0.2773 - val_loss: 1.3753 - val_accuracy: 0.2727
Epoch 12/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3847 - accuracy: 0.2776 - val_loss: 1.3741 - val_accuracy: 0.2727
Epoch 13/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3848 - accuracy: 0.2709 - val_loss: 1.3747 - val_accuracy: 0.2727
Epoch 14/100







280/280 [==============================] - 15s 55ms/step - loss: 1.3768 - accuracy: 0.3144 - val_loss: 1.3690 - val_accuracy: 0.2727
Epoch 15/100






280/280 [==============================] - 15s 54ms/step - loss: 1.3842 - accuracy: 0.2660 - val_loss: 1.3700 - val_accuracy: 0.2727
Epoch 16/100






280/280 [==============================] - 16s 56ms/step - loss: 1.3862 - accuracy: 0.2759 - val_loss: 1.3718 - val_accuracy: 0.2727
Epoch 17/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3795 - accuracy: 0.3026 - val_loss: 1.3715 - val_accuracy: 0.2727
Epoch 18/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3839 - accuracy: 0.3008 - val_loss: 1.3725 - val_accuracy: 0.3333
Epoch 19/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3838 - accuracy: 0.2714 - val_loss: 1.3745 - val_accuracy: 0.2727
Epoch 20/100






280/280 [==============================] - 16s 55ms/step - loss: 1.3848 - accuracy: 0.2571 - val_loss: 1.3781 - val_accuracy: 0.2727
Epoch 21/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3844 - accuracy: 0.2720 - val_loss: 1.3763 - val_accuracy: 0.2727
Epoch 22/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3835 - accuracy: 0.2861 - val_loss: 1.3695 - val_accuracy: 0.2727
Epoch 23/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3820 - accuracy: 0.2916 - val_loss: 1.3738 - val_accuracy: 0.2727
Epoch 24/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3839 - accuracy: 0.2703 - val_loss: 1.3746 - val_accuracy: 0.2727
Epoch 25/100






280/280 [==============================] - 16s 56ms/step - loss: 1.3751 - accuracy: 0.2919 - val_loss: 1.3806 - val_accuracy: 0.2727
Epoch 26/100






280/280 [==============================] - 15s 54ms/step - loss: 1.3883 - accuracy: 0.2473 - val_loss: 1.3769 - val_accuracy: 0.2727
Epoch 27/100







280/280 [==============================] - 16s 56ms/step - loss: 1.3831 - accuracy: 0.2864 - val_loss: 1.3693 - val_accuracy: 0.2727
Epoch 28/100






280/280 [==============================] - 16s 55ms/step - loss: 1.3846 - accuracy: 0.2432 - val_loss: 1.3824 - val_accuracy: 0.2727
Epoch 29/100






280/280 [==============================] - 15s 55ms/step - loss: 1.3780 - accuracy: 0.2952 - val_loss: 1.3700 - val_accuracy: 0.2727
Epoch 30/100
 89/280 [========>.....................] - ETA: 8s - loss: 1.4003 - accuracy: 0.2463
134/280 [=============>................] - ETA: 6s - loss: 1.3970 - accuracy: 0.2506
179/280 [==================>...........] - ETA: 4s - loss: 1.3948 - accuracy: 0.2537
221/280 [======================>.......] - ETA: 2s - loss: 1.3931 - accuracy: 0.2566
263/280 [===========================>..] - ETA: 0s - loss: 1.3914 - accuracy: 0.2600
279/280 [============================>.] - ETA: 0s - loss: 1.3909 - accuracy: 0.2613
  8/280 [..............................] - ETA: 13s - loss: 1.3414 - accuracy: 0.3329.2615 - val_loss: 1.3709 - val_accuracy: 0.2727
 55/280 [====>.........................] - ETA: 9s - loss: 1.3671 - accuracy: 0.2950 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
101/280 [=========>....................] - ETA: 7s - loss: 1.3726 - accuracy: 0.2917 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
148/280 [==============>...............] - ETA: 5s - loss: 1.3757 - accuracy: 0.2910 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
192/280 [===================>..........] - ETA: 3s - loss: 1.3775 - accuracy: 0.2905 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
237/280 [========================>.....] - ETA: 1s - loss: 1.3786 - accuracy: 0.2897 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3791 - accuracy: 0.2898 .2615 - val_loss: 1.3709 - val_accuracy: 0.2727
 28/280 [==>...........................] - ETA: 10s - loss: 1.3626 - accuracy: 0.3236.2897 - val_loss: 1.3682 - val_accuracy: 0.2727
 74/280 [======>.......................] - ETA: 8s - loss: 1.3740 - accuracy: 0.3113 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
121/280 [===========>..................] - ETA: 6s - loss: 1.3775 - accuracy: 0.3047 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
163/280 [================>.............] - ETA: 5s - loss: 1.3785 - accuracy: 0.3027 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
205/280 [====================>.........] - ETA: 3s - loss: 1.3798 - accuracy: 0.2996 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
248/280 [=========================>....] - ETA: 1s - loss: 1.3807 - accuracy: 0.2975 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3810 - accuracy: 0.2962 .2897 - val_loss: 1.3682 - val_accuracy: 0.2727
 39/280 [===>..........................] - ETA: 10s - loss: 1.3833 - accuracy: 0.2333.2961 - val_loss: 1.3674 - val_accuracy: 0.3333
 86/280 [========>.....................] - ETA: 8s - loss: 1.3799 - accuracy: 0.2636 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
128/280 [============>.................] - ETA: 6s - loss: 1.3793 - accuracy: 0.2743 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
173/280 [=================>............] - ETA: 4s - loss: 1.3799 - accuracy: 0.2776 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
217/280 [======================>.......] - ETA: 2s - loss: 1.3807 - accuracy: 0.2782 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
262/280 [===========================>..] - ETA: 0s - loss: 1.3810 - accuracy: 0.2798 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
279/280 [============================>.] - ETA: 0s - loss: 1.3811 - accuracy: 0.2799 .2961 - val_loss: 1.3674 - val_accuracy: 0.3333
  7/280 [..............................] - ETA: 11s - loss: 1.3616 - accuracy: 0.3969.2799 - val_loss: 1.3721 - val_accuracy: 0.2727
 52/280 [====>.........................] - ETA: 10s - loss: 1.3737 - accuracy: 0.3717.2799 - val_loss: 1.3721 - val_accuracy: 0.2727
 93/280 [========>.....................] - ETA: 8s - loss: 1.3772 - accuracy: 0.3395 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
136/280 [=============>................] - ETA: 6s - loss: 1.3774 - accuracy: 0.3267 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
169/280 [=================>............] - ETA: 5s - loss: 1.3774 - accuracy: 0.3190 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
216/280 [======================>.......] - ETA: 2s - loss: 1.3776 - accuracy: 0.3127 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
261/280 [==========================>...] - ETA: 0s - loss: 1.3783 - accuracy: 0.3077 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3786 - accuracy: 0.3060 .2799 - val_loss: 1.3721 - val_accuracy: 0.2727
  8/280 [..............................] - ETA: 12s - loss: 1.3561 - accuracy: 0.2503.3059 - val_loss: 1.3793 - val_accuracy: 0.2727
 53/280 [====>.........................] - ETA: 10s - loss: 1.3712 - accuracy: 0.2507.3059 - val_loss: 1.3793 - val_accuracy: 0.2727
 98/280 [=========>....................] - ETA: 8s - loss: 1.3777 - accuracy: 0.2447 .3059 - val_loss: 1.3793 - val_accuracy: 0.2727
144/280 [==============>...............] - ETA: 6s - loss: 1.3805 - accuracy: 0.2433 .3059 - val_loss: 1.3793 - val_accuracy: 0.2727
191/280 [===================>..........] - ETA: 3s - loss: 1.3818 - accuracy: 0.2452 .3059 - val_loss: 1.3793 - val_accuracy: 0.2727
235/280 [========================>.....] - ETA: 2s - loss: 1.3822 - accuracy: 0.2484 .3059 - val_loss: 1.3793 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3824 - accuracy: 0.2519 .3059 - val_loss: 1.3793 - val_accuracy: 0.2727
 22/280 [=>............................] - ETA: 12s - loss: 1.4130 - accuracy: 0.1859.2521 - val_loss: 1.3782 - val_accuracy: 0.2727
 66/280 [======>.......................] - ETA: 10s - loss: 1.3985 - accuracy: 0.2253.2521 - val_loss: 1.3782 - val_accuracy: 0.2727
110/280 [==========>...................] - ETA: 7s - loss: 1.3947 - accuracy: 0.2400 .2521 - val_loss: 1.3782 - val_accuracy: 0.2727
154/280 [===============>..............] - ETA: 5s - loss: 1.3926 - accuracy: 0.2449 .2521 - val_loss: 1.3782 - val_accuracy: 0.2727
198/280 [====================>.........] - ETA: 3s - loss: 1.3910 - accuracy: 0.2505 .2521 - val_loss: 1.3782 - val_accuracy: 0.2727
243/280 [=========================>....] - ETA: 1s - loss: 1.3898 - accuracy: 0.2547 .2521 - val_loss: 1.3782 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3887 - accuracy: 0.2578 .2521 - val_loss: 1.3782 - val_accuracy: 0.2727
 34/280 [==>...........................] - ETA: 10s - loss: 1.3999 - accuracy: 0.2432.2580 - val_loss: 1.3646 - val_accuracy: 0.2727
 79/280 [=======>......................] - ETA: 9s - loss: 1.3953 - accuracy: 0.2604 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
126/280 [============>.................] - ETA: 6s - loss: 1.3930 - accuracy: 0.2640 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
171/280 [=================>............] - ETA: 4s - loss: 1.3911 - accuracy: 0.2670 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
216/280 [======================>.......] - ETA: 2s - loss: 1.3895 - accuracy: 0.2715 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
259/280 [==========================>...] - ETA: 0s - loss: 1.3878 - accuracy: 0.2754 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3873 - accuracy: 0.2763 .2580 - val_loss: 1.3646 - val_accuracy: 0.2727
 41/280 [===>..........................] - ETA: 11s - loss: 1.3842 - accuracy: 0.2730.2764 - val_loss: 1.3678 - val_accuracy: 0.2727
 88/280 [========>.....................] - ETA: 8s - loss: 1.3786 - accuracy: 0.2806 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
132/280 [=============>................] - ETA: 6s - loss: 1.3800 - accuracy: 0.2794 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
177/280 [=================>............] - ETA: 4s - loss: 1.3808 - accuracy: 0.2795 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
221/280 [======================>.......] - ETA: 2s - loss: 1.3813 - accuracy: 0.2790 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
266/280 [===========================>..] - ETA: 0s - loss: 1.3817 - accuracy: 0.2770 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3818 - accuracy: 0.2762 .2764 - val_loss: 1.3678 - val_accuracy: 0.2727
 12/280 [>.............................] - ETA: 12s - loss: 1.3714 - accuracy: 0.2391.2761 - val_loss: 1.3734 - val_accuracy: 0.2727
 57/280 [=====>........................] - ETA: 10s - loss: 1.3735 - accuracy: 0.2589.2761 - val_loss: 1.3734 - val_accuracy: 0.2727
104/280 [==========>...................] - ETA: 7s - loss: 1.3777 - accuracy: 0.2618 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
149/280 [==============>...............] - ETA: 5s - loss: 1.3796 - accuracy: 0.2657 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
189/280 [===================>..........] - ETA: 4s - loss: 1.3802 - accuracy: 0.2687 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
232/280 [=======================>......] - ETA: 2s - loss: 1.3803 - accuracy: 0.2727 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
276/280 [============================>.] - ETA: 0s - loss: 1.3807 - accuracy: 0.2749 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3807 - accuracy: 0.2750 .2761 - val_loss: 1.3734 - val_accuracy: 0.2727
 19/280 [=>............................] - ETA: 12s - loss: 1.3916 - accuracy: 0.1407    1 - val_loss: 1.3709 - val_accuracy: 0.2727
 64/280 [=====>........................] - ETA: 9s - loss: 1.3929 - accuracy: 0.1553     1 - val_loss: 1.3709 - val_accuracy: 0.2727
109/280 [==========>...................] - ETA: 7s - loss: 1.3899 - accuracy: 0.1831     1 - val_loss: 1.3709 - val_accuracy: 0.2727
152/280 [===============>..............] - ETA: 5s - loss: 1.3890 - accuracy: 0.2004     1 - val_loss: 1.3709 - val_accuracy: 0.2727
187/280 [===================>..........] - ETA: 4s - loss: 1.3881 - accuracy: 0.2109     1 - val_loss: 1.3709 - val_accuracy: 0.2727
231/280 [=======================>......] - ETA: 2s - loss: 1.3867 - accuracy: 0.2219     1 - val_loss: 1.3709 - val_accuracy: 0.2727
275/280 [============================>.] - ETA: 0s - loss: 1.3860 - accuracy: 0.2297     1 - val_loss: 1.3709 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.2304     1 - val_loss: 1.3709 - val_accuracy: 0.2727
 19/280 [=>............................] - ETA: 12s - loss: 1.3617 - accuracy: 0.2981.2306 - val_loss: 1.3729 - val_accuracy: 0.2727
 64/280 [=====>........................] - ETA: 9s - loss: 1.3704 - accuracy: 0.3083 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
107/280 [==========>...................] - ETA: 8s - loss: 1.3746 - accuracy: 0.3037 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
149/280 [==============>...............] - ETA: 6s - loss: 1.3769 - accuracy: 0.3005 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
194/280 [===================>..........] - ETA: 3s - loss: 1.3779 - accuracy: 0.2986 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
238/280 [========================>.....] - ETA: 1s - loss: 1.3786 - accuracy: 0.2971 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3792 - accuracy: 0.2955 .2306 - val_loss: 1.3729 - val_accuracy: 0.2727
 29/280 [==>...........................] - ETA: 11s - loss: 1.3720 - accuracy: 0.3455.2954 - val_loss: 1.3705 - val_accuracy: 0.2727
 76/280 [=======>......................] - ETA: 9s - loss: 1.3767 - accuracy: 0.3199 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
122/280 [============>.................] - ETA: 6s - loss: 1.3808 - accuracy: 0.3020 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
166/280 [================>.............] - ETA: 5s - loss: 1.3820 - accuracy: 0.2969 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
211/280 [=====================>........] - ETA: 3s - loss: 1.3825 - accuracy: 0.2932 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
254/280 [==========================>...] - ETA: 1s - loss: 1.3824 - accuracy: 0.2913 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3824 - accuracy: 0.2909 .2954 - val_loss: 1.3705 - val_accuracy: 0.2727
  1/280 [..............................] - ETA: 19s - loss: 1.4558 - accuracy: 0.2500.2909 - val_loss: 1.3762 - val_accuracy: 0.2727
 44/280 [===>..........................] - ETA: 11s - loss: 1.3965 - accuracy: 0.2695.2909 - val_loss: 1.3762 - val_accuracy: 0.2727
 89/280 [========>.....................] - ETA: 8s - loss: 1.3908 - accuracy: 0.2787 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
130/280 [============>.................] - ETA: 7s - loss: 1.3892 - accuracy: 0.2818 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
174/280 [=================>............] - ETA: 4s - loss: 1.3881 - accuracy: 0.2837 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
217/280 [======================>.......] - ETA: 2s - loss: 1.3874 - accuracy: 0.2829 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
263/280 [===========================>..] - ETA: 0s - loss: 1.3867 - accuracy: 0.2814 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3864 - accuracy: 0.2813 .2909 - val_loss: 1.3762 - val_accuracy: 0.2727
  7/280 [..............................] - ETA: 13s - loss: 1.3768 - accuracy: 0.2968.2813 - val_loss: 1.3735 - val_accuracy: 0.2727
 52/280 [====>.........................] - ETA: 10s - loss: 1.3652 - accuracy: 0.3044.2813 - val_loss: 1.3735 - val_accuracy: 0.2727
 97/280 [=========>....................] - ETA: 8s - loss: 1.3699 - accuracy: 0.3020 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
140/280 [==============>...............] - ETA: 6s - loss: 1.3737 - accuracy: 0.2980 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
185/280 [==================>...........] - ETA: 4s - loss: 1.3765 - accuracy: 0.2914 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
230/280 [=======================>......] - ETA: 2s - loss: 1.3777 - accuracy: 0.2870 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
274/280 [============================>.] - ETA: 0s - loss: 1.3785 - accuracy: 0.2842 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3786 - accuracy: 0.2840 .2813 - val_loss: 1.3735 - val_accuracy: 0.2727
 17/280 [>.............................] - ETA: 11s - loss: 1.4126 - accuracy: 0.2498.2839 - val_loss: 1.3745 - val_accuracy: 0.2727
 62/280 [=====>........................] - ETA: 9s - loss: 1.3887 - accuracy: 0.2834 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
107/280 [==========>...................] - ETA: 7s - loss: 1.3830 - accuracy: 0.2850 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
153/280 [===============>..............] - ETA: 5s - loss: 1.3812 - accuracy: 0.2900 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
198/280 [====================>.........] - ETA: 3s - loss: 1.3807 - accuracy: 0.2924 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
243/280 [=========================>....] - ETA: 1s - loss: 1.3809 - accuracy: 0.2921 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3812 - accuracy: 0.2914 .2839 - val_loss: 1.3745 - val_accuracy: 0.2727
 34/280 [==>...........................] - ETA: 11s - loss: 1.3907 - accuracy: 0.2996.2914 - val_loss: 1.3710 - val_accuracy: 0.2727
 82/280 [=======>......................] - ETA: 8s - loss: 1.3862 - accuracy: 0.2962 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
125/280 [============>.................] - ETA: 6s - loss: 1.3834 - accuracy: 0.3032 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
170/280 [=================>............] - ETA: 4s - loss: 1.3830 - accuracy: 0.3032 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
212/280 [=====================>........] - ETA: 3s - loss: 1.3830 - accuracy: 0.3015 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
245/280 [=========================>....] - ETA: 1s - loss: 1.3830 - accuracy: 0.2998 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3830 - accuracy: 0.2980 .2914 - val_loss: 1.3710 - val_accuracy: 0.2727
 30/280 [==>...........................] - ETA: 11s - loss: 1.3704 - accuracy: 0.3142.2980 - val_loss: 1.3669 - val_accuracy: 0.3333
 75/280 [=======>......................] - ETA: 9s - loss: 1.3758 - accuracy: 0.2989 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
121/280 [===========>..................] - ETA: 7s - loss: 1.3777 - accuracy: 0.2914 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
164/280 [================>.............] - ETA: 5s - loss: 1.3788 - accuracy: 0.2896 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
209/280 [=====================>........] - ETA: 3s - loss: 1.3799 - accuracy: 0.2869 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
255/280 [==========================>...] - ETA: 1s - loss: 1.3804 - accuracy: 0.2846 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
280/280 [==============================] - ETA: 0s - loss: 1.3807 - accuracy: 0.2836 .2980 - val_loss: 1.3669 - val_accuracy: 0.3333
  1/280 [..............................] - ETA: 17s - loss: 1.3312 - accuracy: 0.2500.2836 - val_loss: 1.3708 - val_accuracy: 0.2727
 46/280 [===>..........................] - ETA: 10s - loss: 1.3795 - accuracy: 0.2375.2836 - val_loss: 1.3708 - val_accuracy: 0.2727
 93/280 [========>.....................] - ETA: 8s - loss: 1.3794 - accuracy: 0.2644 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
135/280 [=============>................] - ETA: 6s - loss: 1.3790 - accuracy: 0.2754 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
174/280 [=================>............] - ETA: 4s - loss: 1.3795 - accuracy: 0.2781 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
215/280 [======================>.......] - ETA: 3s - loss: 1.3799 - accuracy: 0.2800 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
262/280 [===========================>..] - ETA: 0s - loss: 1.3803 - accuracy: 0.2808 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3804 - accuracy: 0.2808 .2836 - val_loss: 1.3708 - val_accuracy: 0.2727
  6/280 [..............................] - ETA: 12s - loss: 1.3460 - accuracy: 0.4431.2809 - val_loss: 1.3735 - val_accuracy: 0.2727
 50/280 [====>.........................] - ETA: 10s - loss: 1.3676 - accuracy: 0.3419.2809 - val_loss: 1.3735 - val_accuracy: 0.2727
 96/280 [=========>....................] - ETA: 8s - loss: 1.3698 - accuracy: 0.3290 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
142/280 [==============>...............] - ETA: 6s - loss: 1.3730 - accuracy: 0.3184 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
185/280 [==================>...........] - ETA: 4s - loss: 1.3752 - accuracy: 0.3089 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
231/280 [=======================>......] - ETA: 2s - loss: 1.3771 - accuracy: 0.3007 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
276/280 [============================>.] - ETA: 0s - loss: 1.3780 - accuracy: 0.2967 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3781 - accuracy: 0.2964 .2809 - val_loss: 1.3735 - val_accuracy: 0.2727
 18/280 [>.............................] - ETA: 11s - loss: 1.3720 - accuracy: 0.2988.2963 - val_loss: 1.3704 - val_accuracy: 0.2727
 62/280 [=====>........................] - ETA: 9s - loss: 1.3753 - accuracy: 0.2722 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
103/280 [==========>...................] - ETA: 8s - loss: 1.3793 - accuracy: 0.2646 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
147/280 [==============>...............] - ETA: 6s - loss: 1.3804 - accuracy: 0.2665 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
191/280 [===================>..........] - ETA: 4s - loss: 1.3806 - accuracy: 0.2687 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
235/280 [========================>.....] - ETA: 2s - loss: 1.3810 - accuracy: 0.2705 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3814 - accuracy: 0.2716 .2963 - val_loss: 1.3704 - val_accuracy: 0.2727
 25/280 [=>............................] - ETA: 11s - loss: 1.3827 - accuracy: 0.2257    6 - val_loss: 1.3700 - val_accuracy: 0.2727
 71/280 [======>.......................] - ETA: 9s - loss: 1.3815 - accuracy: 0.2452     6 - val_loss: 1.3700 - val_accuracy: 0.2727
116/280 [===========>..................] - ETA: 7s - loss: 1.3806 - accuracy: 0.2511     6 - val_loss: 1.3700 - val_accuracy: 0.2727
161/280 [================>.............] - ETA: 5s - loss: 1.3809 - accuracy: 0.2548     6 - val_loss: 1.3700 - val_accuracy: 0.2727
203/280 [====================>.........] - ETA: 3s - loss: 1.3812 - accuracy: 0.2581     6 - val_loss: 1.3700 - val_accuracy: 0.2727
247/280 [=========================>....] - ETA: 1s - loss: 1.3813 - accuracy: 0.2611     6 - val_loss: 1.3700 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3815 - accuracy: 0.2627     6 - val_loss: 1.3700 - val_accuracy: 0.2727
 32/280 [==>...........................] - ETA: 11s - loss: 1.4012 - accuracy: 0.2559.2628 - val_loss: 1.3736 - val_accuracy: 0.2727
 75/280 [=======>......................] - ETA: 9s - loss: 1.3907 - accuracy: 0.2856 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
119/280 [===========>..................] - ETA: 7s - loss: 1.3866 - accuracy: 0.2896 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
163/280 [================>.............] - ETA: 5s - loss: 1.3856 - accuracy: 0.2880 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
211/280 [=====================>........] - ETA: 3s - loss: 1.3851 - accuracy: 0.2854 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
255/280 [==========================>...] - ETA: 1s - loss: 1.3846 - accuracy: 0.2843 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3844 - accuracy: 0.2841 .2628 - val_loss: 1.3736 - val_accuracy: 0.2727
  3/280 [..............................] - ETA: 10s - loss: 1.3911 - accuracy: 0.2083.2840 - val_loss: 1.3801 - val_accuracy: 0.2727
 46/280 [===>..........................] - ETA: 10s - loss: 1.3890 - accuracy: 0.2923.2840 - val_loss: 1.3801 - val_accuracy: 0.2727
 80/280 [=======>......................] - ETA: 8s - loss: 1.3872 - accuracy: 0.2831 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
127/280 [============>.................] - ETA: 6s - loss: 1.3872 - accuracy: 0.2758 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
172/280 [=================>............] - ETA: 4s - loss: 1.3871 - accuracy: 0.2709 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
218/280 [======================>.......] - ETA: 2s - loss: 1.3864 - accuracy: 0.2714 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
261/280 [==========================>...] - ETA: 0s - loss: 1.3860 - accuracy: 0.2721 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3859 - accuracy: 0.2724 .2840 - val_loss: 1.3801 - val_accuracy: 0.2727
  1/280 [..............................] - ETA: 18s - loss: 1.3234 - accuracy: 0.7500.2724 - val_loss: 1.3702 - val_accuracy: 0.2727
 45/280 [===>..........................] - ETA: 10s - loss: 1.3892 - accuracy: 0.2984.2724 - val_loss: 1.3702 - val_accuracy: 0.2727
 90/280 [========>.....................] - ETA: 8s - loss: 1.3889 - accuracy: 0.2767 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
135/280 [=============>................] - ETA: 6s - loss: 1.3870 - accuracy: 0.2718 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
179/280 [==================>...........] - ETA: 4s - loss: 1.3850 - accuracy: 0.2727 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
224/280 [=======================>......] - ETA: 2s - loss: 1.3847 - accuracy: 0.2726 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
269/280 [===========================>..] - ETA: 0s - loss: 1.3844 - accuracy: 0.2733 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3844 - accuracy: 0.2735 .2724 - val_loss: 1.3702 - val_accuracy: 0.2727
 16/280 [>.............................] - ETA: 11s - loss: 1.3699 - accuracy: 0.3203.2735 - val_loss: 1.3740 - val_accuracy: 0.2727
 59/280 [=====>........................] - ETA: 10s - loss: 1.3736 - accuracy: 0.2902.2735 - val_loss: 1.3740 - val_accuracy: 0.2727
106/280 [==========>...................] - ETA: 7s - loss: 1.3759 - accuracy: 0.2815 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
150/280 [===============>..............] - ETA: 5s - loss: 1.3761 - accuracy: 0.2791 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
191/280 [===================>..........] - ETA: 4s - loss: 1.3767 - accuracy: 0.2788 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
232/280 [=======================>......] - ETA: 2s - loss: 1.3772 - accuracy: 0.2799 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
276/280 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.2796 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
280/280 [==============================] - ETA: 0s - loss: 1.3780 - accuracy: 0.2796 .2735 - val_loss: 1.3740 - val_accuracy: 0.2727
 18/280 [>.............................] - ETA: 12s - loss: 1.3634 - accuracy: 0.3714.2796 - val_loss: 1.3783 - val_accuracy: 0.2727
 64/280 [=====>........................] - ETA: 9s - loss: 1.3760 - accuracy: 0.3044 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
109/280 [==========>...................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2870 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
152/280 [===============>..............] - ETA: 5s - loss: 1.3834 - accuracy: 0.2753 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
197/280 [====================>.........] - ETA: 3s - loss: 1.3842 - accuracy: 0.2720 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
244/280 [=========================>....] - ETA: 1s - loss: 1.3839 - accuracy: 0.2729 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
279/280 [============================>.] - ETA: 0s - loss: 1.3839 - accuracy: 0.2728 .2796 - val_loss: 1.3783 - val_accuracy: 0.2727
30/55 [===============>..............] - ETA: 1s - loss: 1.3416 - accuracy: 0.3250: 0.2728 - val_loss: 1.3662 - val_accuracy: 0.2727
55/55 [==============================] - 2s 44ms/step - loss: 1.3549 - accuracy: 0.2727728 - val_loss: 1.3662 - val_accuracy: 0.2727
55/55 [==============================] - 2s 44ms/step - loss: 1.3549 - accuracy: 0.2727728 - val_loss: 1.3662 - val_accuracy: 0.2727