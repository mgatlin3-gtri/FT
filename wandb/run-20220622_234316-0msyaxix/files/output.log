2022-06-22 23:43:21.128557: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 23:43:21.129525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-22 23:43:21.161870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 23:43:21.162234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 23:43:21.162254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 23:43:21.164736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 23:43:21.164792: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 23:43:21.166993: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 23:43:21.167452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 23:43:21.169765: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 23:43:21.171023: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 23:43:21.175442: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 23:43:21.176521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 23:43:21.176884: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-22 23:43:21.176966: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 23:43:21.361790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 23:43:21.362069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 23:43:21.362095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 23:43:21.362121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 23:43:21.362134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 23:43:21.362147: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 23:43:21.362160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 23:43:21.362170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 23:43:21.362182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 23:43:21.362195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 23:43:21.362918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 23:43:21.362946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 23:43:22.102644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-22 23:43:22.102697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-22 23:43:22.102711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-22 23:43:22.102716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-22 23:43:22.103704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-22 23:43:22.104372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-22 23:43:22.380349: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-22 23:43:22.380814: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-22 23:43:22.928401: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 23:43:23.152852: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 23:43:23.724142: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-22 23:43:23.757237: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 32)      896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 32)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 32)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 16)      4624
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 16)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 16)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 32)      4640
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 32)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 64)        18496
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 64)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 64)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 64)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 64)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 260
=================================================================
Total params: 28,916
Trainable params: 28,916
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100






140/140 [==============================] - 19s 99ms/step - loss: 1.3815 - accuracy: 0.3028 - val_loss: 1.2604 - val_accuracy: 0.4735
Epoch 2/100






140/140 [==============================] - 14s 98ms/step - loss: 1.2739 - accuracy: 0.3812 - val_loss: 1.0858 - val_accuracy: 0.5189
Epoch 3/100





140/140 [==============================] - 13s 94ms/step - loss: 1.2235 - accuracy: 0.4277 - val_loss: 1.0593 - val_accuracy: 0.5076
Epoch 4/100






140/140 [==============================] - 13s 95ms/step - loss: 1.1412 - accuracy: 0.4945 - val_loss: 1.0196 - val_accuracy: 0.4886
Epoch 5/100






140/140 [==============================] - 13s 95ms/step - loss: 1.1208 - accuracy: 0.4776 - val_loss: 0.9396 - val_accuracy: 0.6515
Epoch 6/100





140/140 [==============================] - 14s 98ms/step - loss: 1.0306 - accuracy: 0.5845 - val_loss: 0.8808 - val_accuracy: 0.6553
Epoch 7/100





140/140 [==============================] - 13s 95ms/step - loss: 0.9420 - accuracy: 0.6274 - val_loss: 0.8864 - val_accuracy: 0.6591
Epoch 8/100






140/140 [==============================] - 13s 94ms/step - loss: 0.8309 - accuracy: 0.6780 - val_loss: 0.7302 - val_accuracy: 0.7159
Epoch 9/100






140/140 [==============================] - 13s 95ms/step - loss: 0.8051 - accuracy: 0.7043 - val_loss: 0.7159 - val_accuracy: 0.7045
Epoch 10/100





140/140 [==============================] - 13s 95ms/step - loss: 0.7114 - accuracy: 0.7355 - val_loss: 0.6445 - val_accuracy: 0.7424
Epoch 11/100






140/140 [==============================] - 13s 96ms/step - loss: 0.7206 - accuracy: 0.6995 - val_loss: 0.5801 - val_accuracy: 0.7803
Epoch 12/100





140/140 [==============================] - 13s 94ms/step - loss: 0.6377 - accuracy: 0.7341 - val_loss: 0.6657 - val_accuracy: 0.6818
Epoch 13/100





140/140 [==============================] - 13s 95ms/step - loss: 0.6926 - accuracy: 0.7125 - val_loss: 0.5224 - val_accuracy: 0.7992
Epoch 14/100






140/140 [==============================] - 13s 94ms/step - loss: 0.5836 - accuracy: 0.7757 - val_loss: 0.5348 - val_accuracy: 0.7917
Epoch 15/100





140/140 [==============================] - 13s 95ms/step - loss: 0.5881 - accuracy: 0.7959 - val_loss: 0.5621 - val_accuracy: 0.7803
Epoch 16/100






140/140 [==============================] - 13s 95ms/step - loss: 0.5438 - accuracy: 0.7839 - val_loss: 0.5148 - val_accuracy: 0.7955
Epoch 17/100






140/140 [==============================] - 13s 94ms/step - loss: 0.5466 - accuracy: 0.7942 - val_loss: 0.5470 - val_accuracy: 0.7765
Epoch 18/100





140/140 [==============================] - 13s 94ms/step - loss: 0.5670 - accuracy: 0.7627 - val_loss: 0.4717 - val_accuracy: 0.8144
Epoch 19/100






140/140 [==============================] - 13s 94ms/step - loss: 0.5492 - accuracy: 0.7877 - val_loss: 0.4848 - val_accuracy: 0.8068
Epoch 20/100





140/140 [==============================] - 13s 94ms/step - loss: 0.5231 - accuracy: 0.8089 - val_loss: 0.4536 - val_accuracy: 0.8333
Epoch 21/100






140/140 [==============================] - 13s 94ms/step - loss: 0.4856 - accuracy: 0.8216 - val_loss: 0.4285 - val_accuracy: 0.8447
Epoch 22/100






140/140 [==============================] - 13s 94ms/step - loss: 0.4770 - accuracy: 0.8162 - val_loss: 0.4576 - val_accuracy: 0.8523
Epoch 23/100





140/140 [==============================] - 13s 94ms/step - loss: 0.5164 - accuracy: 0.7954 - val_loss: 0.4746 - val_accuracy: 0.8258
Epoch 24/100






140/140 [==============================] - 13s 94ms/step - loss: 0.3986 - accuracy: 0.8639 - val_loss: 0.4880 - val_accuracy: 0.8030
Epoch 25/100





140/140 [==============================] - 13s 95ms/step - loss: 0.5078 - accuracy: 0.8179 - val_loss: 0.3914 - val_accuracy: 0.8902
Epoch 26/100






140/140 [==============================] - 13s 94ms/step - loss: 0.4403 - accuracy: 0.8446 - val_loss: 0.4189 - val_accuracy: 0.8939
Epoch 27/100






140/140 [==============================] - 13s 94ms/step - loss: 0.4886 - accuracy: 0.8291 - val_loss: 0.3989 - val_accuracy: 0.8561
Epoch 28/100





140/140 [==============================] - 13s 94ms/step - loss: 0.4047 - accuracy: 0.8484 - val_loss: 0.3931 - val_accuracy: 0.8750
Epoch 29/100





140/140 [==============================] - 13s 95ms/step - loss: 0.4223 - accuracy: 0.8427 - val_loss: 0.3601 - val_accuracy: 0.8826
Epoch 30/100
 41/140 [=======>......................] - ETA: 7s - loss: 0.3491 - accuracy: 0.8748
 67/140 [=============>................] - ETA: 5s - loss: 0.3858 - accuracy: 0.8534
 93/140 [==================>...........] - ETA: 3s - loss: 0.4035 - accuracy: 0.8443
119/140 [========================>.....] - ETA: 1s - loss: 0.4083 - accuracy: 0.8430
140/140 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.8437
140/140 [==============================] - 13s 94ms/step - loss: 0.4080 - accuracy: 0.8437 - val_loss: 0.3299 - val_accuracy: 0.8939
 26/140 [====>.........................] - ETA: 8s - loss: 0.4141 - accuracy: 0.8534 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
 52/140 [==========>...................] - ETA: 6s - loss: 0.4384 - accuracy: 0.8404 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
 78/140 [===============>..............] - ETA: 4s - loss: 0.4499 - accuracy: 0.8335 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
105/140 [=====================>........] - ETA: 2s - loss: 0.4568 - accuracy: 0.8303 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
131/140 [===========================>..] - ETA: 0s - loss: 0.4570 - accuracy: 0.8303 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
140/140 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8307 .8437 - val_loss: 0.3299 - val_accuracy: 0.8939
 11/140 [=>............................] - ETA: 10s - loss: 0.3395 - accuracy: 0.8633.8307 - val_loss: 0.4065 - val_accuracy: 0.8523
 37/140 [======>.......................] - ETA: 8s - loss: 0.3742 - accuracy: 0.8742 .8307 - val_loss: 0.4065 - val_accuracy: 0.8523
 64/140 [============>.................] - ETA: 5s - loss: 0.3768 - accuracy: 0.8758 .8307 - val_loss: 0.4065 - val_accuracy: 0.8523
 89/140 [==================>...........] - ETA: 3s - loss: 0.3800 - accuracy: 0.8727 .8307 - val_loss: 0.4065 - val_accuracy: 0.8523
116/140 [=======================>......] - ETA: 1s - loss: 0.3833 - accuracy: 0.8699 .8307 - val_loss: 0.4065 - val_accuracy: 0.8523
140/140 [==============================] - ETA: 0s - loss: 0.3825 - accuracy: 0.8694 .8307 - val_loss: 0.4065 - val_accuracy: 0.8523
 22/140 [===>..........................] - ETA: 9s - loss: 0.4149 - accuracy: 0.8439 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
 49/140 [=========>....................] - ETA: 6s - loss: 0.3857 - accuracy: 0.8610 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
 75/140 [===============>..............] - ETA: 4s - loss: 0.3842 - accuracy: 0.8595 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
101/140 [====================>.........] - ETA: 3s - loss: 0.3874 - accuracy: 0.8572 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
128/140 [==========================>...] - ETA: 0s - loss: 0.3898 - accuracy: 0.8561 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
140/140 [==============================] - ETA: 0s - loss: 0.3911 - accuracy: 0.8558 .8694 - val_loss: 0.5375 - val_accuracy: 0.8220
  9/140 [>.............................] - ETA: 10s - loss: 0.3549 - accuracy: 0.9053.8557 - val_loss: 0.4226 - val_accuracy: 0.8712
 35/140 [======>.......................] - ETA: 8s - loss: 0.3647 - accuracy: 0.8669 .8557 - val_loss: 0.4226 - val_accuracy: 0.8712
 61/140 [============>.................] - ETA: 6s - loss: 0.3637 - accuracy: 0.8634 .8557 - val_loss: 0.4226 - val_accuracy: 0.8712
 88/140 [=================>............] - ETA: 3s - loss: 0.3592 - accuracy: 0.8639 .8557 - val_loss: 0.4226 - val_accuracy: 0.8712
114/140 [=======================>......] - ETA: 1s - loss: 0.3568 - accuracy: 0.8649 .8557 - val_loss: 0.4226 - val_accuracy: 0.8712
140/140 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8653 .8557 - val_loss: 0.4226 - val_accuracy: 0.8712
 20/140 [===>..........................] - ETA: 9s - loss: 0.2566 - accuracy: 0.8831 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
 47/140 [=========>....................] - ETA: 7s - loss: 0.2809 - accuracy: 0.8818 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
 73/140 [==============>...............] - ETA: 5s - loss: 0.2956 - accuracy: 0.8794 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
 99/140 [====================>.........] - ETA: 3s - loss: 0.3160 - accuracy: 0.8745 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
124/140 [=========================>....] - ETA: 1s - loss: 0.3291 - accuracy: 0.8711 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
140/140 [==============================] - ETA: 0s - loss: 0.3366 - accuracy: 0.8692 .8653 - val_loss: 0.3932 - val_accuracy: 0.8636
  5/140 [>.............................] - ETA: 10s - loss: 0.5751 - accuracy: 0.8233.8690 - val_loss: 0.4564 - val_accuracy: 0.8371
 31/140 [=====>........................] - ETA: 8s - loss: 0.4994 - accuracy: 0.8417 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
 51/140 [=========>....................] - ETA: 6s - loss: 0.4613 - accuracy: 0.8521 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
 78/140 [===============>..............] - ETA: 4s - loss: 0.4292 - accuracy: 0.8615 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
103/140 [=====================>........] - ETA: 2s - loss: 0.4110 - accuracy: 0.8656 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
129/140 [==========================>...] - ETA: 0s - loss: 0.4003 - accuracy: 0.8672 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8677 .8690 - val_loss: 0.4564 - val_accuracy: 0.8371
 10/140 [=>............................] - ETA: 10s - loss: 0.2493 - accuracy: 0.9058.8677 - val_loss: 0.4698 - val_accuracy: 0.8371
 36/140 [======>.......................] - ETA: 8s - loss: 0.2935 - accuracy: 0.8917 .8677 - val_loss: 0.4698 - val_accuracy: 0.8371
 62/140 [============>.................] - ETA: 6s - loss: 0.3054 - accuracy: 0.8907 .8677 - val_loss: 0.4698 - val_accuracy: 0.8371
 88/140 [=================>............] - ETA: 4s - loss: 0.3153 - accuracy: 0.8861 .8677 - val_loss: 0.4698 - val_accuracy: 0.8371
114/140 [=======================>......] - ETA: 2s - loss: 0.3218 - accuracy: 0.8830 .8677 - val_loss: 0.4698 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.8803 .8677 - val_loss: 0.4698 - val_accuracy: 0.8371
 20/140 [===>..........................] - ETA: 9s - loss: 0.3675 - accuracy: 0.8685 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
 46/140 [========>.....................] - ETA: 7s - loss: 0.3163 - accuracy: 0.8877 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
 73/140 [==============>...............] - ETA: 5s - loss: 0.3130 - accuracy: 0.8854 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
 99/140 [====================>.........] - ETA: 3s - loss: 0.3266 - accuracy: 0.8803 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
126/140 [==========================>...] - ETA: 1s - loss: 0.3369 - accuracy: 0.8769 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.8754 .8802 - val_loss: 0.4370 - val_accuracy: 0.8371
  6/140 [>.............................] - ETA: 10s - loss: 0.3883 - accuracy: 0.8163.8753 - val_loss: 0.3803 - val_accuracy: 0.8826
 31/140 [=====>........................] - ETA: 8s - loss: 0.3691 - accuracy: 0.8504 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
 58/140 [===========>..................] - ETA: 6s - loss: 0.3766 - accuracy: 0.8543 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
 84/140 [=================>............] - ETA: 4s - loss: 0.3789 - accuracy: 0.8563 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
110/140 [======================>.......] - ETA: 2s - loss: 0.3769 - accuracy: 0.8585 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
136/140 [============================>.] - ETA: 0s - loss: 0.3759 - accuracy: 0.8592 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
140/140 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.8593 .8753 - val_loss: 0.3803 - val_accuracy: 0.8826
 16/140 [==>...........................] - ETA: 9s - loss: 0.3067 - accuracy: 0.9151 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
 42/140 [========>.....................] - ETA: 7s - loss: 0.3070 - accuracy: 0.8991 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
 68/140 [=============>................] - ETA: 5s - loss: 0.3090 - accuracy: 0.8949 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
 95/140 [===================>..........] - ETA: 3s - loss: 0.3187 - accuracy: 0.8874 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
121/140 [========================>.....] - ETA: 1s - loss: 0.3259 - accuracy: 0.8814 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
140/140 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.8784 .8594 - val_loss: 0.4078 - val_accuracy: 0.8674
  2/140 [..............................] - ETA: 10s - loss: 0.3008 - accuracy: 0.8125.8783 - val_loss: 0.4506 - val_accuracy: 0.8371
 27/140 [====>.........................] - ETA: 8s - loss: 0.3911 - accuracy: 0.8130 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
 54/140 [==========>...................] - ETA: 6s - loss: 0.3806 - accuracy: 0.8287 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
 80/140 [================>.............] - ETA: 4s - loss: 0.3772 - accuracy: 0.8348 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
106/140 [=====================>........] - ETA: 2s - loss: 0.3737 - accuracy: 0.8390 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
131/140 [===========================>..] - ETA: 0s - loss: 0.3704 - accuracy: 0.8422 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.3690 - accuracy: 0.8436 .8783 - val_loss: 0.4506 - val_accuracy: 0.8371
 11/140 [=>............................] - ETA: 10s - loss: 0.5000 - accuracy: 0.8146.8437 - val_loss: 0.4559 - val_accuracy: 0.8409
 31/140 [=====>........................] - ETA: 8s - loss: 0.4096 - accuracy: 0.8388 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
 58/140 [===========>..................] - ETA: 6s - loss: 0.3864 - accuracy: 0.8461 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
 84/140 [=================>............] - ETA: 4s - loss: 0.3741 - accuracy: 0.8522 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
110/140 [======================>.......] - ETA: 2s - loss: 0.3672 - accuracy: 0.8571 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
136/140 [============================>.] - ETA: 0s - loss: 0.3661 - accuracy: 0.8601 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
140/140 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8606 .8437 - val_loss: 0.4559 - val_accuracy: 0.8409
 17/140 [==>...........................] - ETA: 9s - loss: 0.3664 - accuracy: 0.8898 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
 43/140 [========>.....................] - ETA: 7s - loss: 0.3395 - accuracy: 0.8819 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
 69/140 [=============>................] - ETA: 5s - loss: 0.3330 - accuracy: 0.8808 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
 95/140 [===================>..........] - ETA: 3s - loss: 0.3267 - accuracy: 0.8826 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
121/140 [========================>.....] - ETA: 1s - loss: 0.3224 - accuracy: 0.8841 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
140/140 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.8846 .8607 - val_loss: 0.4568 - val_accuracy: 0.8712
  2/140 [..............................] - ETA: 12s - loss: 0.2478 - accuracy: 0.9375.8846 - val_loss: 0.3647 - val_accuracy: 0.8864
 28/140 [=====>........................] - ETA: 8s - loss: 0.2648 - accuracy: 0.9158 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
 54/140 [==========>...................] - ETA: 6s - loss: 0.2610 - accuracy: 0.9164 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
 81/140 [================>.............] - ETA: 4s - loss: 0.2618 - accuracy: 0.9129 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
107/140 [=====================>........] - ETA: 2s - loss: 0.2683 - accuracy: 0.9075 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
133/140 [===========================>..] - ETA: 0s - loss: 0.2793 - accuracy: 0.9008 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
140/140 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8993 .8846 - val_loss: 0.3647 - val_accuracy: 0.8864
 14/140 [==>...........................] - ETA: 9s - loss: 0.2788 - accuracy: 0.8631 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
 40/140 [=======>......................] - ETA: 7s - loss: 0.2855 - accuracy: 0.8774 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
 66/140 [=============>................] - ETA: 5s - loss: 0.2895 - accuracy: 0.8846 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
 92/140 [==================>...........] - ETA: 3s - loss: 0.2990 - accuracy: 0.8845 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
118/140 [========================>.....] - ETA: 1s - loss: 0.3041 - accuracy: 0.8843 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
140/140 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.8843 .8991 - val_loss: 0.4914 - val_accuracy: 0.8447
140/140 [==============================] - 13s 95ms/step - loss: 0.3063 - accuracy: 0.8843 - val_loss: 0.4971 - val_accuracy: 0.8371
 25/140 [====>.........................] - ETA: 8s - loss: 0.2496 - accuracy: 0.9336 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
 51/140 [=========>....................] - ETA: 6s - loss: 0.2724 - accuracy: 0.9142 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
 78/140 [===============>..............] - ETA: 4s - loss: 0.2802 - accuracy: 0.9077 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
104/140 [=====================>........] - ETA: 2s - loss: 0.2867 - accuracy: 0.9049 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
130/140 [==========================>...] - ETA: 0s - loss: 0.2931 - accuracy: 0.9025 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.9017 .8843 - val_loss: 0.4971 - val_accuracy: 0.8371
 10/140 [=>............................] - ETA: 10s - loss: 0.1531 - accuracy: 0.9395.9016 - val_loss: 0.4138 - val_accuracy: 0.8864
 36/140 [======>.......................] - ETA: 8s - loss: 0.2194 - accuracy: 0.9246 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
 62/140 [============>.................] - ETA: 6s - loss: 0.2462 - accuracy: 0.9169 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
 88/140 [=================>............] - ETA: 4s - loss: 0.2592 - accuracy: 0.9124 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
108/140 [======================>.......] - ETA: 2s - loss: 0.2647 - accuracy: 0.9103 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
134/140 [===========================>..] - ETA: 0s - loss: 0.2711 - accuracy: 0.9074 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
140/140 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9067 .9016 - val_loss: 0.4138 - val_accuracy: 0.8864
 14/140 [==>...........................] - ETA: 9s - loss: 0.3315 - accuracy: 0.8814 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
 40/140 [=======>......................] - ETA: 7s - loss: 0.3018 - accuracy: 0.8849 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
 67/140 [=============>................] - ETA: 5s - loss: 0.2913 - accuracy: 0.8862 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
 93/140 [==================>...........] - ETA: 3s - loss: 0.2977 - accuracy: 0.8833 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
119/140 [========================>.....] - ETA: 1s - loss: 0.3074 - accuracy: 0.8794 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
140/140 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8775 .9066 - val_loss: 0.4244 - val_accuracy: 0.8561
140/140 [==============================] - 13s 94ms/step - loss: 0.3125 - accuracy: 0.8774 - val_loss: 0.3793 - val_accuracy: 0.9015
 26/140 [====>.........................] - ETA: 8s - loss: 0.2839 - accuracy: 0.8780 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
 52/140 [==========>...................] - ETA: 6s - loss: 0.2969 - accuracy: 0.8728 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
 79/140 [===============>..............] - ETA: 4s - loss: 0.2927 - accuracy: 0.8783 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
105/140 [=====================>........] - ETA: 2s - loss: 0.2855 - accuracy: 0.8844 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
130/140 [==========================>...] - ETA: 0s - loss: 0.2817 - accuracy: 0.8881 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
140/140 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.8889 .8774 - val_loss: 0.3793 - val_accuracy: 0.9015
 11/140 [=>............................] - ETA: 9s - loss: 0.2147 - accuracy: 0.9420 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
 37/140 [======>.......................] - ETA: 7s - loss: 0.2696 - accuracy: 0.9154 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
 64/140 [============>.................] - ETA: 5s - loss: 0.2739 - accuracy: 0.9098 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
 89/140 [==================>...........] - ETA: 3s - loss: 0.2744 - accuracy: 0.9067 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
116/140 [=======================>......] - ETA: 1s - loss: 0.2763 - accuracy: 0.9041 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
140/140 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9022 .8889 - val_loss: 0.4470 - val_accuracy: 0.8864
22/28 [======================>.......] - ETA: 0s - loss: 0.4197 - accuracy: 0.8125: 0.9021 - val_loss: 0.3398 - val_accuracy: 0.9015
27/28 [===========================>..] - ETA: 0s - loss: 0.4132 - accuracy: 0.8333: 0.9021 - val_loss: 0.3398 - val_accuracy: 0.9015
28/28 [==============================] - 4s 137ms/step - loss: 0.4063 - accuracy: 0.836421 - val_loss: 0.3398 - val_accuracy: 0.9015
28/28 [==============================] - 4s 137ms/step - loss: 0.4063 - accuracy: 0.836421 - val_loss: 0.3398 - val_accuracy: 0.9015