2022-06-23 05:26:09.841337: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 05:26:09.842375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 05:26:09.886499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 05:26:09.887011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 05:26:09.887049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 05:26:09.891978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 05:26:09.892036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 05:26:09.894499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 05:26:09.894934: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 05:26:09.897079: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 05:26:09.898265: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 05:26:09.902513: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 05:26:09.903599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 05:26:09.904023: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 05:26:09.904104: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 05:26:10.079223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 05:26:10.079475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 05:26:10.079499: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 05:26:10.079524: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 05:26:10.079538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 05:26:10.079550: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 05:26:10.079560: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 05:26:10.079571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 05:26:10.079583: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 05:26:10.079596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 05:26:10.080321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 05:26:10.080348: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 05:26:10.819128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 05:26:10.819171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 05:26:10.819185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 05:26:10.819190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 05:26:10.820206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 05:26:10.820898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 05:26:11.054325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 05:26:11.054807: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 05:26:11.595874: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 05:26:11.792936: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 05:26:12.371532: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 05:26:12.407816: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 32)      896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 32)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 32)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 32)      9248
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 128)     36992
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 128)       0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 16)        18448
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 16)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 16)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 16)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 16)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 68
=================================================================
Total params: 65,652
Trainable params: 65,652
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100






280/280 [==============================] - 20s 51ms/step - loss: 1.3889 - accuracy: 0.2731 - val_loss: 1.2769 - val_accuracy: 0.3258
Epoch 2/100






280/280 [==============================] - 14s 50ms/step - loss: 1.2826 - accuracy: 0.3534 - val_loss: 1.1537 - val_accuracy: 0.4091
Epoch 3/100






280/280 [==============================] - 14s 50ms/step - loss: 1.2306 - accuracy: 0.4261 - val_loss: 1.0475 - val_accuracy: 0.5492
Epoch 4/100






280/280 [==============================] - 14s 50ms/step - loss: 1.1216 - accuracy: 0.5316 - val_loss: 1.0409 - val_accuracy: 0.6212
Epoch 5/100






280/280 [==============================] - 14s 50ms/step - loss: 1.0322 - accuracy: 0.5691 - val_loss: 0.9064 - val_accuracy: 0.6742
Epoch 6/100






280/280 [==============================] - 14s 51ms/step - loss: 1.0029 - accuracy: 0.6016 - val_loss: 0.8259 - val_accuracy: 0.6818
Epoch 7/100





280/280 [==============================] - 14s 50ms/step - loss: 0.9255 - accuracy: 0.6559 - val_loss: 0.8724 - val_accuracy: 0.6818
Epoch 8/100





280/280 [==============================] - 14s 50ms/step - loss: 0.8658 - accuracy: 0.6622 - val_loss: 0.7849 - val_accuracy: 0.6894
Epoch 9/100





280/280 [==============================] - 14s 50ms/step - loss: 0.8485 - accuracy: 0.6937 - val_loss: 0.8460 - val_accuracy: 0.6667
Epoch 10/100





280/280 [==============================] - 14s 50ms/step - loss: 0.8053 - accuracy: 0.7026 - val_loss: 0.7761 - val_accuracy: 0.6705
Epoch 11/100





280/280 [==============================] - 14s 50ms/step - loss: 0.7979 - accuracy: 0.7066 - val_loss: 0.6986 - val_accuracy: 0.7273
Epoch 12/100






280/280 [==============================] - 14s 50ms/step - loss: 0.7427 - accuracy: 0.7264 - val_loss: 0.7277 - val_accuracy: 0.7197
Epoch 13/100






280/280 [==============================] - 14s 50ms/step - loss: 0.7536 - accuracy: 0.7117 - val_loss: 0.6511 - val_accuracy: 0.7273
Epoch 14/100






280/280 [==============================] - 14s 50ms/step - loss: 0.7631 - accuracy: 0.7322 - val_loss: 0.6529 - val_accuracy: 0.7386
Epoch 15/100






280/280 [==============================] - 14s 51ms/step - loss: 0.7249 - accuracy: 0.7217 - val_loss: 0.7249 - val_accuracy: 0.7197
Epoch 16/100






280/280 [==============================] - 14s 50ms/step - loss: 0.7318 - accuracy: 0.7108 - val_loss: 0.6645 - val_accuracy: 0.7045
Epoch 17/100






280/280 [==============================] - 14s 49ms/step - loss: 0.6381 - accuracy: 0.7600 - val_loss: 0.6001 - val_accuracy: 0.7765
Epoch 18/100






280/280 [==============================] - 14s 50ms/step - loss: 0.6455 - accuracy: 0.7677 - val_loss: 0.5803 - val_accuracy: 0.7652
Epoch 19/100






280/280 [==============================] - 14s 50ms/step - loss: 0.6874 - accuracy: 0.7359 - val_loss: 0.5858 - val_accuracy: 0.8220
Epoch 20/100






280/280 [==============================] - 14s 49ms/step - loss: 0.6676 - accuracy: 0.7404 - val_loss: 0.5744 - val_accuracy: 0.7803
Epoch 21/100






280/280 [==============================] - 14s 50ms/step - loss: 0.6661 - accuracy: 0.7452 - val_loss: 0.5558 - val_accuracy: 0.7879
Epoch 22/100






280/280 [==============================] - 14s 50ms/step - loss: 0.6547 - accuracy: 0.7657 - val_loss: 0.5872 - val_accuracy: 0.7917
Epoch 23/100






280/280 [==============================] - 14s 50ms/step - loss: 0.5928 - accuracy: 0.7535 - val_loss: 0.5434 - val_accuracy: 0.7727
Epoch 24/100






280/280 [==============================] - 14s 49ms/step - loss: 0.5216 - accuracy: 0.8015 - val_loss: 0.5100 - val_accuracy: 0.8106
Epoch 25/100






280/280 [==============================] - 14s 50ms/step - loss: 0.5896 - accuracy: 0.7779 - val_loss: 0.5259 - val_accuracy: 0.8106
Epoch 26/100






280/280 [==============================] - 14s 50ms/step - loss: 0.5851 - accuracy: 0.7727 - val_loss: 0.5109 - val_accuracy: 0.7917
Epoch 27/100






280/280 [==============================] - 14s 50ms/step - loss: 0.5519 - accuracy: 0.7844 - val_loss: 0.4727 - val_accuracy: 0.8182
Epoch 28/100






280/280 [==============================] - 14s 50ms/step - loss: 0.5934 - accuracy: 0.7878 - val_loss: 0.5106 - val_accuracy: 0.8144
Epoch 29/100






280/280 [==============================] - 14s 50ms/step - loss: 0.4992 - accuracy: 0.8111 - val_loss: 0.5457 - val_accuracy: 0.7879
Epoch 30/100
 62/280 [=====>........................] - ETA: 9s - loss: 0.4887 - accuracy: 0.8213
113/280 [===========>..................] - ETA: 6s - loss: 0.5106 - accuracy: 0.8093
161/280 [================>.............] - ETA: 4s - loss: 0.5176 - accuracy: 0.8061
209/280 [=====================>........] - ETA: 2s - loss: 0.5208 - accuracy: 0.8050
259/280 [==========================>...] - ETA: 0s - loss: 0.5238 - accuracy: 0.8034
280/280 [==============================] - ETA: 0s - loss: 0.5250 - accuracy: 0.8027
 14/280 [>.............................] - ETA: 11s - loss: 0.3887 - accuracy: 0.8882.8026 - val_loss: 0.5381 - val_accuracy: 0.7992
 63/280 [=====>........................] - ETA: 9s - loss: 0.4738 - accuracy: 0.8364 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
112/280 [===========>..................] - ETA: 6s - loss: 0.4729 - accuracy: 0.8321 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
161/280 [================>.............] - ETA: 4s - loss: 0.4718 - accuracy: 0.8324 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
210/280 [=====================>........] - ETA: 2s - loss: 0.4775 - accuracy: 0.8298 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
258/280 [==========================>...] - ETA: 0s - loss: 0.4822 - accuracy: 0.8273 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
279/280 [============================>.] - ETA: 0s - loss: 0.4836 - accuracy: 0.8264 .8026 - val_loss: 0.5381 - val_accuracy: 0.7992
 15/280 [>.............................] - ETA: 11s - loss: 0.3209 - accuracy: 0.8787.8263 - val_loss: 0.4787 - val_accuracy: 0.8220
 64/280 [=====>........................] - ETA: 8s - loss: 0.4218 - accuracy: 0.8443 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
113/280 [===========>..................] - ETA: 6s - loss: 0.4420 - accuracy: 0.8415 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
161/280 [================>.............] - ETA: 4s - loss: 0.4511 - accuracy: 0.8403 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
210/280 [=====================>........] - ETA: 2s - loss: 0.4602 - accuracy: 0.8377 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
259/280 [==========================>...] - ETA: 0s - loss: 0.4711 - accuracy: 0.8344 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
279/280 [============================>.] - ETA: 0s - loss: 0.4741 - accuracy: 0.8336 .8263 - val_loss: 0.4787 - val_accuracy: 0.8220
 15/280 [>.............................] - ETA: 11s - loss: 0.4548 - accuracy: 0.8120.8335 - val_loss: 0.4420 - val_accuracy: 0.8258
 65/280 [=====>........................] - ETA: 8s - loss: 0.4897 - accuracy: 0.7922 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
114/280 [===========>..................] - ETA: 6s - loss: 0.4949 - accuracy: 0.7964 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
162/280 [================>.............] - ETA: 4s - loss: 0.4983 - accuracy: 0.7969 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
211/280 [=====================>........] - ETA: 2s - loss: 0.4959 - accuracy: 0.7995 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
262/280 [===========================>..] - ETA: 0s - loss: 0.4969 - accuracy: 0.8008 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
280/280 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.8012 .8335 - val_loss: 0.4420 - val_accuracy: 0.8258
 17/280 [>.............................] - ETA: 11s - loss: 0.5204 - accuracy: 0.7528.8012 - val_loss: 0.4435 - val_accuracy: 0.8258
 66/280 [======>.......................] - ETA: 8s - loss: 0.5203 - accuracy: 0.7809 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
116/280 [===========>..................] - ETA: 6s - loss: 0.5082 - accuracy: 0.7915 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
166/280 [================>.............] - ETA: 4s - loss: 0.5053 - accuracy: 0.7950 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
215/280 [======================>.......] - ETA: 2s - loss: 0.5054 - accuracy: 0.7970 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
264/280 [===========================>..] - ETA: 0s - loss: 0.5030 - accuracy: 0.8006 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
280/280 [==============================] - ETA: 0s - loss: 0.5021 - accuracy: 0.8015 .8012 - val_loss: 0.4435 - val_accuracy: 0.8258
 19/280 [=>............................] - ETA: 10s - loss: 0.4705 - accuracy: 0.8382.8015 - val_loss: 0.4323 - val_accuracy: 0.8182
 69/280 [======>.......................] - ETA: 8s - loss: 0.5043 - accuracy: 0.8307 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
118/280 [===========>..................] - ETA: 6s - loss: 0.4863 - accuracy: 0.8309 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
154/280 [===============>..............] - ETA: 5s - loss: 0.4802 - accuracy: 0.8302 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
203/280 [====================>.........] - ETA: 3s - loss: 0.4763 - accuracy: 0.8297 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
251/280 [=========================>....] - ETA: 1s - loss: 0.4750 - accuracy: 0.8289 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
280/280 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.8282 .8015 - val_loss: 0.4323 - val_accuracy: 0.8182
  9/280 [..............................] - ETA: 11s - loss: 0.3574 - accuracy: 0.8512.8281 - val_loss: 0.4890 - val_accuracy: 0.8106
 57/280 [=====>........................] - ETA: 9s - loss: 0.4441 - accuracy: 0.8288 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
105/280 [==========>...................] - ETA: 7s - loss: 0.4466 - accuracy: 0.8333 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
154/280 [===============>..............] - ETA: 5s - loss: 0.4431 - accuracy: 0.8378 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
203/280 [====================>.........] - ETA: 3s - loss: 0.4481 - accuracy: 0.8378 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
253/280 [==========================>...] - ETA: 1s - loss: 0.4519 - accuracy: 0.8372 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
279/280 [============================>.] - ETA: 0s - loss: 0.4550 - accuracy: 0.8364 .8281 - val_loss: 0.4890 - val_accuracy: 0.8106
  8/280 [..............................] - ETA: 11s - loss: 0.6521 - accuracy: 0.7566.8363 - val_loss: 0.5057 - val_accuracy: 0.8030
 55/280 [====>.........................] - ETA: 9s - loss: 0.4345 - accuracy: 0.8359 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
104/280 [==========>...................] - ETA: 7s - loss: 0.4325 - accuracy: 0.8367 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
153/280 [===============>..............] - ETA: 5s - loss: 0.4379 - accuracy: 0.8332 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
202/280 [====================>.........] - ETA: 3s - loss: 0.4400 - accuracy: 0.8322 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
252/280 [==========================>...] - ETA: 1s - loss: 0.4443 - accuracy: 0.8300 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
279/280 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.8294 .8363 - val_loss: 0.5057 - val_accuracy: 0.8030
  7/280 [..............................] - ETA: 11s - loss: 0.2555 - accuracy: 0.8995.8293 - val_loss: 0.5019 - val_accuracy: 0.8068
 57/280 [=====>........................] - ETA: 9s - loss: 0.4522 - accuracy: 0.8271 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
105/280 [==========>...................] - ETA: 7s - loss: 0.4598 - accuracy: 0.8270 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
155/280 [===============>..............] - ETA: 5s - loss: 0.4755 - accuracy: 0.8232 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
204/280 [====================>.........] - ETA: 3s - loss: 0.4783 - accuracy: 0.8229 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
255/280 [==========================>...] - ETA: 1s - loss: 0.4795 - accuracy: 0.8226 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
279/280 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.8223 .8293 - val_loss: 0.5019 - val_accuracy: 0.8068
 12/280 [>.............................] - ETA: 11s - loss: 0.4279 - accuracy: 0.8716.8223 - val_loss: 0.4968 - val_accuracy: 0.8220
 62/280 [=====>........................] - ETA: 8s - loss: 0.4549 - accuracy: 0.8433 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
110/280 [==========>...................] - ETA: 6s - loss: 0.4463 - accuracy: 0.8481 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
159/280 [================>.............] - ETA: 4s - loss: 0.4511 - accuracy: 0.8453 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
208/280 [=====================>........] - ETA: 2s - loss: 0.4467 - accuracy: 0.8462 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
255/280 [==========================>...] - ETA: 1s - loss: 0.4456 - accuracy: 0.8453 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
279/280 [============================>.] - ETA: 0s - loss: 0.4453 - accuracy: 0.8446 .8223 - val_loss: 0.4968 - val_accuracy: 0.8220
 12/280 [>.............................] - ETA: 11s - loss: 0.3578 - accuracy: 0.9347.8445 - val_loss: 0.5692 - val_accuracy: 0.7576
 60/280 [=====>........................] - ETA: 9s - loss: 0.5110 - accuracy: 0.8172 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
108/280 [==========>...................] - ETA: 7s - loss: 0.5213 - accuracy: 0.8003 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
158/280 [===============>..............] - ETA: 5s - loss: 0.5245 - accuracy: 0.7949 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
204/280 [====================>.........] - ETA: 3s - loss: 0.5187 - accuracy: 0.7963 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
252/280 [==========================>...] - ETA: 1s - loss: 0.5091 - accuracy: 0.8000 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
280/280 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.8022 .8445 - val_loss: 0.5692 - val_accuracy: 0.7576
  7/280 [..............................] - ETA: 11s - loss: 0.3315 - accuracy: 0.9499.8023 - val_loss: 0.4290 - val_accuracy: 0.8409
 55/280 [====>.........................] - ETA: 9s - loss: 0.3935 - accuracy: 0.8794 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
103/280 [==========>...................] - ETA: 7s - loss: 0.3859 - accuracy: 0.8765 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
152/280 [===============>..............] - ETA: 5s - loss: 0.3900 - accuracy: 0.8728 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
201/280 [====================>.........] - ETA: 3s - loss: 0.3917 - accuracy: 0.8699 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
251/280 [=========================>....] - ETA: 1s - loss: 0.3983 - accuracy: 0.8655 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
280/280 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.8635 .8023 - val_loss: 0.4290 - val_accuracy: 0.8409
  5/280 [..............................] - ETA: 10s - loss: 0.3814 - accuracy: 0.7875.8634 - val_loss: 0.4598 - val_accuracy: 0.8106
 41/280 [===>..........................] - ETA: 10s - loss: 0.4978 - accuracy: 0.7977.8634 - val_loss: 0.4598 - val_accuracy: 0.8106
 92/280 [========>.....................] - ETA: 7s - loss: 0.4699 - accuracy: 0.8136 .8634 - val_loss: 0.4598 - val_accuracy: 0.8106
140/280 [==============>...............] - ETA: 5s - loss: 0.4618 - accuracy: 0.8200 .8634 - val_loss: 0.4598 - val_accuracy: 0.8106
190/280 [===================>..........] - ETA: 3s - loss: 0.4636 - accuracy: 0.8226 .8634 - val_loss: 0.4598 - val_accuracy: 0.8106
237/280 [========================>.....] - ETA: 1s - loss: 0.4614 - accuracy: 0.8253 .8634 - val_loss: 0.4598 - val_accuracy: 0.8106
279/280 [============================>.] - ETA: 0s - loss: 0.4601 - accuracy: 0.8269 .8634 - val_loss: 0.4598 - val_accuracy: 0.8106
 43/280 [===>..........................] - ETA: 9s - loss: 0.5617 - accuracy: 0.7884 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
 93/280 [========>.....................] - ETA: 7s - loss: 0.5086 - accuracy: 0.8078 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
141/280 [==============>...............] - ETA: 5s - loss: 0.4911 - accuracy: 0.8165 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
190/280 [===================>..........] - ETA: 3s - loss: 0.4811 - accuracy: 0.8191 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
241/280 [========================>.....] - ETA: 1s - loss: 0.4746 - accuracy: 0.8202 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.8211 .8270 - val_loss: 0.4621 - val_accuracy: 0.8409
 45/280 [===>..........................] - ETA: 9s - loss: 0.4336 - accuracy: 0.8481 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
 95/280 [=========>....................] - ETA: 7s - loss: 0.4080 - accuracy: 0.8518 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
143/280 [==============>...............] - ETA: 5s - loss: 0.3993 - accuracy: 0.8550 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
191/280 [===================>..........] - ETA: 3s - loss: 0.3980 - accuracy: 0.8529 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
240/280 [========================>.....] - ETA: 1s - loss: 0.4015 - accuracy: 0.8500 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.4048 - accuracy: 0.8482 .8212 - val_loss: 0.4077 - val_accuracy: 0.8561
 45/280 [===>..........................] - ETA: 9s - loss: 0.4201 - accuracy: 0.8539 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
 96/280 [=========>....................] - ETA: 7s - loss: 0.4156 - accuracy: 0.8505 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
145/280 [==============>...............] - ETA: 5s - loss: 0.4188 - accuracy: 0.8455 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
192/280 [===================>..........] - ETA: 3s - loss: 0.4175 - accuracy: 0.8438 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
240/280 [========================>.....] - ETA: 1s - loss: 0.4174 - accuracy: 0.8424 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.4177 - accuracy: 0.8421 .8481 - val_loss: 0.4351 - val_accuracy: 0.8561
 46/280 [===>..........................] - ETA: 9s - loss: 0.5692 - accuracy: 0.7634 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
 95/280 [=========>....................] - ETA: 7s - loss: 0.5227 - accuracy: 0.7920 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
144/280 [==============>...............] - ETA: 5s - loss: 0.4909 - accuracy: 0.8080 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
192/280 [===================>..........] - ETA: 3s - loss: 0.4782 - accuracy: 0.8151 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
241/280 [========================>.....] - ETA: 1s - loss: 0.4711 - accuracy: 0.8190 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
279/280 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8215 .8421 - val_loss: 0.6026 - val_accuracy: 0.7727
 47/280 [====>.........................] - ETA: 9s - loss: 0.3149 - accuracy: 0.9151 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
 97/280 [=========>....................] - ETA: 7s - loss: 0.3307 - accuracy: 0.9061 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
146/280 [==============>...............] - ETA: 5s - loss: 0.3400 - accuracy: 0.8980 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
195/280 [===================>..........] - ETA: 3s - loss: 0.3441 - accuracy: 0.8933 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
243/280 [=========================>....] - ETA: 1s - loss: 0.3482 - accuracy: 0.8899 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
280/280 [==============================] - ETA: 0s - loss: 0.3512 - accuracy: 0.8874 .8216 - val_loss: 0.5234 - val_accuracy: 0.7841
280/280 [==============================] - 14s 50ms/step - loss: 0.3513 - accuracy: 0.8873 - val_loss: 0.4157 - val_accuracy: 0.8409
 49/280 [====>.........................] - ETA: 9s - loss: 0.3498 - accuracy: 0.8470 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
 97/280 [=========>....................] - ETA: 7s - loss: 0.3446 - accuracy: 0.8535 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
145/280 [==============>...............] - ETA: 5s - loss: 0.3396 - accuracy: 0.8598 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
194/280 [===================>..........] - ETA: 3s - loss: 0.3439 - accuracy: 0.8608 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
231/280 [=======================>......] - ETA: 2s - loss: 0.3489 - accuracy: 0.8600 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.3553 - accuracy: 0.8587 .8873 - val_loss: 0.4157 - val_accuracy: 0.8409
 35/280 [==>...........................] - ETA: 10s - loss: 0.2760 - accuracy: 0.8961.8587 - val_loss: 0.4301 - val_accuracy: 0.8182
 85/280 [========>.....................] - ETA: 8s - loss: 0.3236 - accuracy: 0.8815 .8587 - val_loss: 0.4301 - val_accuracy: 0.8182
133/280 [=============>................] - ETA: 6s - loss: 0.3448 - accuracy: 0.8723 .8587 - val_loss: 0.4301 - val_accuracy: 0.8182
182/280 [==================>...........] - ETA: 4s - loss: 0.3512 - accuracy: 0.8700 .8587 - val_loss: 0.4301 - val_accuracy: 0.8182
231/280 [=======================>......] - ETA: 2s - loss: 0.3547 - accuracy: 0.8681 .8587 - val_loss: 0.4301 - val_accuracy: 0.8182
279/280 [============================>.] - ETA: 0s - loss: 0.3573 - accuracy: 0.8669 .8587 - val_loss: 0.4301 - val_accuracy: 0.8182
 33/280 [==>...........................] - ETA: 9s - loss: 0.3905 - accuracy: 0.8040 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
 81/280 [=======>......................] - ETA: 8s - loss: 0.3829 - accuracy: 0.8265 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
132/280 [=============>................] - ETA: 6s - loss: 0.3808 - accuracy: 0.8361 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
180/280 [==================>...........] - ETA: 4s - loss: 0.3806 - accuracy: 0.8392 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
229/280 [=======================>......] - ETA: 2s - loss: 0.3851 - accuracy: 0.8388 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
277/280 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8403 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
279/280 [============================>.] - ETA: 0s - loss: 0.3868 - accuracy: 0.8404 .8669 - val_loss: 0.3845 - val_accuracy: 0.8371
 32/280 [==>...........................] - ETA: 9s - loss: 0.3012 - accuracy: 0.8740 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
 81/280 [=======>......................] - ETA: 8s - loss: 0.3333 - accuracy: 0.8743 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
131/280 [=============>................] - ETA: 6s - loss: 0.3511 - accuracy: 0.8684 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
179/280 [==================>...........] - ETA: 4s - loss: 0.3607 - accuracy: 0.8629 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
230/280 [=======================>......] - ETA: 2s - loss: 0.3673 - accuracy: 0.8598 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
278/280 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8586 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.3700 - accuracy: 0.8586 .8404 - val_loss: 0.3839 - val_accuracy: 0.8561
 34/280 [==>...........................] - ETA: 10s - loss: 0.2957 - accuracy: 0.9303.8586 - val_loss: 0.3734 - val_accuracy: 0.8674
 81/280 [=======>......................] - ETA: 8s - loss: 0.3342 - accuracy: 0.8975 .8586 - val_loss: 0.3734 - val_accuracy: 0.8674
131/280 [=============>................] - ETA: 6s - loss: 0.3444 - accuracy: 0.8848 .8586 - val_loss: 0.3734 - val_accuracy: 0.8674
180/280 [==================>...........] - ETA: 4s - loss: 0.3475 - accuracy: 0.8793 .8586 - val_loss: 0.3734 - val_accuracy: 0.8674
230/280 [=======================>......] - ETA: 2s - loss: 0.3512 - accuracy: 0.8754 .8586 - val_loss: 0.3734 - val_accuracy: 0.8674
279/280 [============================>.] - ETA: 0s - loss: 0.3551 - accuracy: 0.8720 .8586 - val_loss: 0.3734 - val_accuracy: 0.8674
 36/280 [==>...........................] - ETA: 10s - loss: 0.3403 - accuracy: 0.8738.8719 - val_loss: 0.4101 - val_accuracy: 0.8485
 85/280 [========>.....................] - ETA: 8s - loss: 0.3335 - accuracy: 0.8786 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
134/280 [=============>................] - ETA: 5s - loss: 0.3347 - accuracy: 0.8780 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
182/280 [==================>...........] - ETA: 4s - loss: 0.3430 - accuracy: 0.8740 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
231/280 [=======================>......] - ETA: 2s - loss: 0.3474 - accuracy: 0.8717 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
278/280 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8702 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
280/280 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8702 .8719 - val_loss: 0.4101 - val_accuracy: 0.8485
 35/280 [==>...........................] - ETA: 10s - loss: 0.4317 - accuracy: 0.8664.8702 - val_loss: 0.5527 - val_accuracy: 0.7803
 85/280 [========>.....................] - ETA: 8s - loss: 0.3623 - accuracy: 0.8729 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
133/280 [=============>................] - ETA: 6s - loss: 0.3509 - accuracy: 0.8749 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
180/280 [==================>...........] - ETA: 4s - loss: 0.3506 - accuracy: 0.8718 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
228/280 [=======================>......] - ETA: 2s - loss: 0.3502 - accuracy: 0.8709 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
278/280 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8694 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
280/280 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8693 .8702 - val_loss: 0.5527 - val_accuracy: 0.7803
 33/280 [==>...........................] - ETA: 10s - loss: 0.3482 - accuracy: 0.9005.8693 - val_loss: 0.4865 - val_accuracy: 0.8258
 83/280 [=======>......................] - ETA: 8s - loss: 0.3538 - accuracy: 0.8883 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
132/280 [=============>................] - ETA: 6s - loss: 0.3487 - accuracy: 0.8834 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
169/280 [=================>............] - ETA: 4s - loss: 0.3448 - accuracy: 0.8825 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
218/280 [======================>.......] - ETA: 2s - loss: 0.3463 - accuracy: 0.8804 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
267/280 [===========================>..] - ETA: 0s - loss: 0.3469 - accuracy: 0.8796 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
279/280 [============================>.] - ETA: 0s - loss: 0.3467 - accuracy: 0.8797 .8693 - val_loss: 0.4865 - val_accuracy: 0.8258
 23/280 [=>............................] - ETA: 10s - loss: 0.3652 - accuracy: 0.8815.8797 - val_loss: 0.5161 - val_accuracy: 0.8182
 71/280 [======>.......................] - ETA: 8s - loss: 0.4319 - accuracy: 0.8660 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
121/280 [===========>..................] - ETA: 6s - loss: 0.4265 - accuracy: 0.8612 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
171/280 [=================>............] - ETA: 4s - loss: 0.4190 - accuracy: 0.8581 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
218/280 [======================>.......] - ETA: 2s - loss: 0.4157 - accuracy: 0.8558 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
269/280 [===========================>..] - ETA: 0s - loss: 0.4109 - accuracy: 0.8551 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
279/280 [============================>.] - ETA: 0s - loss: 0.4100 - accuracy: 0.8551 .8797 - val_loss: 0.5161 - val_accuracy: 0.8182
 22/280 [=>............................] - ETA: 10s - loss: 0.2303 - accuracy: 0.9308.8550 - val_loss: 0.4164 - val_accuracy: 0.8371
 72/280 [======>.......................] - ETA: 8s - loss: 0.3099 - accuracy: 0.8802 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
120/280 [===========>..................] - ETA: 6s - loss: 0.3302 - accuracy: 0.8688 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
169/280 [=================>............] - ETA: 4s - loss: 0.3394 - accuracy: 0.8654 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
218/280 [======================>.......] - ETA: 2s - loss: 0.3418 - accuracy: 0.8650 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
267/280 [===========================>..] - ETA: 0s - loss: 0.3421 - accuracy: 0.8650 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
280/280 [==============================] - ETA: 0s - loss: 0.3425 - accuracy: 0.8650 .8550 - val_loss: 0.4164 - val_accuracy: 0.8371
 24/280 [=>............................] - ETA: 10s - loss: 0.5186 - accuracy: 0.8025.8649 - val_loss: 0.4039 - val_accuracy: 0.8371
 72/280 [======>.......................] - ETA: 8s - loss: 0.4097 - accuracy: 0.8446 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
121/280 [===========>..................] - ETA: 6s - loss: 0.3760 - accuracy: 0.8565 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
169/280 [=================>............] - ETA: 4s - loss: 0.3659 - accuracy: 0.8591 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
218/280 [======================>.......] - ETA: 2s - loss: 0.3605 - accuracy: 0.8599 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
268/280 [===========================>..] - ETA: 0s - loss: 0.3581 - accuracy: 0.8607 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
279/280 [============================>.] - ETA: 0s - loss: 0.3578 - accuracy: 0.8608 .8649 - val_loss: 0.4039 - val_accuracy: 0.8371
 22/280 [=>............................] - ETA: 10s - loss: 0.3446 - accuracy: 0.8425.8608 - val_loss: 0.5140 - val_accuracy: 0.7917
 72/280 [======>.......................] - ETA: 8s - loss: 0.2807 - accuracy: 0.8768 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
120/280 [===========>..................] - ETA: 6s - loss: 0.2871 - accuracy: 0.8782 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
169/280 [=================>............] - ETA: 4s - loss: 0.2979 - accuracy: 0.8779 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
216/280 [======================>.......] - ETA: 2s - loss: 0.3051 - accuracy: 0.8763 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
263/280 [===========================>..] - ETA: 0s - loss: 0.3131 - accuracy: 0.8737 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
280/280 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.8729 .8608 - val_loss: 0.5140 - val_accuracy: 0.7917
 20/280 [=>............................] - ETA: 10s - loss: 0.3107 - accuracy: 0.8720.8729 - val_loss: 0.3766 - val_accuracy: 0.8561
 71/280 [======>.......................] - ETA: 8s - loss: 0.3069 - accuracy: 0.8883 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
119/280 [===========>..................] - ETA: 6s - loss: 0.3247 - accuracy: 0.8799 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
167/280 [================>.............] - ETA: 4s - loss: 0.3303 - accuracy: 0.8738 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
217/280 [======================>.......] - ETA: 2s - loss: 0.3347 - accuracy: 0.8699 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
264/280 [===========================>..] - ETA: 0s - loss: 0.3366 - accuracy: 0.8686 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.8685 .8729 - val_loss: 0.3766 - val_accuracy: 0.8561
 20/280 [=>............................] - ETA: 11s - loss: 0.3067 - accuracy: 0.8919.8685 - val_loss: 0.4142 - val_accuracy: 0.8636
 68/280 [======>.......................] - ETA: 8s - loss: 0.2987 - accuracy: 0.8891 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
117/280 [===========>..................] - ETA: 6s - loss: 0.2980 - accuracy: 0.8894 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
165/280 [================>.............] - ETA: 4s - loss: 0.3100 - accuracy: 0.8853 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
202/280 [====================>.........] - ETA: 3s - loss: 0.3163 - accuracy: 0.8827 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
251/280 [=========================>....] - ETA: 1s - loss: 0.3198 - accuracy: 0.8815 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
279/280 [============================>.] - ETA: 0s - loss: 0.3215 - accuracy: 0.8809 .8685 - val_loss: 0.4142 - val_accuracy: 0.8636
  6/280 [..............................] - ETA: 11s - loss: 0.4297 - accuracy: 0.7882.8808 - val_loss: 0.3862 - val_accuracy: 0.8561
 55/280 [====>.........................] - ETA: 9s - loss: 0.3784 - accuracy: 0.8513 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
104/280 [==========>...................] - ETA: 7s - loss: 0.3735 - accuracy: 0.8592 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
154/280 [===============>..............] - ETA: 5s - loss: 0.3587 - accuracy: 0.8681 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
204/280 [====================>.........] - ETA: 3s - loss: 0.3490 - accuracy: 0.8726 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
253/280 [==========================>...] - ETA: 1s - loss: 0.3423 - accuracy: 0.8751 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.3397 - accuracy: 0.8760 .8808 - val_loss: 0.3862 - val_accuracy: 0.8561
  9/280 [..............................] - ETA: 11s - loss: 0.7474 - accuracy: 0.7043.8760 - val_loss: 0.3904 - val_accuracy: 0.8598
 59/280 [=====>........................] - ETA: 9s - loss: 0.4789 - accuracy: 0.8088 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
108/280 [==========>...................] - ETA: 7s - loss: 0.4201 - accuracy: 0.8360 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
156/280 [===============>..............] - ETA: 5s - loss: 0.4031 - accuracy: 0.8445 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
204/280 [====================>.........] - ETA: 3s - loss: 0.3893 - accuracy: 0.8507 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
255/280 [==========================>...] - ETA: 1s - loss: 0.3808 - accuracy: 0.8549 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
279/280 [============================>.] - ETA: 0s - loss: 0.3796 - accuracy: 0.8554 .8760 - val_loss: 0.3904 - val_accuracy: 0.8598
 11/280 [>.............................] - ETA: 12s - loss: 0.2186 - accuracy: 0.9936.8554 - val_loss: 0.3849 - val_accuracy: 0.8750
 60/280 [=====>........................] - ETA: 9s - loss: 0.2901 - accuracy: 0.9274 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
110/280 [==========>...................] - ETA: 6s - loss: 0.3034 - accuracy: 0.9160 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
159/280 [================>.............] - ETA: 4s - loss: 0.3155 - accuracy: 0.9075 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
207/280 [=====================>........] - ETA: 3s - loss: 0.3193 - accuracy: 0.9030 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
257/280 [==========================>...] - ETA: 0s - loss: 0.3220 - accuracy: 0.8991 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
279/280 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.8980 .8554 - val_loss: 0.3849 - val_accuracy: 0.8750
 15/280 [>.............................] - ETA: 10s - loss: 0.3515 - accuracy: 0.8296.8979 - val_loss: 0.5178 - val_accuracy: 0.8030
 62/280 [=====>........................] - ETA: 9s - loss: 0.3461 - accuracy: 0.8486 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
112/280 [===========>..................] - ETA: 6s - loss: 0.3391 - accuracy: 0.8590 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
161/280 [================>.............] - ETA: 4s - loss: 0.3335 - accuracy: 0.8652 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
208/280 [=====================>........] - ETA: 2s - loss: 0.3299 - accuracy: 0.8688 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
256/280 [==========================>...] - ETA: 0s - loss: 0.3299 - accuracy: 0.8699 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
279/280 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8704 .8979 - val_loss: 0.5178 - val_accuracy: 0.8030
 11/280 [>.............................] - ETA: 11s - loss: 0.1809 - accuracy: 0.8961.8705 - val_loss: 0.4459 - val_accuracy: 0.8409
 59/280 [=====>........................] - ETA: 9s - loss: 0.2973 - accuracy: 0.8718 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
109/280 [==========>...................] - ETA: 7s - loss: 0.3192 - accuracy: 0.8748 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
158/280 [===============>..............] - ETA: 5s - loss: 0.3242 - accuracy: 0.8779 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
206/280 [=====================>........] - ETA: 3s - loss: 0.3254 - accuracy: 0.8799 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
254/280 [==========================>...] - ETA: 1s - loss: 0.3241 - accuracy: 0.8812 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8817 .8705 - val_loss: 0.4459 - val_accuracy: 0.8409
 11/280 [>.............................] - ETA: 10s - loss: 0.1659 - accuracy: 0.9449.8817 - val_loss: 0.4235 - val_accuracy: 0.8523
 59/280 [=====>........................] - ETA: 9s - loss: 0.3002 - accuracy: 0.9036 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
107/280 [==========>...................] - ETA: 7s - loss: 0.3300 - accuracy: 0.8953 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
156/280 [===============>..............] - ETA: 5s - loss: 0.3370 - accuracy: 0.8945 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
204/280 [====================>.........] - ETA: 3s - loss: 0.3399 - accuracy: 0.8937 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
253/280 [==========================>...] - ETA: 1s - loss: 0.3386 - accuracy: 0.8932 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
279/280 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.8932 .8817 - val_loss: 0.4235 - val_accuracy: 0.8523
 10/280 [>.............................] - ETA: 11s - loss: 0.4340 - accuracy: 0.7992.8932 - val_loss: 0.4439 - val_accuracy: 0.8409
 46/280 [===>..........................] - ETA: 9s - loss: 0.3237 - accuracy: 0.8555 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
 96/280 [=========>....................] - ETA: 7s - loss: 0.3043 - accuracy: 0.8670 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
143/280 [==============>...............] - ETA: 5s - loss: 0.3051 - accuracy: 0.8695 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
192/280 [===================>..........] - ETA: 3s - loss: 0.3059 - accuracy: 0.8706 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
241/280 [========================>.....] - ETA: 1s - loss: 0.3067 - accuracy: 0.8712 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
280/280 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8728 .8932 - val_loss: 0.4439 - val_accuracy: 0.8409
 45/280 [===>..........................] - ETA: 9s - loss: 0.3316 - accuracy: 0.9064 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
 93/280 [========>.....................] - ETA: 7s - loss: 0.3094 - accuracy: 0.9035 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
142/280 [==============>...............] - ETA: 5s - loss: 0.2949 - accuracy: 0.9036 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
191/280 [===================>..........] - ETA: 3s - loss: 0.2862 - accuracy: 0.9051 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
240/280 [========================>.....] - ETA: 1s - loss: 0.2851 - accuracy: 0.9049 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
279/280 [============================>.] - ETA: 0s - loss: 0.2852 - accuracy: 0.9045 .8729 - val_loss: 0.4908 - val_accuracy: 0.8371
 45/280 [===>..........................] - ETA: 9s - loss: 0.3235 - accuracy: 0.8677 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
 93/280 [========>.....................] - ETA: 7s - loss: 0.3438 - accuracy: 0.8627 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
141/280 [==============>...............] - ETA: 5s - loss: 0.3544 - accuracy: 0.8602 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
190/280 [===================>..........] - ETA: 3s - loss: 0.3519 - accuracy: 0.8624 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
239/280 [========================>.....] - ETA: 1s - loss: 0.3475 - accuracy: 0.8643 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
279/280 [============================>.] - ETA: 0s - loss: 0.3438 - accuracy: 0.8657 .9045 - val_loss: 0.5418 - val_accuracy: 0.8295
 43/280 [===>..........................] - ETA: 9s - loss: 0.4496 - accuracy: 0.8030 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
 91/280 [========>.....................] - ETA: 7s - loss: 0.4283 - accuracy: 0.8236 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
141/280 [==============>...............] - ETA: 5s - loss: 0.4082 - accuracy: 0.8358 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
190/280 [===================>..........] - ETA: 3s - loss: 0.3904 - accuracy: 0.8457 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
238/280 [========================>.....] - ETA: 1s - loss: 0.3760 - accuracy: 0.8534 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.3706 - accuracy: 0.8570 .8658 - val_loss: 0.4113 - val_accuracy: 0.8712
43/55 [======================>.......] - ETA: 0s - loss: 0.4966 - accuracy: 0.8140: 0.8571 - val_loss: 0.4234 - val_accuracy: 0.8523
55/55 [==============================] - 2s 37ms/step - loss: 0.5550 - accuracy: 0.8045571 - val_loss: 0.4234 - val_accuracy: 0.8523
55/55 [==============================] - 2s 37ms/step - loss: 0.5550 - accuracy: 0.8045571 - val_loss: 0.4234 - val_accuracy: 0.8523