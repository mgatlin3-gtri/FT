2022-06-23 02:14:50.445407: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 02:14:50.446722: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 02:14:50.482082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 02:14:50.482440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 02:14:50.482461: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 02:14:50.485015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 02:14:50.485071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 02:14:50.487334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 02:14:50.487890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 02:14:50.490148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 02:14:50.491399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 02:14:50.495793: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 02:14:50.496881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 02:14:50.497237: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 02:14:50.497319: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 02:14:50.688653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 02:14:50.688924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 02:14:50.688948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 02:14:50.688972: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 02:14:50.688986: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 02:14:50.688999: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 02:14:50.689011: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 02:14:50.689022: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 02:14:50.689033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 02:14:50.689044: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 02:14:50.689720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 02:14:50.689745: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 02:14:51.422640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 02:14:51.422681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 02:14:51.422708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 02:14:51.422715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 02:14:51.423745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 02:14:51.424355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 02:14:51.696055: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 02:14:51.696490: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 02:14:52.248427: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 02:14:52.508995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 02:14:53.052495: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 02:14:53.087391: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 64)      1792
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 64)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 64)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 32)      18464
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 128)     36992
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 128)       0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 128)       147584
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 128)       0
_________________________________________________________________
global_average_pooling2d (Gl (None, 128)               0
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense (Dense)                (None, 4)                 516
=================================================================
Total params: 205,348
Trainable params: 205,348
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100







140/140 [==============================] - 22s 114ms/step - loss: 2.3774 - accuracy: 0.2744 - val_loss: 1.3728 - val_accuracy: 0.2727
Epoch 2/100







140/140 [==============================] - 16s 111ms/step - loss: 1.3790 - accuracy: 0.3020 - val_loss: 1.3733 - val_accuracy: 0.2727
Epoch 3/100







140/140 [==============================] - 16s 111ms/step - loss: 1.3797 - accuracy: 0.2777 - val_loss: 1.3755 - val_accuracy: 0.2727
Epoch 4/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3778 - accuracy: 0.3183 - val_loss: 1.3722 - val_accuracy: 0.2727
Epoch 5/100






140/140 [==============================] - 16s 111ms/step - loss: 1.3814 - accuracy: 0.2855 - val_loss: 1.3704 - val_accuracy: 0.2727
Epoch 6/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3765 - accuracy: 0.3005 - val_loss: 1.3699 - val_accuracy: 0.2727
Epoch 7/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3849 - accuracy: 0.2630 - val_loss: 1.3705 - val_accuracy: 0.2727
Epoch 8/100






140/140 [==============================] - 16s 110ms/step - loss: 1.3805 - accuracy: 0.2833 - val_loss: 1.3713 - val_accuracy: 0.2727
Epoch 9/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3744 - accuracy: 0.2777 - val_loss: 1.3795 - val_accuracy: 0.2727
Epoch 10/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3789 - accuracy: 0.2934 - val_loss: 1.3779 - val_accuracy: 0.2727
Epoch 11/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3770 - accuracy: 0.2781 - val_loss: 1.3765 - val_accuracy: 0.2727
Epoch 12/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3785 - accuracy: 0.3032 - val_loss: 1.3716 - val_accuracy: 0.2727
Epoch 13/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3812 - accuracy: 0.2948 - val_loss: 1.3712 - val_accuracy: 0.2727
Epoch 14/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3817 - accuracy: 0.2746 - val_loss: 1.3746 - val_accuracy: 0.2727
Epoch 15/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3905 - accuracy: 0.2530 - val_loss: 1.3734 - val_accuracy: 0.2727
Epoch 16/100







140/140 [==============================] - 16s 110ms/step - loss: 1.3845 - accuracy: 0.2851 - val_loss: 1.3715 - val_accuracy: 0.2727
Epoch 17/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3800 - accuracy: 0.2724 - val_loss: 1.3730 - val_accuracy: 0.2727
Epoch 18/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3760 - accuracy: 0.3044 - val_loss: 1.3725 - val_accuracy: 0.2727
Epoch 19/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3846 - accuracy: 0.2881 - val_loss: 1.3702 - val_accuracy: 0.2727
Epoch 20/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3818 - accuracy: 0.2743 - val_loss: 1.3749 - val_accuracy: 0.2727
Epoch 21/100






140/140 [==============================] - 16s 111ms/step - loss: 1.3823 - accuracy: 0.2718 - val_loss: 1.3678 - val_accuracy: 0.2727
Epoch 22/100






140/140 [==============================] - 16s 111ms/step - loss: 1.3801 - accuracy: 0.2830 - val_loss: 1.3721 - val_accuracy: 0.2727
Epoch 23/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3813 - accuracy: 0.2910 - val_loss: 1.3701 - val_accuracy: 0.2727
Epoch 24/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3802 - accuracy: 0.2634 - val_loss: 1.3727 - val_accuracy: 0.2727
Epoch 25/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3821 - accuracy: 0.2806 - val_loss: 1.3715 - val_accuracy: 0.2727
Epoch 26/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3838 - accuracy: 0.2841 - val_loss: 1.3726 - val_accuracy: 0.2727
Epoch 27/100







140/140 [==============================] - 15s 110ms/step - loss: 1.3757 - accuracy: 0.3193 - val_loss: 1.3728 - val_accuracy: 0.2727
Epoch 28/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3846 - accuracy: 0.2898 - val_loss: 1.3677 - val_accuracy: 0.2727
Epoch 29/100






140/140 [==============================] - 15s 110ms/step - loss: 1.3866 - accuracy: 0.2469 - val_loss: 1.3703 - val_accuracy: 0.2727
Epoch 30/100
 24/140 [====>.........................] - ETA: 10s - loss: 1.3488 - accuracy: 0.3219
 46/140 [========>.....................] - ETA: 8s - loss: 1.3619 - accuracy: 0.3089
 68/140 [=============>................] - ETA: 6s - loss: 1.3682 - accuracy: 0.3034
 91/140 [==================>...........] - ETA: 4s - loss: 1.3715 - accuracy: 0.2989
113/140 [=======================>......] - ETA: 2s - loss: 1.3730 - accuracy: 0.2988
136/140 [============================>.] - ETA: 0s - loss: 1.3743 - accuracy: 0.2979
140/140 [==============================] - ETA: 0s - loss: 1.3745 - accuracy: 0.2976
 10/140 [=>............................] - ETA: 12s - loss: 1.3981 - accuracy: 0.2721    75 - val_loss: 1.3706 - val_accuracy: 0.2727
 32/140 [=====>........................] - ETA: 9s - loss: 1.3824 - accuracy: 0.2980     75 - val_loss: 1.3706 - val_accuracy: 0.2727
 54/140 [==========>...................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2953     75 - val_loss: 1.3706 - val_accuracy: 0.2727
 71/140 [==============>...............] - ETA: 6s - loss: 1.3806 - accuracy: 0.2944     75 - val_loss: 1.3706 - val_accuracy: 0.2727
 94/140 [===================>..........] - ETA: 4s - loss: 1.3805 - accuracy: 0.2927     75 - val_loss: 1.3706 - val_accuracy: 0.2727
116/140 [=======================>......] - ETA: 2s - loss: 1.3807 - accuracy: 0.2914     75 - val_loss: 1.3706 - val_accuracy: 0.2727
138/140 [============================>.] - ETA: 0s - loss: 1.3809 - accuracy: 0.2901     75 - val_loss: 1.3706 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3809 - accuracy: 0.2900     75 - val_loss: 1.3706 - val_accuracy: 0.2727
 13/140 [=>............................] - ETA: 11s - loss: 1.3743 - accuracy: 0.26940.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
 35/140 [======>.......................] - ETA: 9s - loss: 1.3772 - accuracy: 0.2790 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
 57/140 [===========>..................] - ETA: 7s - loss: 1.3792 - accuracy: 0.2778 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
 80/140 [================>.............] - ETA: 5s - loss: 1.3789 - accuracy: 0.2832 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
102/140 [====================>.........] - ETA: 3s - loss: 1.3796 - accuracy: 0.2839 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
124/140 [=========================>....] - ETA: 1s - loss: 1.3800 - accuracy: 0.2833 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3801 - accuracy: 0.2825 0.2900 - val_loss: 1.3735 - val_accuracy: 0.2727
140/140 [==============================] - 15s 110ms/step - loss: 1.3802 - accuracy: 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
 21/140 [===>..........................] - ETA: 11s - loss: 1.3850 - accuracy: 0.22430.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
 43/140 [========>.....................] - ETA: 9s - loss: 1.3853 - accuracy: 0.2299 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
 65/140 [============>.................] - ETA: 6s - loss: 1.3844 - accuracy: 0.2380 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
 87/140 [=================>............] - ETA: 4s - loss: 1.3838 - accuracy: 0.2431 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
109/140 [======================>.......] - ETA: 2s - loss: 1.3840 - accuracy: 0.2452 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
131/140 [===========================>..] - ETA: 0s - loss: 1.3840 - accuracy: 0.2471 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3839 - accuracy: 0.2482 0.2825 - val_loss: 1.3694 - val_accuracy: 0.2727
  6/140 [>.............................] - ETA: 12s - loss: 1.3867 - accuracy: 0.25490.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
 28/140 [=====>........................] - ETA: 10s - loss: 1.3776 - accuracy: 0.28080.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
 50/140 [=========>....................] - ETA: 8s - loss: 1.3782 - accuracy: 0.2828 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
 72/140 [==============>...............] - ETA: 6s - loss: 1.3785 - accuracy: 0.2859 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
 94/140 [===================>..........] - ETA: 4s - loss: 1.3780 - accuracy: 0.2895 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
117/140 [========================>.....] - ETA: 2s - loss: 1.3781 - accuracy: 0.2905 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
139/140 [============================>.] - ETA: 0s - loss: 1.3786 - accuracy: 0.2903 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3786 - accuracy: 0.2903 0.2483 - val_loss: 1.3733 - val_accuracy: 0.2727
 13/140 [=>............................] - ETA: 11s - loss: 1.3700 - accuracy: 0.40130.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
 35/140 [======>.......................] - ETA: 9s - loss: 1.3743 - accuracy: 0.3591 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
 57/140 [===========>..................] - ETA: 7s - loss: 1.3760 - accuracy: 0.3456 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
 79/140 [===============>..............] - ETA: 5s - loss: 1.3776 - accuracy: 0.3323 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
102/140 [====================>.........] - ETA: 3s - loss: 1.3786 - accuracy: 0.3227 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
124/140 [=========================>....] - ETA: 1s - loss: 1.3790 - accuracy: 0.3173 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3793 - accuracy: 0.3134 0.2902 - val_loss: 1.3704 - val_accuracy: 0.2727
 20/140 [===>..........................] - ETA: 11s - loss: 1.3835 - accuracy: 0.19680.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
 42/140 [========>.....................] - ETA: 9s - loss: 1.3855 - accuracy: 0.2067 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
 64/140 [============>.................] - ETA: 7s - loss: 1.3854 - accuracy: 0.2119 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
 86/140 [=================>............] - ETA: 4s - loss: 1.3848 - accuracy: 0.2181 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
103/140 [=====================>........] - ETA: 3s - loss: 1.3843 - accuracy: 0.2237 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
125/140 [=========================>....] - ETA: 1s - loss: 1.3839 - accuracy: 0.2288 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3836 - accuracy: 0.2316 0.3132 - val_loss: 1.3715 - val_accuracy: 0.2727
140/140 [==============================] - 16s 110ms/step - loss: 1.3836 - accuracy: 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
 22/140 [===>..........................] - ETA: 10s - loss: 1.3873 - accuracy: 0.26850.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
 44/140 [========>.....................] - ETA: 8s - loss: 1.3864 - accuracy: 0.2671 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
 66/140 [=============>................] - ETA: 6s - loss: 1.3848 - accuracy: 0.2681 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
 89/140 [==================>...........] - ETA: 4s - loss: 1.3829 - accuracy: 0.2720 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
111/140 [======================>.......] - ETA: 2s - loss: 1.3820 - accuracy: 0.2757 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
133/140 [===========================>..] - ETA: 0s - loss: 1.3820 - accuracy: 0.2778 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3819 - accuracy: 0.2783 0.2317 - val_loss: 1.3710 - val_accuracy: 0.2727
  7/140 [>.............................] - ETA: 12s - loss: 1.3689 - accuracy: 0.29770.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
 29/140 [=====>........................] - ETA: 10s - loss: 1.3717 - accuracy: 0.30970.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
 52/140 [==========>...................] - ETA: 8s - loss: 1.3740 - accuracy: 0.2952 0.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
 74/140 [==============>...............] - ETA: 6s - loss: 1.3758 - accuracy: 0.2867 0.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
 96/140 [===================>..........] - ETA: 4s - loss: 1.3773 - accuracy: 0.2809 0.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
118/140 [========================>.....] - ETA: 2s - loss: 1.3783 - accuracy: 0.2787 0.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3789 - accuracy: 0.2781 0.2784 - val_loss: 1.3743 - val_accuracy: 0.2727
 14/140 [==>...........................] - ETA: 11s - loss: 1.3654 - accuracy: 0.31110.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
 37/140 [======>.......................] - ETA: 9s - loss: 1.3724 - accuracy: 0.3075 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
 59/140 [===========>..................] - ETA: 7s - loss: 1.3766 - accuracy: 0.2996 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
 81/140 [================>.............] - ETA: 5s - loss: 1.3784 - accuracy: 0.2928 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
103/140 [=====================>........] - ETA: 3s - loss: 1.3793 - accuracy: 0.2892 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
125/140 [=========================>....] - ETA: 1s - loss: 1.3797 - accuracy: 0.2876 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3798 - accuracy: 0.2878 0.2781 - val_loss: 1.3748 - val_accuracy: 0.2727
140/140 [==============================] - 15s 110ms/step - loss: 1.3799 - accuracy: 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
 22/140 [===>..........................] - ETA: 10s - loss: 1.3722 - accuracy: 0.30610.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
 45/140 [========>.....................] - ETA: 8s - loss: 1.3754 - accuracy: 0.2983 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
 66/140 [=============>................] - ETA: 6s - loss: 1.3764 - accuracy: 0.2963 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
 89/140 [==================>...........] - ETA: 4s - loss: 1.3771 - accuracy: 0.2945 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
111/140 [======================>.......] - ETA: 2s - loss: 1.3780 - accuracy: 0.2925 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
127/140 [==========================>...] - ETA: 1s - loss: 1.3787 - accuracy: 0.2907 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3790 - accuracy: 0.2901 0.2878 - val_loss: 1.3723 - val_accuracy: 0.2727
  1/140 [..............................] - ETA: 20s - loss: 1.3475 - accuracy: 0.37500.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
 24/140 [====>.........................] - ETA: 10s - loss: 1.3674 - accuracy: 0.32260.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
 45/140 [========>.....................] - ETA: 8s - loss: 1.3698 - accuracy: 0.3207 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
 67/140 [=============>................] - ETA: 6s - loss: 1.3725 - accuracy: 0.3132 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
 90/140 [==================>...........] - ETA: 4s - loss: 1.3745 - accuracy: 0.3072 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
112/140 [=======================>......] - ETA: 2s - loss: 1.3756 - accuracy: 0.3030 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
134/140 [===========================>..] - ETA: 0s - loss: 1.3767 - accuracy: 0.2993 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3769 - accuracy: 0.2986 0.2900 - val_loss: 1.3731 - val_accuracy: 0.2727
  9/140 [>.............................] - ETA: 11s - loss: 1.4104 - accuracy: 0.20990.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
 31/140 [=====>........................] - ETA: 9s - loss: 1.3909 - accuracy: 0.2817 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
 53/140 [==========>...................] - ETA: 7s - loss: 1.3876 - accuracy: 0.2869 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
 75/140 [===============>..............] - ETA: 5s - loss: 1.3862 - accuracy: 0.2876 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
 97/140 [===================>..........] - ETA: 3s - loss: 1.3858 - accuracy: 0.2864 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
119/140 [========================>.....] - ETA: 1s - loss: 1.3855 - accuracy: 0.2841 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3850 - accuracy: 0.2835 0.2985 - val_loss: 1.3742 - val_accuracy: 0.2727
 15/140 [==>...........................] - ETA: 11s - loss: 1.3881 - accuracy: 0.26010.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
 37/140 [======>.......................] - ETA: 9s - loss: 1.3824 - accuracy: 0.2757 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
 59/140 [===========>..................] - ETA: 7s - loss: 1.3807 - accuracy: 0.2822 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
 81/140 [================>.............] - ETA: 5s - loss: 1.3800 - accuracy: 0.2860 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
104/140 [=====================>........] - ETA: 3s - loss: 1.3801 - accuracy: 0.2872 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
126/140 [==========================>...] - ETA: 1s - loss: 1.3804 - accuracy: 0.2870 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3806 - accuracy: 0.2867 0.2835 - val_loss: 1.3716 - val_accuracy: 0.2727
140/140 [==============================] - 15s 110ms/step - loss: 1.3806 - accuracy: 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
 22/140 [===>..........................] - ETA: 10s - loss: 1.3724 - accuracy: 0.33910.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
 44/140 [========>.....................] - ETA: 8s - loss: 1.3736 - accuracy: 0.3315 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
 66/140 [=============>................] - ETA: 6s - loss: 1.3743 - accuracy: 0.3261 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
 89/140 [==================>...........] - ETA: 4s - loss: 1.3754 - accuracy: 0.3203 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
111/140 [======================>.......] - ETA: 2s - loss: 1.3763 - accuracy: 0.3155 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
134/140 [===========================>..] - ETA: 0s - loss: 1.3769 - accuracy: 0.3111 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3770 - accuracy: 0.3099 0.2867 - val_loss: 1.3704 - val_accuracy: 0.2727
  9/140 [>.............................] - ETA: 11s - loss: 1.3882 - accuracy: 0.17090.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
 30/140 [=====>........................] - ETA: 10s - loss: 1.3841 - accuracy: 0.22230.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
 52/140 [==========>...................] - ETA: 8s - loss: 1.3834 - accuracy: 0.2338 0.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
 74/140 [==============>...............] - ETA: 6s - loss: 1.3835 - accuracy: 0.2394 0.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
 97/140 [===================>..........] - ETA: 3s - loss: 1.3832 - accuracy: 0.2461 0.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
120/140 [========================>.....] - ETA: 1s - loss: 1.3828 - accuracy: 0.2502 0.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
140/140 [==============================] - ETA: 0s - loss: 1.3827 - accuracy: 0.2532 0.3097 - val_loss: 1.3680 - val_accuracy: 0.3333
 17/140 [==>...........................] - ETA: 11s - loss: 1.3947 - accuracy: 0.25100.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
 39/140 [=======>......................] - ETA: 9s - loss: 1.3919 - accuracy: 0.2564 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
 55/140 [==========>...................] - ETA: 7s - loss: 1.3906 - accuracy: 0.2579 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
 77/140 [===============>..............] - ETA: 5s - loss: 1.3887 - accuracy: 0.2607 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
100/140 [====================>.........] - ETA: 3s - loss: 1.3870 - accuracy: 0.2611 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
122/140 [=========================>....] - ETA: 1s - loss: 1.3863 - accuracy: 0.2611 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3858 - accuracy: 0.2619 0.2534 - val_loss: 1.3695 - val_accuracy: 0.2727
 19/140 [===>..........................] - ETA: 10s - loss: 1.3920 - accuracy: 0.25040.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
 41/140 [=======>......................] - ETA: 9s - loss: 1.3815 - accuracy: 0.2767 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
 62/140 [============>.................] - ETA: 7s - loss: 1.3785 - accuracy: 0.2842 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
 85/140 [=================>............] - ETA: 5s - loss: 1.3781 - accuracy: 0.2876 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
107/140 [=====================>........] - ETA: 3s - loss: 1.3783 - accuracy: 0.2882 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
129/140 [==========================>...] - ETA: 1s - loss: 1.3786 - accuracy: 0.2887 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3789 - accuracy: 0.2884 0.2620 - val_loss: 1.3733 - val_accuracy: 0.2727
  4/140 [..............................] - ETA: 12s - loss: 1.3826 - accuracy: 0.26300.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
 27/140 [====>.........................] - ETA: 10s - loss: 1.3825 - accuracy: 0.29280.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
 49/140 [=========>....................] - ETA: 8s - loss: 1.3813 - accuracy: 0.2960 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
 70/140 [==============>...............] - ETA: 6s - loss: 1.3810 - accuracy: 0.2972 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
 93/140 [==================>...........] - ETA: 4s - loss: 1.3810 - accuracy: 0.2965 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
115/140 [=======================>......] - ETA: 2s - loss: 1.3808 - accuracy: 0.2956 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
137/140 [============================>.] - ETA: 0s - loss: 1.3805 - accuracy: 0.2955 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
140/140 [==============================] - ETA: 0s - loss: 1.3805 - accuracy: 0.2953 0.2884 - val_loss: 1.3758 - val_accuracy: 0.2727
12/28 [===========>..................] - ETA: 1s - loss: 1.3436 - accuracy: 0.2917y: 0.2952 - val_loss: 1.3714 - val_accuracy: 0.2727
27/28 [===========================>..] - ETA: 0s - loss: 1.3623 - accuracy: 0.2639y: 0.2952 - val_loss: 1.3714 - val_accuracy: 0.2727
28/28 [==============================] - 4s 151ms/step - loss: 1.3619 - accuracy: 0.2727952 - val_loss: 1.3714 - val_accuracy: 0.2727
28/28 [==============================] - 4s 151ms/step - loss: 1.3619 - accuracy: 0.2727952 - val_loss: 1.3714 - val_accuracy: 0.2727