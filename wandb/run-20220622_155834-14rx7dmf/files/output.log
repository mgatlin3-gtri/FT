2022-06-22 15:58:38.962770: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 15:58:38.963949: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-22 15:58:39.008385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:58:39.008639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:58:39.008663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:58:39.011174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:58:39.011210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 15:58:39.013531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 15:58:39.013956: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 15:58:39.016410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 15:58:39.017695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 15:58:39.022459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:58:39.023369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 15:58:39.023890: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-22 15:58:39.023990: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 15:58:39.202171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:58:39.202415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:58:39.202443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:58:39.202473: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:58:39.202488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 15:58:39.202502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 15:58:39.202516: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 15:58:39.202530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 15:58:39.202545: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 15:58:39.202561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:58:39.203329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 15:58:39.203359: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:58:39.988133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-22 15:58:39.988185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-22 15:58:39.988202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-22 15:58:39.988208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-22 15:58:39.989336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7232 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:02:00.0, compute capability: 7.5)
2022-06-22 15:58:39.990427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7240 MB memory) -> physical GPU (device: 1, name: Quadro RTX 4000, pci bus id: 0000:03:00.0, compute capability: 7.5)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-22 15:58:40.338472: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-22 15:58:40.338988: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000010000 Hz
2022-06-22 15:58:40.986004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:58:41.327154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:58:42.319106: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-22 15:58:42.348873: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 16)      448
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 16)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 16)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 32)      4640
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 64)      18496
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 64)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 128)       73856
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 128)       0
_________________________________________________________________
global_average_pooling2d (Gl (None, 128)               0
_________________________________________________________________
dense (Dense)                (None, 4)                 516
=================================================================
Total params: 97,956
Trainable params: 97,956
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50






70/70 [==============================] - 24s 253ms/step - loss: 1.4032 - accuracy: 0.2579 - val_loss: 1.3413 - val_accuracy: 0.3030
Epoch 2/50







70/70 [==============================] - 15s 220ms/step - loss: 1.2871 - accuracy: 0.3612 - val_loss: 1.1548 - val_accuracy: 0.4432
Epoch 3/50






70/70 [==============================] - 16s 223ms/step - loss: 1.2168 - accuracy: 0.4478 - val_loss: 1.1528 - val_accuracy: 0.4962
Epoch 4/50






70/70 [==============================] - 16s 225ms/step - loss: 1.1312 - accuracy: 0.5121 - val_loss: 1.1305 - val_accuracy: 0.4659
Epoch 5/50






70/70 [==============================] - 16s 224ms/step - loss: 1.0805 - accuracy: 0.5486 - val_loss: 1.0103 - val_accuracy: 0.5682
Epoch 6/50







70/70 [==============================] - 16s 222ms/step - loss: 0.9863 - accuracy: 0.6255 - val_loss: 0.9236 - val_accuracy: 0.6553
Epoch 7/50






70/70 [==============================] - 16s 222ms/step - loss: 0.9415 - accuracy: 0.6544 - val_loss: 0.9049 - val_accuracy: 0.6439
Epoch 8/50







70/70 [==============================] - 15s 221ms/step - loss: 0.8922 - accuracy: 0.6441 - val_loss: 0.8092 - val_accuracy: 0.7159
Epoch 9/50







70/70 [==============================] - 16s 225ms/step - loss: 0.8021 - accuracy: 0.7076 - val_loss: 0.7496 - val_accuracy: 0.7121
Epoch 10/50






70/70 [==============================] - 16s 221ms/step - loss: 0.8308 - accuracy: 0.6853 - val_loss: 0.7749 - val_accuracy: 0.6856
Epoch 11/50







70/70 [==============================] - 15s 220ms/step - loss: 0.7686 - accuracy: 0.7130 - val_loss: 0.7186 - val_accuracy: 0.7045
Epoch 12/50






70/70 [==============================] - 16s 222ms/step - loss: 0.7780 - accuracy: 0.7023 - val_loss: 0.6988 - val_accuracy: 0.7348
Epoch 13/50






70/70 [==============================] - 16s 222ms/step - loss: 0.7039 - accuracy: 0.7451 - val_loss: 0.7249 - val_accuracy: 0.7197
Epoch 14/50







70/70 [==============================] - 16s 222ms/step - loss: 0.7287 - accuracy: 0.7261 - val_loss: 0.6814 - val_accuracy: 0.7727
Epoch 15/50






70/70 [==============================] - 16s 222ms/step - loss: 0.6624 - accuracy: 0.7475 - val_loss: 0.6385 - val_accuracy: 0.7614
Epoch 16/50






70/70 [==============================] - 15s 221ms/step - loss: 0.6345 - accuracy: 0.7774 - val_loss: 0.6617 - val_accuracy: 0.7348
Epoch 17/50







70/70 [==============================] - 16s 221ms/step - loss: 0.6834 - accuracy: 0.7649 - val_loss: 0.6173 - val_accuracy: 0.7538
Epoch 18/50






70/70 [==============================] - 15s 221ms/step - loss: 0.6756 - accuracy: 0.7459 - val_loss: 0.6900 - val_accuracy: 0.7197
Epoch 19/50






70/70 [==============================] - 16s 221ms/step - loss: 0.5806 - accuracy: 0.7638 - val_loss: 0.5861 - val_accuracy: 0.7879
Epoch 20/50







70/70 [==============================] - 16s 222ms/step - loss: 0.5742 - accuracy: 0.7927 - val_loss: 0.5668 - val_accuracy: 0.7652
Epoch 21/50






70/70 [==============================] - 16s 221ms/step - loss: 0.5690 - accuracy: 0.7950 - val_loss: 0.6032 - val_accuracy: 0.7727
Epoch 22/50







70/70 [==============================] - 16s 223ms/step - loss: 0.5680 - accuracy: 0.7744 - val_loss: 0.5465 - val_accuracy: 0.7689
Epoch 23/50






70/70 [==============================] - 15s 220ms/step - loss: 0.5870 - accuracy: 0.7774 - val_loss: 0.5476 - val_accuracy: 0.7727
Epoch 24/50







70/70 [==============================] - 16s 224ms/step - loss: 0.5134 - accuracy: 0.8077 - val_loss: 0.5155 - val_accuracy: 0.7955
Epoch 25/50






70/70 [==============================] - 16s 224ms/step - loss: 0.5339 - accuracy: 0.7924 - val_loss: 0.5305 - val_accuracy: 0.8068
Epoch 26/50








70/70 [==============================] - 16s 226ms/step - loss: 0.5434 - accuracy: 0.7879 - val_loss: 0.5378 - val_accuracy: 0.7727
Epoch 27/50






70/70 [==============================] - 16s 223ms/step - loss: 0.4914 - accuracy: 0.8279 - val_loss: 0.5683 - val_accuracy: 0.7614
Epoch 28/50






70/70 [==============================] - 16s 221ms/step - loss: 0.4610 - accuracy: 0.8211 - val_loss: 0.4366 - val_accuracy: 0.8258
Epoch 29/50






70/70 [==============================] - 16s 222ms/step - loss: 0.4092 - accuracy: 0.8343 - val_loss: 0.4481 - val_accuracy: 0.8106
Epoch 30/50






70/70 [==============================] - 16s 224ms/step - loss: 0.4134 - accuracy: 0.8431 - val_loss: 0.5262 - val_accuracy: 0.7955
Epoch 31/50
20/70 [=======>......................] - ETA: 9s - loss: 0.4594 - accuracy: 0.8171
30/70 [===========>..................] - ETA: 7s - loss: 0.4690 - accuracy: 0.8133
41/70 [================>.............] - ETA: 5s - loss: 0.4758 - accuracy: 0.8131
53/70 [=====================>........] - ETA: 3s - loss: 0.4831 - accuracy: 0.8122
64/70 [==========================>...] - ETA: 1s - loss: 0.4854 - accuracy: 0.8127
70/70 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.8131
70/70 [==============================] - 16s 225ms/step - loss: 0.4851 - accuracy: 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
11/70 [===>..........................] - ETA: 10s - loss: 0.4846 - accuracy: 0.81670.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
21/70 [========>.....................] - ETA: 9s - loss: 0.4940 - accuracy: 0.8113 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
32/70 [============>.................] - ETA: 7s - loss: 0.4859 - accuracy: 0.8145 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
43/70 [=================>............] - ETA: 4s - loss: 0.4774 - accuracy: 0.8176 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
54/70 [======================>.......] - ETA: 2s - loss: 0.4678 - accuracy: 0.8217 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
65/70 [==========================>...] - ETA: 0s - loss: 0.4587 - accuracy: 0.8254 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
70/70 [==============================] - ETA: 0s - loss: 0.4552 - accuracy: 0.8267 0.8132 - val_loss: 0.4554 - val_accuracy: 0.8106
 1/70 [..............................] - ETA: 17s - loss: 0.4516 - accuracy: 0.87500.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
12/70 [====>.........................] - ETA: 10s - loss: 0.4094 - accuracy: 0.89000.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
23/70 [========>.....................] - ETA: 8s - loss: 0.3930 - accuracy: 0.8858 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
34/70 [=============>................] - ETA: 6s - loss: 0.3934 - accuracy: 0.8772 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
45/70 [==================>...........] - ETA: 4s - loss: 0.3984 - accuracy: 0.8704 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
56/70 [=======================>......] - ETA: 2s - loss: 0.4032 - accuracy: 0.8660 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
67/70 [===========================>..] - ETA: 0s - loss: 0.4052 - accuracy: 0.8632 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
70/70 [==============================] - ETA: 0s - loss: 0.4052 - accuracy: 0.8629 0.8269 - val_loss: 0.4041 - val_accuracy: 0.8333
 3/70 [>.............................] - ETA: 12s - loss: 0.4219 - accuracy: 0.82640.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
14/70 [=====>........................] - ETA: 10s - loss: 0.3895 - accuracy: 0.84720.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
25/70 [=========>....................] - ETA: 8s - loss: 0.3859 - accuracy: 0.8493 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
36/70 [==============>...............] - ETA: 6s - loss: 0.3797 - accuracy: 0.8516 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
47/70 [===================>..........] - ETA: 4s - loss: 0.3782 - accuracy: 0.8538 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
58/70 [=======================>......] - ETA: 2s - loss: 0.3810 - accuracy: 0.8538 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
69/70 [============================>.] - ETA: 0s - loss: 0.3863 - accuracy: 0.8532 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
70/70 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8531 0.8628 - val_loss: 0.3991 - val_accuracy: 0.8258
 6/70 [=>............................] - ETA: 11s - loss: 0.5468 - accuracy: 0.76880.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
17/70 [======>.......................] - ETA: 9s - loss: 0.4686 - accuracy: 0.8052 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
28/70 [===========>..................] - ETA: 7s - loss: 0.4430 - accuracy: 0.8161 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
39/70 [===============>..............] - ETA: 5s - loss: 0.4307 - accuracy: 0.8204 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
50/70 [====================>.........] - ETA: 3s - loss: 0.4247 - accuracy: 0.8239 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
61/70 [=========================>....] - ETA: 1s - loss: 0.4194 - accuracy: 0.8274 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
70/70 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8291 0.8530 - val_loss: 0.5461 - val_accuracy: 0.7538
 9/70 [==>...........................] - ETA: 11s - loss: 0.3485 - accuracy: 0.86770.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
20/70 [=======>......................] - ETA: 8s - loss: 0.3818 - accuracy: 0.8523 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
31/70 [============>.................] - ETA: 7s - loss: 0.3926 - accuracy: 0.8496 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
42/70 [=================>............] - ETA: 5s - loss: 0.3950 - accuracy: 0.8500 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
53/70 [=====================>........] - ETA: 3s - loss: 0.3963 - accuracy: 0.8504 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
64/70 [==========================>...] - ETA: 1s - loss: 0.3974 - accuracy: 0.8503 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
70/70 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8507 0.8293 - val_loss: 0.5152 - val_accuracy: 0.7652
 1/70 [..............................] - ETA: 16s - loss: 0.4940 - accuracy: 0.75000.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
11/70 [===>..........................] - ETA: 11s - loss: 0.3787 - accuracy: 0.84120.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
22/70 [========>.....................] - ETA: 8s - loss: 0.3815 - accuracy: 0.8505 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
33/70 [=============>................] - ETA: 6s - loss: 0.3845 - accuracy: 0.8504 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
45/70 [==================>...........] - ETA: 4s - loss: 0.3859 - accuracy: 0.8505 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
53/70 [=====================>........] - ETA: 3s - loss: 0.3882 - accuracy: 0.8494 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
67/70 [===========================>..] - ETA: 0s - loss: 0.3892 - accuracy: 0.8496 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
70/70 [==============================] - ETA: 0s - loss: 0.3889 - accuracy: 0.8500 0.8507 - val_loss: 0.4673 - val_accuracy: 0.8220
 3/70 [>.............................] - ETA: 12s - loss: 0.4186 - accuracy: 0.82290.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
11/70 [===>..........................] - ETA: 11s - loss: 0.3595 - accuracy: 0.86710.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
22/70 [========>.....................] - ETA: 8s - loss: 0.3457 - accuracy: 0.8753 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
33/70 [=============>................] - ETA: 6s - loss: 0.3565 - accuracy: 0.8723 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
44/70 [=================>............] - ETA: 4s - loss: 0.3624 - accuracy: 0.8693 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
55/70 [======================>.......] - ETA: 2s - loss: 0.3656 - accuracy: 0.8673 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
67/70 [===========================>..] - ETA: 0s - loss: 0.3722 - accuracy: 0.8638 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
70/70 [==============================] - ETA: 0s - loss: 0.3735 - accuracy: 0.8630 0.8501 - val_loss: 0.4228 - val_accuracy: 0.8371
 3/70 [>.............................] - ETA: 13s - loss: 0.4394 - accuracy: 0.82990.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
14/70 [=====>........................] - ETA: 10s - loss: 0.4146 - accuracy: 0.82670.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
25/70 [=========>....................] - ETA: 8s - loss: 0.4033 - accuracy: 0.8328 0.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
36/70 [==============>...............] - ETA: 6s - loss: 0.3929 - accuracy: 0.8369 0.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
47/70 [===================>..........] - ETA: 4s - loss: 0.3866 - accuracy: 0.8399 0.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
58/70 [=======================>......] - ETA: 2s - loss: 0.3826 - accuracy: 0.8434 0.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
70/70 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8453 0.8628 - val_loss: 0.4295 - val_accuracy: 0.7955
 6/70 [=>............................] - ETA: 12s - loss: 0.2893 - accuracy: 0.89670.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
17/70 [======>.......................] - ETA: 9s - loss: 0.2988 - accuracy: 0.8940 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
28/70 [===========>..................] - ETA: 7s - loss: 0.3142 - accuracy: 0.8865 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
39/70 [===============>..............] - ETA: 5s - loss: 0.3312 - accuracy: 0.8785 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
50/70 [====================>.........] - ETA: 3s - loss: 0.3443 - accuracy: 0.8730 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
62/70 [=========================>....] - ETA: 1s - loss: 0.3545 - accuracy: 0.8692 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
70/70 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.8681 0.8454 - val_loss: 0.4118 - val_accuracy: 0.8485
 9/70 [==>...........................] - ETA: 11s - loss: 0.3861 - accuracy: 0.82840.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
19/70 [=======>......................] - ETA: 9s - loss: 0.3726 - accuracy: 0.8359 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
31/70 [============>.................] - ETA: 7s - loss: 0.3671 - accuracy: 0.8405 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
42/70 [=================>............] - ETA: 5s - loss: 0.3618 - accuracy: 0.8451 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
52/70 [=====================>........] - ETA: 3s - loss: 0.3650 - accuracy: 0.8458 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
64/70 [==========================>...] - ETA: 1s - loss: 0.3666 - accuracy: 0.8468 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
70/70 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.8476 0.8679 - val_loss: 0.4309 - val_accuracy: 0.8068
70/70 [==============================] - 16s 224ms/step - loss: 0.3667 - accuracy: 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
10/70 [===>..........................] - ETA: 11s - loss: 0.3622 - accuracy: 0.84650.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
21/70 [========>.....................] - ETA: 9s - loss: 0.3929 - accuracy: 0.8318 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
32/70 [============>.................] - ETA: 7s - loss: 0.3913 - accuracy: 0.8361 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
44/70 [=================>............] - ETA: 4s - loss: 0.3865 - accuracy: 0.8428 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
55/70 [======================>.......] - ETA: 2s - loss: 0.3822 - accuracy: 0.8474 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
66/70 [===========================>..] - ETA: 0s - loss: 0.3784 - accuracy: 0.8507 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
70/70 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.8518 0.8477 - val_loss: 0.3750 - val_accuracy: 0.8485
 2/70 [..............................] - ETA: 13s - loss: 0.2255 - accuracy: 0.93750.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
13/70 [====>.........................] - ETA: 10s - loss: 0.2804 - accuracy: 0.87690.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
25/70 [=========>....................] - ETA: 8s - loss: 0.3046 - accuracy: 0.8636 0.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
36/70 [==============>...............] - ETA: 6s - loss: 0.3232 - accuracy: 0.8562 0.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
47/70 [===================>..........] - ETA: 4s - loss: 0.3295 - accuracy: 0.8549 0.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
59/70 [========================>.....] - ETA: 1s - loss: 0.3336 - accuracy: 0.8549 0.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
70/70 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.8549 0.8520 - val_loss: 0.4577 - val_accuracy: 0.8068
 6/70 [=>............................] - ETA: 12s - loss: 0.3721 - accuracy: 0.82920.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
17/70 [======>.......................] - ETA: 9s - loss: 0.3416 - accuracy: 0.8542 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
29/70 [===========>..................] - ETA: 7s - loss: 0.3279 - accuracy: 0.8695 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
40/70 [================>.............] - ETA: 5s - loss: 0.3241 - accuracy: 0.8753 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
51/70 [====================>.........] - ETA: 3s - loss: 0.3217 - accuracy: 0.8783 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
63/70 [==========================>...] - ETA: 1s - loss: 0.3225 - accuracy: 0.8792 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
70/70 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.8799 0.8550 - val_loss: 0.4250 - val_accuracy: 0.8182
70/70 [==============================] - 15s 220ms/step - loss: 0.3227 - accuracy: 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
10/70 [===>..........................] - ETA: 10s - loss: 0.2764 - accuracy: 0.91980.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
22/70 [========>.....................] - ETA: 8s - loss: 0.2818 - accuracy: 0.9100 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
33/70 [=============>................] - ETA: 6s - loss: 0.2903 - accuracy: 0.9036 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
44/70 [=================>............] - ETA: 4s - loss: 0.2978 - accuracy: 0.8994 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
55/70 [======================>.......] - ETA: 2s - loss: 0.3022 - accuracy: 0.8968 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
64/70 [==========================>...] - ETA: 1s - loss: 0.3042 - accuracy: 0.8953 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
70/70 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.8945 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333
70/70 [==============================] - 15s 219ms/step - loss: 0.3058 - accuracy: 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
11/70 [===>..........................] - ETA: 10s - loss: 0.2821 - accuracy: 0.89520.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
22/70 [========>.....................] - ETA: 8s - loss: 0.2907 - accuracy: 0.8942 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
34/70 [=============>................] - ETA: 6s - loss: 0.2982 - accuracy: 0.8901 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
45/70 [==================>...........] - ETA: 4s - loss: 0.3019 - accuracy: 0.8893 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
56/70 [=======================>......] - ETA: 2s - loss: 0.3054 - accuracy: 0.8884 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
68/70 [============================>.] - ETA: 0s - loss: 0.3110 - accuracy: 0.8858 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
70/70 [==============================] - ETA: 0s - loss: 0.3118 - accuracy: 0.8853 0.8943 - val_loss: 0.3653 - val_accuracy: 0.8371
 4/70 [>.............................] - ETA: 12s - loss: 0.4352 - accuracy: 0.81640.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
16/70 [=====>........................] - ETA: 9s - loss: 0.3919 - accuracy: 0.8514 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
27/70 [==========>...................] - ETA: 7s - loss: 0.3989 - accuracy: 0.8419 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
38/70 [===============>..............] - ETA: 5s - loss: 0.3949 - accuracy: 0.8411 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
49/70 [====================>.........] - ETA: 3s - loss: 0.3897 - accuracy: 0.8422 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
61/70 [=========================>....] - ETA: 1s - loss: 0.3846 - accuracy: 0.8442 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
70/70 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.8462 0.8851 - val_loss: 0.4535 - val_accuracy: 0.8295
 8/70 [==>...........................] - ETA: 11s - loss: 0.2645 - accuracy: 0.89320.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
19/70 [=======>......................] - ETA: 9s - loss: 0.2978 - accuracy: 0.8850 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
31/70 [============>.................] - ETA: 7s - loss: 0.3201 - accuracy: 0.8721 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
42/70 [=================>............] - ETA: 5s - loss: 0.3266 - accuracy: 0.8685 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
53/70 [=====================>........] - ETA: 3s - loss: 0.3300 - accuracy: 0.8674 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
65/70 [==========================>...] - ETA: 0s - loss: 0.3323 - accuracy: 0.8664 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
70/70 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.8664 0.8464 - val_loss: 0.3945 - val_accuracy: 0.8485
 1/70 [..............................] - ETA: 16s - loss: 0.4096 - accuracy: 0.87500.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
12/70 [====>.........................] - ETA: 10s - loss: 0.2565 - accuracy: 0.91570.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
23/70 [========>.....................] - ETA: 8s - loss: 0.2553 - accuracy: 0.9066 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
35/70 [==============>...............] - ETA: 6s - loss: 0.2590 - accuracy: 0.9034 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
46/70 [==================>...........] - ETA: 4s - loss: 0.2671 - accuracy: 0.8997 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
57/70 [=======================>......] - ETA: 2s - loss: 0.2736 - accuracy: 0.8963 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
68/70 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.8930 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
70/70 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.8924 0.8664 - val_loss: 0.3884 - val_accuracy: 0.8258
 5/70 [=>............................] - ETA: 11s - loss: 0.3744 - accuracy: 0.88580.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
16/70 [=====>........................] - ETA: 9s - loss: 0.3435 - accuracy: 0.8703 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
27/70 [==========>...................] - ETA: 7s - loss: 0.3194 - accuracy: 0.8771 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
38/70 [===============>..............] - ETA: 5s - loss: 0.3079 - accuracy: 0.8798 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
49/70 [====================>.........] - ETA: 3s - loss: 0.3064 - accuracy: 0.8792 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
57/70 [=======================>......] - ETA: 2s - loss: 0.3085 - accuracy: 0.8783 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
68/70 [============================>.] - ETA: 0s - loss: 0.3123 - accuracy: 0.8771 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
70/70 [==============================] - ETA: 0s - loss: 0.3129 - accuracy: 0.8770 0.8922 - val_loss: 0.5079 - val_accuracy: 0.7992
 4/14 [=======>......................] - ETA: 1s - loss: 0.7508 - accuracy: 0.7344 0.8769 - val_loss: 0.4970 - val_accuracy: 0.8106
13/14 [==========================>...] - ETA: 0s - loss: 0.5873 - accuracy: 0.8029 0.8769 - val_loss: 0.4970 - val_accuracy: 0.8106
13/14 [==========================>...] - ETA: 0s - loss: 0.5873 - accuracy: 0.8029 0.8769 - val_loss: 0.4970 - val_accuracy: 0.8106
Traceback (most recent call last):
  File "/home/apopa6/feces_thesis/2dCNN.py", line 89, in <module>
    wandb.log({"test_loss": test_loss, "test_accuracy": test_accuracy, "config": wandb.config})
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 256, in wrapper
    return func(self, *args, **kwargs)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 222, in wrapper
    return func(self, *args, **kwargs)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1548, in log
    self._log(data=data, step=step, commit=commit)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1339, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1228, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 548, in publish_partial_history
    item.value_json = json_dumps_safer_history(v)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/util.py", line 820, in json_dumps_safer_history
    return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/json/__init__.py", line 234, in dumps
    return cls(
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/site-packages/wandb/util.py", line 787, in default
    return json.JSONEncoder.default(self, obj)
  File "/home/apopa6/.conda/envs/ICE_NN/lib/python3.9/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
14/14 [==============================] - 4s 306ms/step - loss: 0.6188 - accuracy: 0.79559 - val_loss: 0.4970 - val_accuracy: 0.8106
14/14 [==============================] - 4s 306ms/step - loss: 0.6188 - accuracy: 0.79559 - val_loss: 0.4970 - val_accuracy: 0.8106