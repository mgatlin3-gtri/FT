2022-06-23 10:27:16.924216: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 10:27:16.925222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 10:27:16.961903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 10:27:16.962268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 10:27:16.962287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 10:27:16.965238: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 10:27:16.965298: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 10:27:16.967477: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 10:27:16.967973: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 10:27:16.970182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 10:27:16.971440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 10:27:16.975794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 10:27:16.977190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 10:27:16.977544: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 10:27:16.977623: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 10:27:17.181492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 10:27:17.181779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 10:27:17.181809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 10:27:17.181846: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 10:27:17.181860: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 10:27:17.181872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 10:27:17.181883: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 10:27:17.181894: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 10:27:17.181907: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 10:27:17.181918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 10:27:17.182602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 10:27:17.182626: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 10:27:17.920274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 10:27:17.920318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 10:27:17.920330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 10:27:17.920335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 10:27:17.921374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 10:27:17.922031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 10:27:18.192943: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 10:27:18.193404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 10:27:18.743385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 10:27:18.991948: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 10:27:19.556584: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 10:27:19.592189: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 32)      896
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 32)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 32)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 16)      4624
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 16)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 16)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 32)      4640
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 32)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 64)        18496
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 64)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 64)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 64)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 64)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 260
=================================================================
Total params: 28,916
Trainable params: 28,916
Non-trainable params: 0
_________________________________________________________________
Epoch 1/80






140/140 [==============================] - 20s 99ms/step - loss: 1.3829 - accuracy: 0.2914 - val_loss: 1.3236 - val_accuracy: 0.3523
Epoch 2/80






140/140 [==============================] - 14s 98ms/step - loss: 1.2990 - accuracy: 0.3486 - val_loss: 1.0188 - val_accuracy: 0.6061
Epoch 3/80





140/140 [==============================] - 13s 96ms/step - loss: 1.1225 - accuracy: 0.5136 - val_loss: 0.9502 - val_accuracy: 0.5909
Epoch 4/80





140/140 [==============================] - 13s 96ms/step - loss: 0.9691 - accuracy: 0.6122 - val_loss: 0.8929 - val_accuracy: 0.6667
Epoch 5/80





140/140 [==============================] - 14s 98ms/step - loss: 0.8672 - accuracy: 0.6353 - val_loss: 0.9637 - val_accuracy: 0.6136
Epoch 6/80






140/140 [==============================] - 14s 98ms/step - loss: 0.7985 - accuracy: 0.7030 - val_loss: 0.8753 - val_accuracy: 0.6326
Epoch 7/80






140/140 [==============================] - 14s 96ms/step - loss: 0.7872 - accuracy: 0.6750 - val_loss: 0.7881 - val_accuracy: 0.6818
Epoch 8/80





140/140 [==============================] - 14s 97ms/step - loss: 0.7585 - accuracy: 0.7001 - val_loss: 0.9315 - val_accuracy: 0.6136
Epoch 9/80





140/140 [==============================] - 14s 97ms/step - loss: 0.6634 - accuracy: 0.7505 - val_loss: 0.8835 - val_accuracy: 0.6477
Epoch 10/80





140/140 [==============================] - 14s 96ms/step - loss: 0.7050 - accuracy: 0.7225 - val_loss: 0.7518 - val_accuracy: 0.7576
Epoch 11/80






140/140 [==============================] - 14s 99ms/step - loss: 0.6732 - accuracy: 0.7493 - val_loss: 0.6380 - val_accuracy: 0.7576
Epoch 12/80






140/140 [==============================] - 13s 95ms/step - loss: 0.6044 - accuracy: 0.7769 - val_loss: 0.8150 - val_accuracy: 0.7045
Epoch 13/80





140/140 [==============================] - 14s 98ms/step - loss: 0.6173 - accuracy: 0.7690 - val_loss: 0.5800 - val_accuracy: 0.7538
Epoch 14/80





140/140 [==============================] - 14s 97ms/step - loss: 0.5949 - accuracy: 0.7698 - val_loss: 0.6233 - val_accuracy: 0.7614
Epoch 15/80





140/140 [==============================] - 14s 97ms/step - loss: 0.5951 - accuracy: 0.7937 - val_loss: 0.6107 - val_accuracy: 0.7765
Epoch 16/80






140/140 [==============================] - 14s 97ms/step - loss: 0.5877 - accuracy: 0.7645 - val_loss: 0.5486 - val_accuracy: 0.7917
Epoch 17/80






140/140 [==============================] - 14s 97ms/step - loss: 0.5083 - accuracy: 0.8024 - val_loss: 0.5328 - val_accuracy: 0.7917
Epoch 18/80





140/140 [==============================] - 14s 97ms/step - loss: 0.5174 - accuracy: 0.8082 - val_loss: 0.6328 - val_accuracy: 0.7992
Epoch 19/80





140/140 [==============================] - 13s 96ms/step - loss: 0.4729 - accuracy: 0.8269 - val_loss: 0.4832 - val_accuracy: 0.7917
Epoch 20/80





140/140 [==============================] - 14s 97ms/step - loss: 0.4573 - accuracy: 0.8436 - val_loss: 0.4725 - val_accuracy: 0.8030
Epoch 21/80






140/140 [==============================] - 14s 97ms/step - loss: 0.4585 - accuracy: 0.8196 - val_loss: 0.4643 - val_accuracy: 0.8182
Epoch 22/80






140/140 [==============================] - 14s 97ms/step - loss: 0.4242 - accuracy: 0.8476 - val_loss: 0.5066 - val_accuracy: 0.8106
Epoch 23/80





140/140 [==============================] - 13s 96ms/step - loss: 0.4350 - accuracy: 0.8607 - val_loss: 0.4936 - val_accuracy: 0.8182
Epoch 24/80






140/140 [==============================] - 13s 96ms/step - loss: 0.4394 - accuracy: 0.8325 - val_loss: 0.5158 - val_accuracy: 0.7765
Epoch 25/80





140/140 [==============================] - 13s 96ms/step - loss: 0.3873 - accuracy: 0.8582 - val_loss: 0.5308 - val_accuracy: 0.8144
Epoch 26/80






140/140 [==============================] - 14s 97ms/step - loss: 0.4011 - accuracy: 0.8369 - val_loss: 0.4280 - val_accuracy: 0.8674
Epoch 27/80





140/140 [==============================] - 13s 96ms/step - loss: 0.3504 - accuracy: 0.8617 - val_loss: 0.7449 - val_accuracy: 0.7311
Epoch 28/80





140/140 [==============================] - 13s 96ms/step - loss: 0.3700 - accuracy: 0.8750 - val_loss: 0.5860 - val_accuracy: 0.7765
Epoch 29/80






140/140 [==============================] - 14s 97ms/step - loss: 0.3873 - accuracy: 0.8609 - val_loss: 0.6667 - val_accuracy: 0.8182
Epoch 30/80
 38/140 [=======>......................] - ETA: 8s - loss: 0.3478 - accuracy: 0.8739
 63/140 [============>.................] - ETA: 6s - loss: 0.3500 - accuracy: 0.8682
 83/140 [================>.............] - ETA: 4s - loss: 0.3492 - accuracy: 0.8688
108/140 [======================>.......] - ETA: 2s - loss: 0.3504 - accuracy: 0.8699
135/140 [===========================>..] - ETA: 0s - loss: 0.3511 - accuracy: 0.8708
140/140 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.8708
 13/140 [=>............................] - ETA: 10s - loss: 0.3742 - accuracy: 0.8525.8708 - val_loss: 0.5094 - val_accuracy: 0.7614
 38/140 [=======>......................] - ETA: 8s - loss: 0.4293 - accuracy: 0.8233 .8708 - val_loss: 0.5094 - val_accuracy: 0.7614
 63/140 [============>.................] - ETA: 6s - loss: 0.4261 - accuracy: 0.8278 .8708 - val_loss: 0.5094 - val_accuracy: 0.7614
 91/140 [==================>...........] - ETA: 3s - loss: 0.4198 - accuracy: 0.8321 .8708 - val_loss: 0.5094 - val_accuracy: 0.7614
116/140 [=======================>......] - ETA: 1s - loss: 0.4120 - accuracy: 0.8357 .8708 - val_loss: 0.5094 - val_accuracy: 0.7614
140/140 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8391 .8708 - val_loss: 0.5094 - val_accuracy: 0.7614
 20/140 [===>..........................] - ETA: 9s - loss: 0.3499 - accuracy: 0.8647 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
 45/140 [========>.....................] - ETA: 7s - loss: 0.3518 - accuracy: 0.8693 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
 71/140 [==============>...............] - ETA: 5s - loss: 0.3410 - accuracy: 0.8769 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
 97/140 [===================>..........] - ETA: 3s - loss: 0.3417 - accuracy: 0.8755 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
123/140 [=========================>....] - ETA: 1s - loss: 0.3451 - accuracy: 0.8723 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.3471 - accuracy: 0.8706 .8392 - val_loss: 0.4604 - val_accuracy: 0.8371
  3/140 [..............................] - ETA: 10s - loss: 0.4868 - accuracy: 0.8889.8705 - val_loss: 0.5074 - val_accuracy: 0.7879
 28/140 [=====>........................] - ETA: 8s - loss: 0.4440 - accuracy: 0.8686 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
 54/140 [==========>...................] - ETA: 6s - loss: 0.4440 - accuracy: 0.8527 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
 78/140 [===============>..............] - ETA: 4s - loss: 0.4349 - accuracy: 0.8478 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
105/140 [=====================>........] - ETA: 2s - loss: 0.4216 - accuracy: 0.8480 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
130/140 [==========================>...] - ETA: 0s - loss: 0.4110 - accuracy: 0.8495 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
140/140 [==============================] - ETA: 0s - loss: 0.4074 - accuracy: 0.8501 .8705 - val_loss: 0.5074 - val_accuracy: 0.7879
 10/140 [=>............................] - ETA: 10s - loss: 0.3021 - accuracy: 0.8805.8501 - val_loss: 0.5286 - val_accuracy: 0.7727
 35/140 [======>.......................] - ETA: 8s - loss: 0.2929 - accuracy: 0.8780 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
 60/140 [===========>..................] - ETA: 6s - loss: 0.2806 - accuracy: 0.8883 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
 87/140 [=================>............] - ETA: 4s - loss: 0.2790 - accuracy: 0.8919 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
111/140 [======================>.......] - ETA: 2s - loss: 0.2850 - accuracy: 0.8912 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
138/140 [============================>.] - ETA: 0s - loss: 0.2909 - accuracy: 0.8904 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
140/140 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8903 .8501 - val_loss: 0.5286 - val_accuracy: 0.7727
 17/140 [==>...........................] - ETA: 9s - loss: 0.2315 - accuracy: 0.8890 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
 41/140 [=======>......................] - ETA: 8s - loss: 0.2314 - accuracy: 0.8962 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
 66/140 [=============>................] - ETA: 5s - loss: 0.2373 - accuracy: 0.9008 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
 92/140 [==================>...........] - ETA: 3s - loss: 0.2491 - accuracy: 0.9001 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
117/140 [========================>.....] - ETA: 1s - loss: 0.2559 - accuracy: 0.8990 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.8987 .8903 - val_loss: 0.5471 - val_accuracy: 0.8371
 22/140 [===>..........................] - ETA: 9s - loss: 0.2171 - accuracy: 0.9218 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
 47/140 [=========>....................] - ETA: 7s - loss: 0.2309 - accuracy: 0.9101 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
 72/140 [==============>...............] - ETA: 5s - loss: 0.2377 - accuracy: 0.9061 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
 91/140 [==================>...........] - ETA: 3s - loss: 0.2385 - accuracy: 0.9057 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
117/140 [========================>.....] - ETA: 1s - loss: 0.2409 - accuracy: 0.9051 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
140/140 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.9036 .8987 - val_loss: 0.6458 - val_accuracy: 0.7841
 21/140 [===>..........................] - ETA: 9s - loss: 0.2034 - accuracy: 0.8833 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
 46/140 [========>.....................] - ETA: 7s - loss: 0.2027 - accuracy: 0.9010 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
 71/140 [==============>...............] - ETA: 5s - loss: 0.2243 - accuracy: 0.8991 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
 97/140 [===================>..........] - ETA: 3s - loss: 0.2366 - accuracy: 0.8971 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
123/140 [=========================>....] - ETA: 1s - loss: 0.2438 - accuracy: 0.8957 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
140/140 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.8947 .9036 - val_loss: 0.6182 - val_accuracy: 0.7955
  2/140 [..............................] - ETA: 10s - loss: 0.1383 - accuracy: 1.0000.8946 - val_loss: 0.6182 - val_accuracy: 0.7689
 28/140 [=====>........................] - ETA: 8s - loss: 0.2021 - accuracy: 0.9326 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
 53/140 [==========>...................] - ETA: 6s - loss: 0.2294 - accuracy: 0.9209 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
 79/140 [===============>..............] - ETA: 4s - loss: 0.2529 - accuracy: 0.9109 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
105/140 [=====================>........] - ETA: 2s - loss: 0.2633 - accuracy: 0.9069 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
130/140 [==========================>...] - ETA: 0s - loss: 0.2682 - accuracy: 0.9051 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
140/140 [==============================] - ETA: 0s - loss: 0.2695 - accuracy: 0.9046 .8946 - val_loss: 0.6182 - val_accuracy: 0.7689
  9/140 [>.............................] - ETA: 10s - loss: 0.2373 - accuracy: 0.8833.9046 - val_loss: 0.5076 - val_accuracy: 0.8295
 34/140 [======>.......................] - ETA: 8s - loss: 0.1985 - accuracy: 0.9101 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
 59/140 [===========>..................] - ETA: 6s - loss: 0.2058 - accuracy: 0.9110 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
 85/140 [=================>............] - ETA: 4s - loss: 0.2165 - accuracy: 0.9088 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
110/140 [======================>.......] - ETA: 2s - loss: 0.2247 - accuracy: 0.9073 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
137/140 [============================>.] - ETA: 0s - loss: 0.2288 - accuracy: 0.9067 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
140/140 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.9065 .9046 - val_loss: 0.5076 - val_accuracy: 0.8295
 15/140 [==>...........................] - ETA: 9s - loss: 0.1774 - accuracy: 0.9448 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
 40/140 [=======>......................] - ETA: 8s - loss: 0.2088 - accuracy: 0.9336 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
 65/140 [============>.................] - ETA: 6s - loss: 0.2095 - accuracy: 0.9303 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
 91/140 [==================>...........] - ETA: 3s - loss: 0.2163 - accuracy: 0.9252 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
117/140 [========================>.....] - ETA: 1s - loss: 0.2230 - accuracy: 0.9218 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
140/140 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.9192 .9064 - val_loss: 0.6028 - val_accuracy: 0.7917
 22/140 [===>..........................] - ETA: 9s - loss: 0.3097 - accuracy: 0.8819 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
 47/140 [=========>....................] - ETA: 7s - loss: 0.3020 - accuracy: 0.8866 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
 72/140 [==============>...............] - ETA: 5s - loss: 0.2910 - accuracy: 0.8908 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
 98/140 [====================>.........] - ETA: 3s - loss: 0.2822 - accuracy: 0.8940 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
124/140 [=========================>....] - ETA: 1s - loss: 0.2769 - accuracy: 0.8962 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
140/140 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.8973 .9191 - val_loss: 0.5662 - val_accuracy: 0.8295
  1/140 [..............................] - ETA: 16s - loss: 0.6250 - accuracy: 0.8750.8974 - val_loss: 0.5019 - val_accuracy: 0.8220
 26/140 [====>.........................] - ETA: 9s - loss: 0.4921 - accuracy: 0.8537 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
 51/140 [=========>....................] - ETA: 7s - loss: 0.4313 - accuracy: 0.8695 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
 77/140 [===============>..............] - ETA: 5s - loss: 0.3911 - accuracy: 0.8810 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
 96/140 [===================>..........] - ETA: 3s - loss: 0.3742 - accuracy: 0.8850 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
122/140 [=========================>....] - ETA: 1s - loss: 0.3575 - accuracy: 0.8879 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
140/140 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8902 .8974 - val_loss: 0.5019 - val_accuracy: 0.8220
  2/140 [..............................] - ETA: 12s - loss: 0.0657 - accuracy: 1.0000.8903 - val_loss: 0.5193 - val_accuracy: 0.8295
 27/140 [====>.........................] - ETA: 9s - loss: 0.2435 - accuracy: 0.9026 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
 52/140 [==========>...................] - ETA: 7s - loss: 0.2375 - accuracy: 0.9048 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
 77/140 [===============>..............] - ETA: 5s - loss: 0.2373 - accuracy: 0.9062 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
103/140 [=====================>........] - ETA: 2s - loss: 0.2340 - accuracy: 0.9084 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
128/140 [==========================>...] - ETA: 0s - loss: 0.2313 - accuracy: 0.9101 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
140/140 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.9105 .8903 - val_loss: 0.5193 - val_accuracy: 0.8295
  8/140 [>.............................] - ETA: 10s - loss: 0.1603 - accuracy: 0.9701.9106 - val_loss: 0.6560 - val_accuracy: 0.7841
 33/140 [======>.......................] - ETA: 8s - loss: 0.2083 - accuracy: 0.9381 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
 59/140 [===========>..................] - ETA: 6s - loss: 0.2182 - accuracy: 0.9299 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
 84/140 [=================>............] - ETA: 4s - loss: 0.2209 - accuracy: 0.9286 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
109/140 [======================>.......] - ETA: 2s - loss: 0.2223 - accuracy: 0.9274 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
136/140 [============================>.] - ETA: 0s - loss: 0.2223 - accuracy: 0.9273 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
140/140 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.9273 .9106 - val_loss: 0.6560 - val_accuracy: 0.7841
 15/140 [==>...........................] - ETA: 10s - loss: 0.3637 - accuracy: 0.9029.9273 - val_loss: 0.7314 - val_accuracy: 0.7841
 40/140 [=======>......................] - ETA: 8s - loss: 0.2711 - accuracy: 0.9187 .9273 - val_loss: 0.7314 - val_accuracy: 0.7841
 65/140 [============>.................] - ETA: 6s - loss: 0.2588 - accuracy: 0.9190 .9273 - val_loss: 0.7314 - val_accuracy: 0.7841
 91/140 [==================>...........] - ETA: 3s - loss: 0.2574 - accuracy: 0.9169 .9273 - val_loss: 0.7314 - val_accuracy: 0.7841
117/140 [========================>.....] - ETA: 1s - loss: 0.2552 - accuracy: 0.9157 .9273 - val_loss: 0.7314 - val_accuracy: 0.7841
140/140 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.9139 .9273 - val_loss: 0.7314 - val_accuracy: 0.7841
 21/140 [===>..........................] - ETA: 9s - loss: 0.2675 - accuracy: 0.8851 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
 46/140 [========>.....................] - ETA: 7s - loss: 0.2540 - accuracy: 0.8860 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
 71/140 [==============>...............] - ETA: 5s - loss: 0.2681 - accuracy: 0.8878 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
 97/140 [===================>..........] - ETA: 3s - loss: 0.2808 - accuracy: 0.8874 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
122/140 [=========================>....] - ETA: 1s - loss: 0.2861 - accuracy: 0.8877 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
140/140 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.8882 .9138 - val_loss: 0.7503 - val_accuracy: 0.7765
  1/140 [..............................] - ETA: 16s - loss: 0.4556 - accuracy: 0.8750.8883 - val_loss: 0.6166 - val_accuracy: 0.8030
 25/140 [====>.........................] - ETA: 9s - loss: 0.2897 - accuracy: 0.8923 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
 51/140 [=========>....................] - ETA: 7s - loss: 0.2670 - accuracy: 0.8993 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
 76/140 [===============>..............] - ETA: 5s - loss: 0.2621 - accuracy: 0.9045 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
101/140 [====================>.........] - ETA: 3s - loss: 0.2537 - accuracy: 0.9088 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
127/140 [==========================>...] - ETA: 1s - loss: 0.2461 - accuracy: 0.9119 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
140/140 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9128 .8883 - val_loss: 0.6166 - val_accuracy: 0.8030
  7/140 [>.............................] - ETA: 10s - loss: 0.0811 - accuracy: 0.9828.9129 - val_loss: 0.6197 - val_accuracy: 0.7765
 33/140 [======>.......................] - ETA: 8s - loss: 0.1530 - accuracy: 0.9430 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
 58/140 [===========>..................] - ETA: 6s - loss: 0.1824 - accuracy: 0.9300 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
 85/140 [=================>............] - ETA: 4s - loss: 0.1883 - accuracy: 0.9283 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
111/140 [======================>.......] - ETA: 2s - loss: 0.1910 - accuracy: 0.9274 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
138/140 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9270 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
140/140 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9270 .9129 - val_loss: 0.6197 - val_accuracy: 0.7765
 17/140 [==>...........................] - ETA: 10s - loss: 0.3768 - accuracy: 0.8332.9270 - val_loss: 0.7813 - val_accuracy: 0.7727
 42/140 [========>.....................] - ETA: 7s - loss: 0.3167 - accuracy: 0.8700 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
 66/140 [=============>................] - ETA: 6s - loss: 0.2951 - accuracy: 0.8818 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
 86/140 [=================>............] - ETA: 4s - loss: 0.2849 - accuracy: 0.8876 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
112/140 [=======================>......] - ETA: 2s - loss: 0.2733 - accuracy: 0.8935 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
138/140 [============================>.] - ETA: 0s - loss: 0.2648 - accuracy: 0.8978 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
140/140 [==============================] - ETA: 0s - loss: 0.2643 - accuracy: 0.8980 .9270 - val_loss: 0.7813 - val_accuracy: 0.7727
 17/140 [==>...........................] - ETA: 10s - loss: 0.1497 - accuracy: 0.9400.8981 - val_loss: 0.7180 - val_accuracy: 0.8030
 42/140 [========>.....................] - ETA: 8s - loss: 0.1587 - accuracy: 0.9415 .8981 - val_loss: 0.7180 - val_accuracy: 0.8030
 67/140 [=============>................] - ETA: 5s - loss: 0.1592 - accuracy: 0.9428 .8981 - val_loss: 0.7180 - val_accuracy: 0.8030
 93/140 [==================>...........] - ETA: 3s - loss: 0.1697 - accuracy: 0.9409 .8981 - val_loss: 0.7180 - val_accuracy: 0.8030
119/140 [========================>.....] - ETA: 1s - loss: 0.1822 - accuracy: 0.9372 .8981 - val_loss: 0.7180 - val_accuracy: 0.8030
140/140 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.9330 .8981 - val_loss: 0.7180 - val_accuracy: 0.8030
 23/140 [===>..........................] - ETA: 9s - loss: 0.3201 - accuracy: 0.8742 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
 48/140 [=========>....................] - ETA: 7s - loss: 0.3142 - accuracy: 0.8793 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
 74/140 [==============>...............] - ETA: 5s - loss: 0.3066 - accuracy: 0.8812 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
100/140 [====================>.........] - ETA: 3s - loss: 0.3032 - accuracy: 0.8815 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
126/140 [==========================>...] - ETA: 1s - loss: 0.2978 - accuracy: 0.8833 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
140/140 [==============================] - ETA: 0s - loss: 0.2944 - accuracy: 0.8845 .9329 - val_loss: 0.6654 - val_accuracy: 0.8030
  5/140 [>.............................] - ETA: 10s - loss: 0.2124 - accuracy: 0.9429.8846 - val_loss: 0.6059 - val_accuracy: 0.8371
 30/140 [=====>........................] - ETA: 8s - loss: 0.2148 - accuracy: 0.9178 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
 55/140 [==========>...................] - ETA: 6s - loss: 0.2136 - accuracy: 0.9174 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
 81/140 [================>.............] - ETA: 4s - loss: 0.2084 - accuracy: 0.9192 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
107/140 [=====================>........] - ETA: 2s - loss: 0.2036 - accuracy: 0.9219 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
133/140 [===========================>..] - ETA: 0s - loss: 0.1984 - accuracy: 0.9244 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
140/140 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.9249 .8846 - val_loss: 0.6059 - val_accuracy: 0.8371
 12/140 [=>............................] - ETA: 10s - loss: 0.2331 - accuracy: 0.9167.9249 - val_loss: 0.7710 - val_accuracy: 0.7955
 37/140 [======>.......................] - ETA: 8s - loss: 0.2177 - accuracy: 0.9157 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
 62/140 [============>.................] - ETA: 6s - loss: 0.1988 - accuracy: 0.9243 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
 88/140 [=================>............] - ETA: 4s - loss: 0.1881 - accuracy: 0.9288 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
115/140 [=======================>......] - ETA: 1s - loss: 0.1824 - accuracy: 0.9308 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
139/140 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9312 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
140/140 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.9311 .9249 - val_loss: 0.7710 - val_accuracy: 0.7955
 19/140 [===>..........................] - ETA: 9s - loss: 0.1743 - accuracy: 0.9541 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
 44/140 [========>.....................] - ETA: 7s - loss: 0.1643 - accuracy: 0.9532 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
 69/140 [=============>................] - ETA: 5s - loss: 0.1648 - accuracy: 0.9504 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
 95/140 [===================>..........] - ETA: 3s - loss: 0.1639 - accuracy: 0.9499 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
121/140 [========================>.....] - ETA: 1s - loss: 0.1635 - accuracy: 0.9489 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
140/140 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9476 .9311 - val_loss: 0.6611 - val_accuracy: 0.8106
140/140 [==============================] - 14s 97ms/step - loss: 0.1648 - accuracy: 0.9475 - val_loss: 0.6978 - val_accuracy: 0.8106
 25/140 [====>.........................] - ETA: 9s - loss: 0.0968 - accuracy: 0.9761 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
 51/140 [=========>....................] - ETA: 7s - loss: 0.1366 - accuracy: 0.9555 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
 69/140 [=============>................] - ETA: 5s - loss: 0.1517 - accuracy: 0.9483 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
 96/140 [===================>..........] - ETA: 3s - loss: 0.1640 - accuracy: 0.9427 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
122/140 [=========================>....] - ETA: 1s - loss: 0.1693 - accuracy: 0.9402 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
140/140 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9390 .9475 - val_loss: 0.6978 - val_accuracy: 0.8106
  2/140 [..............................] - ETA: 11s - loss: 0.3497 - accuracy: 0.9062.9389 - val_loss: 0.8738 - val_accuracy: 0.8333
 27/140 [====>.........................] - ETA: 9s - loss: 0.2172 - accuracy: 0.9245 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
 52/140 [==========>...................] - ETA: 7s - loss: 0.1800 - accuracy: 0.9321 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
 77/140 [===============>..............] - ETA: 5s - loss: 0.1794 - accuracy: 0.9321 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
105/140 [=====================>........] - ETA: 2s - loss: 0.1930 - accuracy: 0.9269 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
131/140 [===========================>..] - ETA: 0s - loss: 0.2020 - accuracy: 0.9233 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
140/140 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9223 .9389 - val_loss: 0.8738 - val_accuracy: 0.8333
  8/140 [>.............................] - ETA: 10s - loss: 0.1416 - accuracy: 0.9117.9222 - val_loss: 0.7533 - val_accuracy: 0.7992
 33/140 [======>.......................] - ETA: 8s - loss: 0.1421 - accuracy: 0.9322 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
 58/140 [===========>..................] - ETA: 6s - loss: 0.1403 - accuracy: 0.9371 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
 84/140 [=================>............] - ETA: 4s - loss: 0.1491 - accuracy: 0.9368 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
110/140 [======================>.......] - ETA: 2s - loss: 0.1562 - accuracy: 0.9361 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
136/140 [============================>.] - ETA: 0s - loss: 0.1595 - accuracy: 0.9358 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
140/140 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.9357 .9222 - val_loss: 0.7533 - val_accuracy: 0.7992
 14/140 [==>...........................] - ETA: 10s - loss: 0.1586 - accuracy: 0.9503.9357 - val_loss: 0.7002 - val_accuracy: 0.8068
 39/140 [=======>......................] - ETA: 8s - loss: 0.1631 - accuracy: 0.9471 .9357 - val_loss: 0.7002 - val_accuracy: 0.8068
 64/140 [============>.................] - ETA: 6s - loss: 0.1759 - accuracy: 0.9411 .9357 - val_loss: 0.7002 - val_accuracy: 0.8068
 90/140 [==================>...........] - ETA: 3s - loss: 0.1920 - accuracy: 0.9342 .9357 - val_loss: 0.7002 - val_accuracy: 0.8068
115/140 [=======================>......] - ETA: 1s - loss: 0.1996 - accuracy: 0.9309 .9357 - val_loss: 0.7002 - val_accuracy: 0.8068
140/140 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9282 .9357 - val_loss: 0.7002 - val_accuracy: 0.8068
 19/140 [===>..........................] - ETA: 9s - loss: 0.0914 - accuracy: 0.9912 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
 45/140 [========>.....................] - ETA: 7s - loss: 0.1191 - accuracy: 0.9781 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
 70/140 [==============>...............] - ETA: 5s - loss: 0.1284 - accuracy: 0.9725 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
 97/140 [===================>..........] - ETA: 3s - loss: 0.1298 - accuracy: 0.9690 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
123/140 [=========================>....] - ETA: 1s - loss: 0.1307 - accuracy: 0.9668 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
140/140 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9646 .9282 - val_loss: 0.6440 - val_accuracy: 0.8106
  2/140 [..............................] - ETA: 11s - loss: 0.1160 - accuracy: 1.0000.9644 - val_loss: 0.7163 - val_accuracy: 0.7917
 28/140 [=====>........................] - ETA: 8s - loss: 0.1015 - accuracy: 0.9694 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
 54/140 [==========>...................] - ETA: 6s - loss: 0.1030 - accuracy: 0.9660 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
 78/140 [===============>..............] - ETA: 4s - loss: 0.1060 - accuracy: 0.9637 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
104/140 [=====================>........] - ETA: 2s - loss: 0.1111 - accuracy: 0.9613 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
130/140 [==========================>...] - ETA: 0s - loss: 0.1154 - accuracy: 0.9600 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
140/140 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.9594 .9644 - val_loss: 0.7163 - val_accuracy: 0.7917
 10/140 [=>............................] - ETA: 10s - loss: 0.0836 - accuracy: 0.9894.9594 - val_loss: 0.7531 - val_accuracy: 0.8144
