2022-06-23 00:31:06.466883: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 00:31:06.468121: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 00:31:06.510080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 00:31:06.510440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 00:31:06.510460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 00:31:06.512769: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 00:31:06.512821: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 00:31:06.514913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 00:31:06.515369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 00:31:06.517567: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 00:31:06.518752: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 00:31:06.523074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 00:31:06.524421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 00:31:06.524833: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 00:31:06.524917: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 00:31:06.750720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 00:31:06.751004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 00:31:06.751029: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 00:31:06.751058: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 00:31:06.751071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 00:31:06.751082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 00:31:06.751096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 00:31:06.751106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 00:31:06.751116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 00:31:06.751128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 00:31:06.751871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 00:31:06.751898: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 00:31:07.484322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 00:31:07.484362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 00:31:07.484375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 00:31:07.484380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 00:31:07.485413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 00:31:07.486452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 00:31:07.718630: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 00:31:07.719099: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 00:31:08.265605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 00:31:08.458834: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 00:31:09.043835: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 00:31:09.079522: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0245s vs `on_train_batch_end` time: 0.0280s). Check your callbacks.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 128)     3584
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 128)     0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 128)     0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 16)      18448
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 16)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 16)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 32)      4640
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 32)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 32)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 32)        9248
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 32)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 32)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 32)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 132
=================================================================
Total params: 36,052
Trainable params: 36,052
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100







280/280 [==============================] - 23s 63ms/step - loss: 1.3909 - accuracy: 0.2310 - val_loss: 1.3027 - val_accuracy: 0.2727
Epoch 2/100







280/280 [==============================] - 17s 62ms/step - loss: 1.3319 - accuracy: 0.2898 - val_loss: 1.3053 - val_accuracy: 0.3712
Epoch 3/100







280/280 [==============================] - 17s 61ms/step - loss: 1.2858 - accuracy: 0.3527 - val_loss: 1.1510 - val_accuracy: 0.5644
Epoch 4/100








280/280 [==============================] - 17s 62ms/step - loss: 1.1479 - accuracy: 0.5054 - val_loss: 1.0298 - val_accuracy: 0.5909
Epoch 5/100







280/280 [==============================] - 17s 62ms/step - loss: 1.0426 - accuracy: 0.5658 - val_loss: 0.9237 - val_accuracy: 0.6061
Epoch 6/100







280/280 [==============================] - 17s 62ms/step - loss: 0.9630 - accuracy: 0.6127 - val_loss: 0.8358 - val_accuracy: 0.6856
Epoch 7/100








280/280 [==============================] - 17s 61ms/step - loss: 0.9815 - accuracy: 0.6151 - val_loss: 0.8332 - val_accuracy: 0.6970
Epoch 8/100







280/280 [==============================] - 17s 61ms/step - loss: 0.8448 - accuracy: 0.6775 - val_loss: 0.7995 - val_accuracy: 0.6818
Epoch 9/100








280/280 [==============================] - 17s 61ms/step - loss: 0.8462 - accuracy: 0.6711 - val_loss: 0.8053 - val_accuracy: 0.6742
Epoch 10/100







280/280 [==============================] - 17s 61ms/step - loss: 0.8045 - accuracy: 0.6840 - val_loss: 0.8644 - val_accuracy: 0.6477
Epoch 11/100







280/280 [==============================] - 17s 62ms/step - loss: 0.8160 - accuracy: 0.7032 - val_loss: 0.7558 - val_accuracy: 0.6856
Epoch 12/100








280/280 [==============================] - 17s 61ms/step - loss: 0.8115 - accuracy: 0.6861 - val_loss: 0.7816 - val_accuracy: 0.6553
Epoch 13/100







280/280 [==============================] - 17s 62ms/step - loss: 0.7396 - accuracy: 0.7229 - val_loss: 0.7846 - val_accuracy: 0.6667
Epoch 14/100







280/280 [==============================] - 17s 62ms/step - loss: 0.8062 - accuracy: 0.6859 - val_loss: 0.7683 - val_accuracy: 0.7121
Epoch 15/100








280/280 [==============================] - 17s 62ms/step - loss: 0.7628 - accuracy: 0.6984 - val_loss: 0.7896 - val_accuracy: 0.7083
Epoch 16/100







280/280 [==============================] - 17s 62ms/step - loss: 0.7274 - accuracy: 0.7255 - val_loss: 0.7209 - val_accuracy: 0.6932
Epoch 17/100







280/280 [==============================] - 17s 61ms/step - loss: 0.7025 - accuracy: 0.7327 - val_loss: 0.7717 - val_accuracy: 0.7121
Epoch 18/100








280/280 [==============================] - 17s 62ms/step - loss: 0.7577 - accuracy: 0.6876 - val_loss: 0.7269 - val_accuracy: 0.7083
Epoch 19/100







280/280 [==============================] - 17s 61ms/step - loss: 0.7469 - accuracy: 0.7071 - val_loss: 0.8549 - val_accuracy: 0.6705
Epoch 20/100








280/280 [==============================] - 17s 61ms/step - loss: 0.7295 - accuracy: 0.7187 - val_loss: 0.6484 - val_accuracy: 0.7311
Epoch 21/100







280/280 [==============================] - 17s 62ms/step - loss: 0.6649 - accuracy: 0.7268 - val_loss: 0.8001 - val_accuracy: 0.6780
Epoch 22/100








280/280 [==============================] - 17s 61ms/step - loss: 0.7354 - accuracy: 0.6922 - val_loss: 0.8326 - val_accuracy: 0.7083
Epoch 23/100







280/280 [==============================] - 17s 61ms/step - loss: 0.7053 - accuracy: 0.7211 - val_loss: 0.6911 - val_accuracy: 0.7348
Epoch 24/100







280/280 [==============================] - 17s 62ms/step - loss: 0.6864 - accuracy: 0.7263 - val_loss: 0.6583 - val_accuracy: 0.7273
Epoch 25/100








280/280 [==============================] - 17s 62ms/step - loss: 0.7058 - accuracy: 0.7113 - val_loss: 0.5805 - val_accuracy: 0.7538
Epoch 26/100







280/280 [==============================] - 17s 61ms/step - loss: 0.6754 - accuracy: 0.7429 - val_loss: 0.6772 - val_accuracy: 0.7235
Epoch 27/100







280/280 [==============================] - 17s 61ms/step - loss: 0.6527 - accuracy: 0.7388 - val_loss: 0.5872 - val_accuracy: 0.7879
Epoch 28/100








280/280 [==============================] - 17s 61ms/step - loss: 0.6113 - accuracy: 0.7595 - val_loss: 0.5943 - val_accuracy: 0.7614
Epoch 29/100







280/280 [==============================] - 17s 62ms/step - loss: 0.6416 - accuracy: 0.7450 - val_loss: 0.6370 - val_accuracy: 0.7538
Epoch 30/100
 40/280 [===>..........................] - ETA: 12s - loss: 0.6050 - accuracy: 0.7561
 79/280 [=======>......................] - ETA: 10s - loss: 0.6220 - accuracy: 0.7552
118/280 [===========>..................] - ETA: 8s - loss: 0.6217 - accuracy: 0.7609
156/280 [===============>..............] - ETA: 6s - loss: 0.6192 - accuracy: 0.7643
195/280 [===================>..........] - ETA: 4s - loss: 0.6151 - accuracy: 0.7679
233/280 [=======================>......] - ETA: 2s - loss: 0.6145 - accuracy: 0.7702
272/280 [============================>.] - ETA: 0s - loss: 0.6154 - accuracy: 0.7709
279/280 [============================>.] - ETA: 0s - loss: 0.6157 - accuracy: 0.7709
 21/280 [=>............................] - ETA: 13s - loss: 0.6400 - accuracy: 0.6854.7709 - val_loss: 0.7131 - val_accuracy: 0.6894
 59/280 [=====>........................] - ETA: 11s - loss: 0.6572 - accuracy: 0.7143.7709 - val_loss: 0.7131 - val_accuracy: 0.6894
 97/280 [=========>....................] - ETA: 9s - loss: 0.6543 - accuracy: 0.7276 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
136/280 [=============>................] - ETA: 7s - loss: 0.6464 - accuracy: 0.7354 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
174/280 [=================>............] - ETA: 5s - loss: 0.6394 - accuracy: 0.7403 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
214/280 [=====================>........] - ETA: 3s - loss: 0.6333 - accuracy: 0.7444 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
242/280 [========================>.....] - ETA: 1s - loss: 0.6300 - accuracy: 0.7470 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
280/280 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.7501 .7709 - val_loss: 0.7131 - val_accuracy: 0.6894
 30/280 [==>...........................] - ETA: 13s - loss: 0.5933 - accuracy: 0.8216.7502 - val_loss: 0.6706 - val_accuracy: 0.7538
 67/280 [======>.......................] - ETA: 11s - loss: 0.5954 - accuracy: 0.7958.7502 - val_loss: 0.6706 - val_accuracy: 0.7538
106/280 [==========>...................] - ETA: 9s - loss: 0.5992 - accuracy: 0.7896 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
143/280 [==============>...............] - ETA: 7s - loss: 0.5995 - accuracy: 0.7881 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
182/280 [==================>...........] - ETA: 5s - loss: 0.5974 - accuracy: 0.7870 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
219/280 [======================>.......] - ETA: 3s - loss: 0.5988 - accuracy: 0.7848 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
258/280 [==========================>...] - ETA: 1s - loss: 0.6016 - accuracy: 0.7812 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
279/280 [============================>.] - ETA: 0s - loss: 0.6033 - accuracy: 0.7793 .7502 - val_loss: 0.6706 - val_accuracy: 0.7538
  6/280 [..............................] - ETA: 14s - loss: 0.5664 - accuracy: 0.7757.7791 - val_loss: 0.7007 - val_accuracy: 0.7424
 46/280 [===>..........................] - ETA: 12s - loss: 0.6222 - accuracy: 0.7783.7791 - val_loss: 0.7007 - val_accuracy: 0.7424
 84/280 [========>.....................] - ETA: 10s - loss: 0.6177 - accuracy: 0.7756.7791 - val_loss: 0.7007 - val_accuracy: 0.7424
122/280 [============>.................] - ETA: 8s - loss: 0.6212 - accuracy: 0.7726 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
161/280 [================>.............] - ETA: 6s - loss: 0.6227 - accuracy: 0.7695 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
200/280 [====================>.........] - ETA: 4s - loss: 0.6234 - accuracy: 0.7678 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
238/280 [========================>.....] - ETA: 2s - loss: 0.6220 - accuracy: 0.7673 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
276/280 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.7659 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
279/280 [============================>.] - ETA: 0s - loss: 0.6220 - accuracy: 0.7658 .7791 - val_loss: 0.7007 - val_accuracy: 0.7424
 25/280 [=>............................] - ETA: 13s - loss: 0.4935 - accuracy: 0.7872.7657 - val_loss: 0.5837 - val_accuracy: 0.7689
 63/280 [=====>........................] - ETA: 11s - loss: 0.5131 - accuracy: 0.7872.7657 - val_loss: 0.5837 - val_accuracy: 0.7689
102/280 [=========>....................] - ETA: 9s - loss: 0.5341 - accuracy: 0.7733 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
140/280 [==============>...............] - ETA: 7s - loss: 0.5528 - accuracy: 0.7668 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
179/280 [==================>...........] - ETA: 5s - loss: 0.5613 - accuracy: 0.7653 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
217/280 [======================>.......] - ETA: 3s - loss: 0.5641 - accuracy: 0.7650 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
255/280 [==========================>...] - ETA: 1s - loss: 0.5672 - accuracy: 0.7645 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
279/280 [============================>.] - ETA: 0s - loss: 0.5684 - accuracy: 0.7646 .7657 - val_loss: 0.5837 - val_accuracy: 0.7689
  2/280 [..............................] - ETA: 14s - loss: 0.4004 - accuracy: 0.7500.7646 - val_loss: 0.5684 - val_accuracy: 0.7689
 40/280 [===>..........................] - ETA: 12s - loss: 0.5688 - accuracy: 0.7345.7646 - val_loss: 0.5684 - val_accuracy: 0.7689
 68/280 [======>.......................] - ETA: 11s - loss: 0.5460 - accuracy: 0.7650.7646 - val_loss: 0.5684 - val_accuracy: 0.7689
105/280 [==========>...................] - ETA: 9s - loss: 0.5321 - accuracy: 0.7825 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
145/280 [==============>...............] - ETA: 7s - loss: 0.5362 - accuracy: 0.7858 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
184/280 [==================>...........] - ETA: 5s - loss: 0.5438 - accuracy: 0.7852 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
223/280 [======================>.......] - ETA: 3s - loss: 0.5501 - accuracy: 0.7840 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
262/280 [===========================>..] - ETA: 0s - loss: 0.5577 - accuracy: 0.7818 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
279/280 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.7812 .7646 - val_loss: 0.5684 - val_accuracy: 0.7689
 10/280 [>.............................] - ETA: 14s - loss: 0.3837 - accuracy: 0.9156.7812 - val_loss: 0.6338 - val_accuracy: 0.7538
 48/280 [====>.........................] - ETA: 12s - loss: 0.5517 - accuracy: 0.7991.7812 - val_loss: 0.6338 - val_accuracy: 0.7538
 87/280 [========>.....................] - ETA: 10s - loss: 0.5767 - accuracy: 0.7872.7812 - val_loss: 0.6338 - val_accuracy: 0.7538
125/280 [============>.................] - ETA: 8s - loss: 0.5803 - accuracy: 0.7860 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
162/280 [================>.............] - ETA: 6s - loss: 0.5833 - accuracy: 0.7834 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
202/280 [====================>.........] - ETA: 4s - loss: 0.5839 - accuracy: 0.7810 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
241/280 [========================>.....] - ETA: 2s - loss: 0.5857 - accuracy: 0.7790 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
278/280 [============================>.] - ETA: 0s - loss: 0.5863 - accuracy: 0.7784 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
280/280 [==============================] - ETA: 0s - loss: 0.5863 - accuracy: 0.7783 .7812 - val_loss: 0.6338 - val_accuracy: 0.7538
 27/280 [=>............................] - ETA: 13s - loss: 0.6436 - accuracy: 0.7310.7783 - val_loss: 0.5316 - val_accuracy: 0.7765
 66/280 [======>.......................] - ETA: 11s - loss: 0.6224 - accuracy: 0.7437.7783 - val_loss: 0.5316 - val_accuracy: 0.7765
103/280 [==========>...................] - ETA: 9s - loss: 0.6158 - accuracy: 0.7489 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
143/280 [==============>...............] - ETA: 7s - loss: 0.6097 - accuracy: 0.7531 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
181/280 [==================>...........] - ETA: 5s - loss: 0.6017 - accuracy: 0.7587 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
218/280 [======================>.......] - ETA: 3s - loss: 0.5994 - accuracy: 0.7618 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
258/280 [==========================>...] - ETA: 1s - loss: 0.5959 - accuracy: 0.7651 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
279/280 [============================>.] - ETA: 0s - loss: 0.5950 - accuracy: 0.7661 .7783 - val_loss: 0.5316 - val_accuracy: 0.7765
  7/280 [..............................] - ETA: 14s - loss: 0.4404 - accuracy: 0.7320.7662 - val_loss: 0.6380 - val_accuracy: 0.7424
 45/280 [===>..........................] - ETA: 12s - loss: 0.5920 - accuracy: 0.7326.7662 - val_loss: 0.6380 - val_accuracy: 0.7424
 73/280 [======>.......................] - ETA: 11s - loss: 0.5716 - accuracy: 0.7528.7662 - val_loss: 0.6380 - val_accuracy: 0.7424
111/280 [==========>...................] - ETA: 9s - loss: 0.5568 - accuracy: 0.7671 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
149/280 [==============>...............] - ETA: 6s - loss: 0.5552 - accuracy: 0.7730 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
188/280 [===================>..........] - ETA: 4s - loss: 0.5586 - accuracy: 0.7738 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
226/280 [=======================>......] - ETA: 2s - loss: 0.5610 - accuracy: 0.7747 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
264/280 [===========================>..] - ETA: 0s - loss: 0.5621 - accuracy: 0.7755 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
279/280 [============================>.] - ETA: 0s - loss: 0.5627 - accuracy: 0.7757 .7662 - val_loss: 0.6380 - val_accuracy: 0.7424
 14/280 [>.............................] - ETA: 13s - loss: 0.4233 - accuracy: 0.8285.7758 - val_loss: 0.5269 - val_accuracy: 0.7917
 53/280 [====>.........................] - ETA: 11s - loss: 0.4335 - accuracy: 0.8269.7758 - val_loss: 0.5269 - val_accuracy: 0.7917
 91/280 [========>.....................] - ETA: 9s - loss: 0.4668 - accuracy: 0.8150 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
128/280 [============>.................] - ETA: 8s - loss: 0.4994 - accuracy: 0.8043 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
167/280 [================>.............] - ETA: 5s - loss: 0.5144 - accuracy: 0.8002 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
205/280 [====================>.........] - ETA: 3s - loss: 0.5272 - accuracy: 0.7961 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
243/280 [=========================>....] - ETA: 1s - loss: 0.5351 - accuracy: 0.7932 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
279/280 [============================>.] - ETA: 0s - loss: 0.5400 - accuracy: 0.7913 .7758 - val_loss: 0.5269 - val_accuracy: 0.7917
 30/280 [==>...........................] - ETA: 13s - loss: 0.6048 - accuracy: 0.8083.7912 - val_loss: 0.5629 - val_accuracy: 0.7955
 67/280 [======>.......................] - ETA: 11s - loss: 0.6325 - accuracy: 0.7969.7912 - val_loss: 0.5629 - val_accuracy: 0.7955
106/280 [==========>...................] - ETA: 9s - loss: 0.6374 - accuracy: 0.7895 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
143/280 [==============>...............] - ETA: 7s - loss: 0.6375 - accuracy: 0.7843 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
182/280 [==================>...........] - ETA: 5s - loss: 0.6295 - accuracy: 0.7851 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
219/280 [======================>.......] - ETA: 3s - loss: 0.6229 - accuracy: 0.7854 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
259/280 [==========================>...] - ETA: 1s - loss: 0.6174 - accuracy: 0.7854 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
279/280 [============================>.] - ETA: 0s - loss: 0.6151 - accuracy: 0.7853 .7912 - val_loss: 0.5629 - val_accuracy: 0.7955
  5/280 [..............................] - ETA: 15s - loss: 0.8778 - accuracy: 0.6683.7853 - val_loss: 0.7343 - val_accuracy: 0.7008
 44/280 [===>..........................] - ETA: 12s - loss: 0.6238 - accuracy: 0.7933.7853 - val_loss: 0.7343 - val_accuracy: 0.7008
 83/280 [=======>......................] - ETA: 10s - loss: 0.5976 - accuracy: 0.7957.7853 - val_loss: 0.7343 - val_accuracy: 0.7008
122/280 [============>.................] - ETA: 8s - loss: 0.5927 - accuracy: 0.7920 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
159/280 [================>.............] - ETA: 6s - loss: 0.5880 - accuracy: 0.7914 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
199/280 [====================>.........] - ETA: 4s - loss: 0.5847 - accuracy: 0.7907 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
237/280 [========================>.....] - ETA: 2s - loss: 0.5830 - accuracy: 0.7900 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
275/280 [============================>.] - ETA: 0s - loss: 0.5826 - accuracy: 0.7892 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
279/280 [============================>.] - ETA: 0s - loss: 0.5825 - accuracy: 0.7891 .7853 - val_loss: 0.7343 - val_accuracy: 0.7008
 15/280 [>.............................] - ETA: 13s - loss: 0.5687 - accuracy: 0.7500.7891 - val_loss: 0.5902 - val_accuracy: 0.7765
 53/280 [====>.........................] - ETA: 11s - loss: 0.5672 - accuracy: 0.7779.7891 - val_loss: 0.5902 - val_accuracy: 0.7765
 91/280 [========>.....................] - ETA: 10s - loss: 0.5739 - accuracy: 0.7807.7891 - val_loss: 0.5902 - val_accuracy: 0.7765
129/280 [============>.................] - ETA: 8s - loss: 0.5802 - accuracy: 0.7791 .7891 - val_loss: 0.5902 - val_accuracy: 0.7765
168/280 [=================>............] - ETA: 5s - loss: 0.5822 - accuracy: 0.7775 .7891 - val_loss: 0.5902 - val_accuracy: 0.7765
206/280 [=====================>........] - ETA: 3s - loss: 0.5811 - accuracy: 0.7775 .7891 - val_loss: 0.5902 - val_accuracy: 0.7765
244/280 [=========================>....] - ETA: 1s - loss: 0.5809 - accuracy: 0.7772 .7891 - val_loss: 0.5902 - val_accuracy: 0.7765
279/280 [============================>.] - ETA: 0s - loss: 0.5795 - accuracy: 0.7776 .7891 - val_loss: 0.5902 - val_accuracy: 0.7765
 31/280 [==>...........................] - ETA: 13s - loss: 0.4719 - accuracy: 0.8201.7776 - val_loss: 0.5691 - val_accuracy: 0.7803
 70/280 [======>.......................] - ETA: 11s - loss: 0.4995 - accuracy: 0.8013.7776 - val_loss: 0.5691 - val_accuracy: 0.7803
109/280 [==========>...................] - ETA: 9s - loss: 0.5095 - accuracy: 0.7958 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
146/280 [==============>...............] - ETA: 7s - loss: 0.5174 - accuracy: 0.7922 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
185/280 [==================>...........] - ETA: 5s - loss: 0.5211 - accuracy: 0.7914 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
222/280 [======================>.......] - ETA: 3s - loss: 0.5244 - accuracy: 0.7905 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
261/280 [==========================>...] - ETA: 1s - loss: 0.5281 - accuracy: 0.7893 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
279/280 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7887 .7776 - val_loss: 0.5691 - val_accuracy: 0.7803
 11/280 [>.............................] - ETA: 13s - loss: 0.6233 - accuracy: 0.8409.7887 - val_loss: 0.6651 - val_accuracy: 0.7197
 50/280 [====>.........................] - ETA: 12s - loss: 0.5450 - accuracy: 0.8151.7887 - val_loss: 0.6651 - val_accuracy: 0.7197
 88/280 [========>.....................] - ETA: 10s - loss: 0.5198 - accuracy: 0.8151.7887 - val_loss: 0.6651 - val_accuracy: 0.7197
126/280 [============>.................] - ETA: 8s - loss: 0.5182 - accuracy: 0.8127 .7887 - val_loss: 0.6651 - val_accuracy: 0.7197
163/280 [================>.............] - ETA: 6s - loss: 0.5208 - accuracy: 0.8104 .7887 - val_loss: 0.6651 - val_accuracy: 0.7197
203/280 [====================>.........] - ETA: 4s - loss: 0.5240 - accuracy: 0.8084 .7887 - val_loss: 0.6651 - val_accuracy: 0.7197
242/280 [========================>.....] - ETA: 2s - loss: 0.5285 - accuracy: 0.8064 .7887 - val_loss: 0.6651 - val_accuracy: 0.7197
279/280 [============================>.] - ETA: 0s - loss: 0.5315 - accuracy: 0.8049 .7887 - val_loss: 0.6651 - val_accuracy: 0.7197
 29/280 [==>...........................] - ETA: 13s - loss: 0.5501 - accuracy: 0.8097.8049 - val_loss: 0.5409 - val_accuracy: 0.7614
 68/280 [======>.......................] - ETA: 11s - loss: 0.5429 - accuracy: 0.8186.8049 - val_loss: 0.5409 - val_accuracy: 0.7614
106/280 [==========>...................] - ETA: 9s - loss: 0.5384 - accuracy: 0.8189 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
135/280 [=============>................] - ETA: 7s - loss: 0.5364 - accuracy: 0.8193 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
173/280 [=================>............] - ETA: 5s - loss: 0.5336 - accuracy: 0.8179 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
211/280 [=====================>........] - ETA: 3s - loss: 0.5336 - accuracy: 0.8157 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
250/280 [=========================>....] - ETA: 1s - loss: 0.5345 - accuracy: 0.8132 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
279/280 [============================>.] - ETA: 0s - loss: 0.5353 - accuracy: 0.8116 .8049 - val_loss: 0.5409 - val_accuracy: 0.7614
280/280 [==============================] - 17s 61ms/step - loss: 0.5354 - accuracy: 0.8115 - val_loss: 0.7236 - val_accuracy: 0.7159
 39/280 [===>..........................] - ETA: 12s - loss: 0.5802 - accuracy: 0.8112.8115 - val_loss: 0.7236 - val_accuracy: 0.7159
 78/280 [=======>......................] - ETA: 10s - loss: 0.5601 - accuracy: 0.8055.8115 - val_loss: 0.7236 - val_accuracy: 0.7159
116/280 [===========>..................] - ETA: 8s - loss: 0.5528 - accuracy: 0.8042 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
153/280 [===============>..............] - ETA: 6s - loss: 0.5464 - accuracy: 0.8035 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
193/280 [===================>..........] - ETA: 4s - loss: 0.5451 - accuracy: 0.8022 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
230/280 [=======================>......] - ETA: 2s - loss: 0.5466 - accuracy: 0.8006 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
269/280 [===========================>..] - ETA: 0s - loss: 0.5469 - accuracy: 0.7994 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
280/280 [==============================] - ETA: 0s - loss: 0.5470 - accuracy: 0.7992 .8115 - val_loss: 0.7236 - val_accuracy: 0.7159
 19/280 [=>............................] - ETA: 13s - loss: 0.4044 - accuracy: 0.8765.7991 - val_loss: 0.7313 - val_accuracy: 0.7386
 57/280 [=====>........................] - ETA: 11s - loss: 0.4646 - accuracy: 0.8355.7991 - val_loss: 0.7313 - val_accuracy: 0.7386
 96/280 [=========>....................] - ETA: 9s - loss: 0.5011 - accuracy: 0.8177 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
133/280 [=============>................] - ETA: 7s - loss: 0.5146 - accuracy: 0.8106 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
171/280 [=================>............] - ETA: 5s - loss: 0.5197 - accuracy: 0.8077 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
209/280 [=====================>........] - ETA: 3s - loss: 0.5232 - accuracy: 0.8062 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
248/280 [=========================>....] - ETA: 1s - loss: 0.5232 - accuracy: 0.8060 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
280/280 [==============================] - ETA: 0s - loss: 0.5256 - accuracy: 0.8048 .7991 - val_loss: 0.7313 - val_accuracy: 0.7386
 35/280 [==>...........................] - ETA: 12s - loss: 0.4645 - accuracy: 0.8147.8048 - val_loss: 0.5372 - val_accuracy: 0.7992
 73/280 [======>.......................] - ETA: 10s - loss: 0.4649 - accuracy: 0.8171.8048 - val_loss: 0.5372 - val_accuracy: 0.7992
111/280 [==========>...................] - ETA: 8s - loss: 0.4811 - accuracy: 0.8106 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
150/280 [===============>..............] - ETA: 6s - loss: 0.4943 - accuracy: 0.8073 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
189/280 [===================>..........] - ETA: 4s - loss: 0.5022 - accuracy: 0.8049 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
226/280 [=======================>......] - ETA: 2s - loss: 0.5065 - accuracy: 0.8038 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
265/280 [===========================>..] - ETA: 0s - loss: 0.5084 - accuracy: 0.8033 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
279/280 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.8031 .8048 - val_loss: 0.5372 - val_accuracy: 0.7992
  4/280 [..............................] - ETA: 14s - loss: 0.7685 - accuracy: 0.6823.8030 - val_loss: 0.6006 - val_accuracy: 0.7689
 43/280 [===>..........................] - ETA: 12s - loss: 0.6364 - accuracy: 0.7829.8030 - val_loss: 0.6006 - val_accuracy: 0.7689
 82/280 [=======>......................] - ETA: 10s - loss: 0.6131 - accuracy: 0.7840.8030 - val_loss: 0.6006 - val_accuracy: 0.7689
119/280 [===========>..................] - ETA: 8s - loss: 0.6047 - accuracy: 0.7844 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
158/280 [===============>..............] - ETA: 6s - loss: 0.6008 - accuracy: 0.7848 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
197/280 [====================>.........] - ETA: 4s - loss: 0.5945 - accuracy: 0.7868 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
236/280 [========================>.....] - ETA: 2s - loss: 0.5877 - accuracy: 0.7893 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
273/280 [============================>.] - ETA: 0s - loss: 0.5843 - accuracy: 0.7905 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
279/280 [============================>.] - ETA: 0s - loss: 0.5839 - accuracy: 0.7906 .8030 - val_loss: 0.6006 - val_accuracy: 0.7689
 23/280 [=>............................] - ETA: 13s - loss: 0.5899 - accuracy: 0.8033.7907 - val_loss: 0.7566 - val_accuracy: 0.7197
 60/280 [=====>........................] - ETA: 11s - loss: 0.5343 - accuracy: 0.8219.7907 - val_loss: 0.7566 - val_accuracy: 0.7197
 99/280 [=========>....................] - ETA: 9s - loss: 0.5232 - accuracy: 0.8213 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
137/280 [=============>................] - ETA: 7s - loss: 0.5282 - accuracy: 0.8166 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
175/280 [=================>............] - ETA: 5s - loss: 0.5364 - accuracy: 0.8102 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
212/280 [=====================>........] - ETA: 3s - loss: 0.5391 - accuracy: 0.8076 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
252/280 [==========================>...] - ETA: 1s - loss: 0.5397 - accuracy: 0.8060 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
280/280 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8054 .7907 - val_loss: 0.7566 - val_accuracy: 0.7197
  1/280 [..............................] - ETA: 25s - loss: 0.2877 - accuracy: 1.0000.8054 - val_loss: 0.5379 - val_accuracy: 0.7917
 38/280 [===>..........................] - ETA: 12s - loss: 0.4687 - accuracy: 0.8408.8054 - val_loss: 0.5379 - val_accuracy: 0.7917
 78/280 [=======>......................] - ETA: 10s - loss: 0.4803 - accuracy: 0.8204.8054 - val_loss: 0.5379 - val_accuracy: 0.7917
115/280 [===========>..................] - ETA: 8s - loss: 0.4821 - accuracy: 0.8148 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
154/280 [===============>..............] - ETA: 6s - loss: 0.4835 - accuracy: 0.8121 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
192/280 [===================>..........] - ETA: 4s - loss: 0.4908 - accuracy: 0.8073 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
230/280 [=======================>......] - ETA: 2s - loss: 0.4937 - accuracy: 0.8053 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
268/280 [===========================>..] - ETA: 0s - loss: 0.4966 - accuracy: 0.8044 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
279/280 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.8043 .8054 - val_loss: 0.5379 - val_accuracy: 0.7917
 19/280 [=>............................] - ETA: 13s - loss: 0.6682 - accuracy: 0.7188.8043 - val_loss: 0.6229 - val_accuracy: 0.7652
 56/280 [=====>........................] - ETA: 11s - loss: 0.6188 - accuracy: 0.7491.8043 - val_loss: 0.6229 - val_accuracy: 0.7652
 86/280 [========>.....................] - ETA: 10s - loss: 0.6062 - accuracy: 0.7539.8043 - val_loss: 0.6229 - val_accuracy: 0.7652
124/280 [============>.................] - ETA: 8s - loss: 0.6044 - accuracy: 0.7543 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
163/280 [================>.............] - ETA: 6s - loss: 0.5954 - accuracy: 0.7595 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
201/280 [====================>.........] - ETA: 4s - loss: 0.5888 - accuracy: 0.7633 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
240/280 [========================>.....] - ETA: 2s - loss: 0.5807 - accuracy: 0.7676 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
278/280 [============================>.] - ETA: 0s - loss: 0.5730 - accuracy: 0.7718 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
280/280 [==============================] - ETA: 0s - loss: 0.5727 - accuracy: 0.7720 .8043 - val_loss: 0.6229 - val_accuracy: 0.7652
 28/280 [==>...........................] - ETA: 13s - loss: 0.6296 - accuracy: 0.7667.7721 - val_loss: 0.7594 - val_accuracy: 0.7462
 66/280 [======>.......................] - ETA: 11s - loss: 0.5916 - accuracy: 0.7779.7721 - val_loss: 0.7594 - val_accuracy: 0.7462
105/280 [==========>...................] - ETA: 9s - loss: 0.5635 - accuracy: 0.7857 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
143/280 [==============>...............] - ETA: 7s - loss: 0.5397 - accuracy: 0.7909 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
181/280 [==================>...........] - ETA: 5s - loss: 0.5280 - accuracy: 0.7927 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
219/280 [======================>.......] - ETA: 3s - loss: 0.5252 - accuracy: 0.7922 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
258/280 [==========================>...] - ETA: 1s - loss: 0.5239 - accuracy: 0.7920 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
280/280 [==============================] - ETA: 0s - loss: 0.5231 - accuracy: 0.7920 .7721 - val_loss: 0.7594 - val_accuracy: 0.7462
  7/280 [..............................] - ETA: 14s - loss: 0.5008 - accuracy: 0.7768.7920 - val_loss: 0.5960 - val_accuracy: 0.7765
 45/280 [===>..........................] - ETA: 12s - loss: 0.4829 - accuracy: 0.8002.7920 - val_loss: 0.5960 - val_accuracy: 0.7765
 84/280 [========>.....................] - ETA: 10s - loss: 0.5082 - accuracy: 0.7891.7920 - val_loss: 0.5960 - val_accuracy: 0.7765
122/280 [============>.................] - ETA: 8s - loss: 0.5120 - accuracy: 0.7885 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
160/280 [================>.............] - ETA: 6s - loss: 0.5070 - accuracy: 0.7933 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
199/280 [====================>.........] - ETA: 4s - loss: 0.5057 - accuracy: 0.7955 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
236/280 [========================>.....] - ETA: 2s - loss: 0.5055 - accuracy: 0.7969 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
276/280 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.7976 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
279/280 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.7977 .7920 - val_loss: 0.5960 - val_accuracy: 0.7765
 26/280 [=>............................] - ETA: 13s - loss: 0.4616 - accuracy: 0.8602.7977 - val_loss: 0.5366 - val_accuracy: 0.7879
 63/280 [=====>........................] - ETA: 11s - loss: 0.4613 - accuracy: 0.8523.7977 - val_loss: 0.5366 - val_accuracy: 0.7879
101/280 [=========>....................] - ETA: 9s - loss: 0.4800 - accuracy: 0.8477 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
140/280 [==============>...............] - ETA: 7s - loss: 0.4854 - accuracy: 0.8436 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
179/280 [==================>...........] - ETA: 5s - loss: 0.4926 - accuracy: 0.8379 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
217/280 [======================>.......] - ETA: 3s - loss: 0.4975 - accuracy: 0.8340 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
255/280 [==========================>...] - ETA: 1s - loss: 0.5007 - accuracy: 0.8306 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
280/280 [==============================] - ETA: 0s - loss: 0.5022 - accuracy: 0.8287 .7977 - val_loss: 0.5366 - val_accuracy: 0.7879
  3/280 [..............................] - ETA: 14s - loss: 0.6391 - accuracy: 0.7778.8286 - val_loss: 0.5988 - val_accuracy: 0.7652
 41/280 [===>..........................] - ETA: 12s - loss: 0.4887 - accuracy: 0.8132.8286 - val_loss: 0.5988 - val_accuracy: 0.7652
 70/280 [======>.......................] - ETA: 11s - loss: 0.4695 - accuracy: 0.8149.8286 - val_loss: 0.5988 - val_accuracy: 0.7652
108/280 [==========>...................] - ETA: 9s - loss: 0.4747 - accuracy: 0.8137 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
145/280 [==============>...............] - ETA: 7s - loss: 0.4848 - accuracy: 0.8105 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
183/280 [==================>...........] - ETA: 5s - loss: 0.4920 - accuracy: 0.8088 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
223/280 [======================>.......] - ETA: 3s - loss: 0.4970 - accuracy: 0.8074 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
260/280 [==========================>...] - ETA: 1s - loss: 0.4989 - accuracy: 0.8068 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
279/280 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.8067 .8286 - val_loss: 0.5988 - val_accuracy: 0.7652
  9/280 [..............................] - ETA: 14s - loss: 0.3572 - accuracy: 0.8940.8066 - val_loss: 0.5385 - val_accuracy: 0.8030
 48/280 [====>.........................] - ETA: 12s - loss: 0.4204 - accuracy: 0.8621.8066 - val_loss: 0.5385 - val_accuracy: 0.8030
 85/280 [========>.....................] - ETA: 10s - loss: 0.4282 - accuracy: 0.8549.8066 - val_loss: 0.5385 - val_accuracy: 0.8030
124/280 [============>.................] - ETA: 8s - loss: 0.4369 - accuracy: 0.8486 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
162/280 [================>.............] - ETA: 6s - loss: 0.4421 - accuracy: 0.8462 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
201/280 [====================>.........] - ETA: 4s - loss: 0.4462 - accuracy: 0.8432 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
238/280 [========================>.....] - ETA: 2s - loss: 0.4499 - accuracy: 0.8404 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
278/280 [============================>.] - ETA: 0s - loss: 0.4551 - accuracy: 0.8376 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
280/280 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.8375 .8066 - val_loss: 0.5385 - val_accuracy: 0.8030
 26/280 [=>............................] - ETA: 13s - loss: 0.3952 - accuracy: 0.7988.8374 - val_loss: 0.5571 - val_accuracy: 0.7879
 65/280 [=====>........................] - ETA: 11s - loss: 0.4165 - accuracy: 0.8086.8374 - val_loss: 0.5571 - val_accuracy: 0.7879
104/280 [==========>...................] - ETA: 9s - loss: 0.4367 - accuracy: 0.8068 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
142/280 [==============>...............] - ETA: 7s - loss: 0.4506 - accuracy: 0.8053 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
180/280 [==================>...........] - ETA: 5s - loss: 0.4612 - accuracy: 0.8044 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
218/280 [======================>.......] - ETA: 3s - loss: 0.4698 - accuracy: 0.8041 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
257/280 [==========================>...] - ETA: 1s - loss: 0.4770 - accuracy: 0.8035 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
280/280 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8034 .8374 - val_loss: 0.5571 - val_accuracy: 0.7879
 6/55 [==>...........................] - ETA: 1s - loss: 0.8618 - accuracy: 0.7083: 0.8034 - val_loss: 0.6041 - val_accuracy: 0.7727
55/55 [==============================] - 2s 36ms/step - loss: 0.7151 - accuracy: 0.7409034 - val_loss: 0.6041 - val_accuracy: 0.7727
55/55 [==============================] - 2s 36ms/step - loss: 0.7151 - accuracy: 0.7409034 - val_loss: 0.6041 - val_accuracy: 0.7727
55/55 [==============================] - 2s 36ms/step - loss: 0.7151 - accuracy: 0.7409034 - val_loss: 0.6041 - val_accuracy: 0.7727