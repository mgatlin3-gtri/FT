2022-06-23 04:31:08.293894: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 04:31:08.294912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 04:31:08.326728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 04:31:08.327086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 04:31:08.327106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 04:31:08.329519: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 04:31:08.329575: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 04:31:08.331736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 04:31:08.332211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 04:31:08.334419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 04:31:08.335637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 04:31:08.339994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 04:31:08.341070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 04:31:08.341442: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 04:31:08.341521: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 04:31:08.521203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 04:31:08.521475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 04:31:08.521500: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 04:31:08.521527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 04:31:08.521540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 04:31:08.521551: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 04:31:08.521562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 04:31:08.521573: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 04:31:08.521585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 04:31:08.521597: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 04:31:08.522329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 04:31:08.522354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 04:31:09.260568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 04:31:09.260608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 04:31:09.260621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 04:31:09.260625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 04:31:09.261644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 04:31:09.262691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 04:31:09.497443: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 04:31:09.497879: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 04:31:10.046748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 04:31:10.247708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 04:31:10.816059: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 04:31:10.851863: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 64)      1792
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 64)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 64)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 128)     73856
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 128)     0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 128)     0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 64)      73792
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 64)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 32)        18464
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 32)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 32)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 32)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 32)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 132
=================================================================
Total params: 168,036
Trainable params: 168,036
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 14/280 [>.............................] - ETA: 13s - loss: 1.4318 - accuracy: 0.3562







280/280 [==============================] - 22s 57ms/step - loss: 1.3817 - accuracy: 0.2620 - val_loss: 1.2070 - val_accuracy: 0.3826
Epoch 2/100







280/280 [==============================] - 16s 56ms/step - loss: 1.2003 - accuracy: 0.4414 - val_loss: 1.1772 - val_accuracy: 0.4508
Epoch 3/100







280/280 [==============================] - 16s 56ms/step - loss: 1.1818 - accuracy: 0.4681 - val_loss: 1.0156 - val_accuracy: 0.5341
Epoch 4/100






280/280 [==============================] - 16s 56ms/step - loss: 1.0879 - accuracy: 0.5279 - val_loss: 0.8933 - val_accuracy: 0.6667
Epoch 5/100






280/280 [==============================] - 16s 55ms/step - loss: 0.9355 - accuracy: 0.6333 - val_loss: 0.9409 - val_accuracy: 0.5833
Epoch 6/100







280/280 [==============================] - 16s 56ms/step - loss: 0.8017 - accuracy: 0.6883 - val_loss: 0.8092 - val_accuracy: 0.6780
Epoch 7/100







280/280 [==============================] - 16s 56ms/step - loss: 0.8561 - accuracy: 0.6842 - val_loss: 0.7426 - val_accuracy: 0.6970
Epoch 8/100







280/280 [==============================] - 16s 56ms/step - loss: 0.8312 - accuracy: 0.7018 - val_loss: 0.8170 - val_accuracy: 0.7045
Epoch 9/100






280/280 [==============================] - 16s 56ms/step - loss: 0.7871 - accuracy: 0.6964 - val_loss: 0.8100 - val_accuracy: 0.6629
Epoch 10/100






280/280 [==============================] - 16s 56ms/step - loss: 0.7319 - accuracy: 0.7223 - val_loss: 0.6562 - val_accuracy: 0.7348
Epoch 11/100







280/280 [==============================] - 16s 55ms/step - loss: 0.6902 - accuracy: 0.7343 - val_loss: 0.6527 - val_accuracy: 0.7159
Epoch 12/100







280/280 [==============================] - 16s 56ms/step - loss: 0.6321 - accuracy: 0.7655 - val_loss: 0.5766 - val_accuracy: 0.7576
Epoch 13/100







280/280 [==============================] - 16s 56ms/step - loss: 0.6075 - accuracy: 0.7683 - val_loss: 0.5874 - val_accuracy: 0.7159
Epoch 14/100






280/280 [==============================] - 16s 56ms/step - loss: 0.5504 - accuracy: 0.7979 - val_loss: 0.7755 - val_accuracy: 0.6818
Epoch 15/100






280/280 [==============================] - 16s 55ms/step - loss: 0.6355 - accuracy: 0.7439 - val_loss: 0.6639 - val_accuracy: 0.7197
Epoch 16/100







280/280 [==============================] - 16s 56ms/step - loss: 0.5479 - accuracy: 0.7905 - val_loss: 0.6024 - val_accuracy: 0.7311
Epoch 17/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4968 - accuracy: 0.7964 - val_loss: 0.5969 - val_accuracy: 0.7765
Epoch 18/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4939 - accuracy: 0.8206 - val_loss: 0.5396 - val_accuracy: 0.7614
Epoch 19/100






280/280 [==============================] - 16s 56ms/step - loss: 0.4849 - accuracy: 0.8081 - val_loss: 0.5029 - val_accuracy: 0.7917
Epoch 20/100






280/280 [==============================] - 16s 56ms/step - loss: 0.4796 - accuracy: 0.8126 - val_loss: 0.5704 - val_accuracy: 0.7500
Epoch 21/100






280/280 [==============================] - 16s 56ms/step - loss: 0.4763 - accuracy: 0.8062 - val_loss: 0.6595 - val_accuracy: 0.7197
Epoch 22/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4601 - accuracy: 0.8266 - val_loss: 0.4010 - val_accuracy: 0.8523
Epoch 23/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4093 - accuracy: 0.8454 - val_loss: 0.5005 - val_accuracy: 0.7841
Epoch 24/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4686 - accuracy: 0.8286 - val_loss: 0.5051 - val_accuracy: 0.7765
Epoch 25/100







280/280 [==============================] - 16s 56ms/step - loss: 0.3896 - accuracy: 0.8571 - val_loss: 0.4116 - val_accuracy: 0.8182
Epoch 26/100






280/280 [==============================] - 16s 56ms/step - loss: 0.4318 - accuracy: 0.8317 - val_loss: 0.3913 - val_accuracy: 0.8258
Epoch 27/100






280/280 [==============================] - 16s 56ms/step - loss: 0.4320 - accuracy: 0.8562 - val_loss: 0.6450 - val_accuracy: 0.7424
Epoch 28/100







280/280 [==============================] - 16s 56ms/step - loss: 0.4094 - accuracy: 0.8487 - val_loss: 0.4931 - val_accuracy: 0.8030
Epoch 29/100







280/280 [==============================] - 16s 56ms/step - loss: 0.3914 - accuracy: 0.8650 - val_loss: 0.3785 - val_accuracy: 0.8598
Epoch 30/100
 62/280 [=====>........................] - ETA: 10s - loss: 0.4641 - accuracy: 0.8223
105/280 [==========>...................] - ETA: 8s - loss: 0.4354 - accuracy: 0.8362
147/280 [==============>...............] - ETA: 6s - loss: 0.4149 - accuracy: 0.8450
189/280 [===================>..........] - ETA: 4s - loss: 0.4031 - accuracy: 0.8503
233/280 [=======================>......] - ETA: 2s - loss: 0.3952 - accuracy: 0.8537
275/280 [============================>.] - ETA: 0s - loss: 0.3927 - accuracy: 0.8551
279/280 [============================>.] - ETA: 0s - loss: 0.3926 - accuracy: 0.8552
 30/280 [==>...........................] - ETA: 11s - loss: 0.3785 - accuracy: 0.8323.8552 - val_loss: 0.4791 - val_accuracy: 0.7803
 72/280 [======>.......................] - ETA: 9s - loss: 0.3718 - accuracy: 0.8414 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
114/280 [===========>..................] - ETA: 7s - loss: 0.3680 - accuracy: 0.8469 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
157/280 [===============>..............] - ETA: 5s - loss: 0.3608 - accuracy: 0.8535 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
201/280 [====================>.........] - ETA: 3s - loss: 0.3607 - accuracy: 0.8550 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
243/280 [=========================>....] - ETA: 1s - loss: 0.3603 - accuracy: 0.8559 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
279/280 [============================>.] - ETA: 0s - loss: 0.3616 - accuracy: 0.8559 .8552 - val_loss: 0.4791 - val_accuracy: 0.7803
280/280 [==============================] - 16s 56ms/step - loss: 0.3617 - accuracy: 0.8560 - val_loss: 0.5177 - val_accuracy: 0.7992
 41/280 [===>..........................] - ETA: 11s - loss: 0.4081 - accuracy: 0.8388.8560 - val_loss: 0.5177 - val_accuracy: 0.7992
 84/280 [========>.....................] - ETA: 9s - loss: 0.3934 - accuracy: 0.8449 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
126/280 [============>.................] - ETA: 7s - loss: 0.3906 - accuracy: 0.8471 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
168/280 [=================>............] - ETA: 5s - loss: 0.3954 - accuracy: 0.8468 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
212/280 [=====================>........] - ETA: 3s - loss: 0.3994 - accuracy: 0.8477 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
255/280 [==========================>...] - ETA: 1s - loss: 0.3982 - accuracy: 0.8497 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
279/280 [============================>.] - ETA: 0s - loss: 0.3966 - accuracy: 0.8511 .8560 - val_loss: 0.5177 - val_accuracy: 0.7992
  8/280 [..............................] - ETA: 13s - loss: 0.2834 - accuracy: 0.8899.8512 - val_loss: 0.4911 - val_accuracy: 0.7917
 51/280 [====>.........................] - ETA: 10s - loss: 0.3207 - accuracy: 0.8837.8512 - val_loss: 0.4911 - val_accuracy: 0.7917
 84/280 [========>.....................] - ETA: 9s - loss: 0.3176 - accuracy: 0.8857 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
128/280 [============>.................] - ETA: 7s - loss: 0.3185 - accuracy: 0.8851 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
171/280 [=================>............] - ETA: 5s - loss: 0.3225 - accuracy: 0.8842 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
212/280 [=====================>........] - ETA: 3s - loss: 0.3258 - accuracy: 0.8834 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
254/280 [==========================>...] - ETA: 1s - loss: 0.3298 - accuracy: 0.8825 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
279/280 [============================>.] - ETA: 0s - loss: 0.3313 - accuracy: 0.8820 .8512 - val_loss: 0.4911 - val_accuracy: 0.7917
  8/280 [..............................] - ETA: 13s - loss: 0.3607 - accuracy: 0.7972.8820 - val_loss: 0.3860 - val_accuracy: 0.8371
 51/280 [====>.........................] - ETA: 10s - loss: 0.3692 - accuracy: 0.8333.8820 - val_loss: 0.3860 - val_accuracy: 0.8371
 94/280 [=========>....................] - ETA: 8s - loss: 0.3594 - accuracy: 0.8441 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
138/280 [=============>................] - ETA: 6s - loss: 0.3559 - accuracy: 0.8516 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
180/280 [==================>...........] - ETA: 4s - loss: 0.3553 - accuracy: 0.8548 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
224/280 [=======================>......] - ETA: 2s - loss: 0.3543 - accuracy: 0.8560 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
267/280 [===========================>..] - ETA: 0s - loss: 0.3553 - accuracy: 0.8561 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
280/280 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.8561 .8820 - val_loss: 0.3860 - val_accuracy: 0.8371
 21/280 [=>............................] - ETA: 12s - loss: 0.3760 - accuracy: 0.8492.8561 - val_loss: 0.3645 - val_accuracy: 0.8598
 63/280 [=====>........................] - ETA: 10s - loss: 0.3571 - accuracy: 0.8584.8561 - val_loss: 0.3645 - val_accuracy: 0.8598
105/280 [==========>...................] - ETA: 8s - loss: 0.3548 - accuracy: 0.8601 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
148/280 [==============>...............] - ETA: 6s - loss: 0.3508 - accuracy: 0.8623 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
191/280 [===================>..........] - ETA: 4s - loss: 0.3482 - accuracy: 0.8645 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
235/280 [========================>.....] - ETA: 2s - loss: 0.3469 - accuracy: 0.8659 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
277/280 [============================>.] - ETA: 0s - loss: 0.3448 - accuracy: 0.8676 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
279/280 [============================>.] - ETA: 0s - loss: 0.3447 - accuracy: 0.8677 .8561 - val_loss: 0.3645 - val_accuracy: 0.8598
 32/280 [==>...........................] - ETA: 11s - loss: 0.2615 - accuracy: 0.8956.8678 - val_loss: 0.4395 - val_accuracy: 0.8258
 75/280 [=======>......................] - ETA: 9s - loss: 0.3112 - accuracy: 0.8763 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
117/280 [===========>..................] - ETA: 7s - loss: 0.3238 - accuracy: 0.8759 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
159/280 [================>.............] - ETA: 5s - loss: 0.3334 - accuracy: 0.8745 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
202/280 [====================>.........] - ETA: 3s - loss: 0.3430 - accuracy: 0.8729 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
244/280 [=========================>....] - ETA: 1s - loss: 0.3480 - accuracy: 0.8723 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
280/280 [==============================] - ETA: 0s - loss: 0.3488 - accuracy: 0.8726 .8678 - val_loss: 0.4395 - val_accuracy: 0.8258
  1/280 [..............................] - ETA: 22s - loss: 0.4178 - accuracy: 1.0000.8726 - val_loss: 0.4677 - val_accuracy: 0.8068
 44/280 [===>..........................] - ETA: 11s - loss: 0.5022 - accuracy: 0.8290.8726 - val_loss: 0.4677 - val_accuracy: 0.8068
 86/280 [========>.....................] - ETA: 9s - loss: 0.4374 - accuracy: 0.8484 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
129/280 [============>.................] - ETA: 7s - loss: 0.4096 - accuracy: 0.8595 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
172/280 [=================>............] - ETA: 5s - loss: 0.3924 - accuracy: 0.8660 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
205/280 [====================>.........] - ETA: 3s - loss: 0.3850 - accuracy: 0.8690 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
248/280 [=========================>....] - ETA: 1s - loss: 0.3779 - accuracy: 0.8718 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
279/280 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.8726 .8726 - val_loss: 0.4677 - val_accuracy: 0.8068
  3/280 [..............................] - ETA: 13s - loss: 0.2033 - accuracy: 0.8611.8727 - val_loss: 0.5306 - val_accuracy: 0.7689
 47/280 [====>.........................] - ETA: 10s - loss: 0.2888 - accuracy: 0.8672.8727 - val_loss: 0.5306 - val_accuracy: 0.7689
 88/280 [========>.....................] - ETA: 9s - loss: 0.3164 - accuracy: 0.8680 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
133/280 [=============>................] - ETA: 6s - loss: 0.3168 - accuracy: 0.8720 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
175/280 [=================>............] - ETA: 4s - loss: 0.3185 - accuracy: 0.8735 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
217/280 [======================>.......] - ETA: 2s - loss: 0.3222 - accuracy: 0.8739 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
260/280 [==========================>...] - ETA: 0s - loss: 0.3254 - accuracy: 0.8741 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
279/280 [============================>.] - ETA: 0s - loss: 0.3266 - accuracy: 0.8742 .8727 - val_loss: 0.5306 - val_accuracy: 0.7689
 15/280 [>.............................] - ETA: 12s - loss: 0.3521 - accuracy: 0.9085.8742 - val_loss: 0.4373 - val_accuracy: 0.8371
 57/280 [=====>........................] - ETA: 10s - loss: 0.3439 - accuracy: 0.8924.8742 - val_loss: 0.4373 - val_accuracy: 0.8371
101/280 [=========>....................] - ETA: 8s - loss: 0.3267 - accuracy: 0.8936 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
145/280 [==============>...............] - ETA: 6s - loss: 0.3264 - accuracy: 0.8920 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
187/280 [===================>..........] - ETA: 4s - loss: 0.3290 - accuracy: 0.8895 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
230/280 [=======================>......] - ETA: 2s - loss: 0.3304 - accuracy: 0.8882 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
272/280 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.8867 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
280/280 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.8866 .8742 - val_loss: 0.4373 - val_accuracy: 0.8371
 27/280 [=>............................] - ETA: 11s - loss: 0.2273 - accuracy: 0.9493.8865 - val_loss: 0.4868 - val_accuracy: 0.7879
 70/280 [======>.......................] - ETA: 9s - loss: 0.2478 - accuracy: 0.9309 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
112/280 [===========>..................] - ETA: 7s - loss: 0.2657 - accuracy: 0.9171 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
155/280 [===============>..............] - ETA: 5s - loss: 0.2801 - accuracy: 0.9069 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
199/280 [====================>.........] - ETA: 3s - loss: 0.2950 - accuracy: 0.9000 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
241/280 [========================>.....] - ETA: 1s - loss: 0.3038 - accuracy: 0.8969 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
279/280 [============================>.] - ETA: 0s - loss: 0.3091 - accuracy: 0.8951 .8865 - val_loss: 0.4868 - val_accuracy: 0.7879
 39/280 [===>..........................] - ETA: 11s - loss: 0.2654 - accuracy: 0.9292.8950 - val_loss: 0.4259 - val_accuracy: 0.8030
 81/280 [=======>......................] - ETA: 9s - loss: 0.2563 - accuracy: 0.9278 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
124/280 [============>.................] - ETA: 7s - loss: 0.2542 - accuracy: 0.9223 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
167/280 [================>.............] - ETA: 5s - loss: 0.2718 - accuracy: 0.9131 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
210/280 [=====================>........] - ETA: 3s - loss: 0.2841 - accuracy: 0.9065 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
252/280 [==========================>...] - ETA: 1s - loss: 0.2925 - accuracy: 0.9028 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
279/280 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.9010 .8950 - val_loss: 0.4259 - val_accuracy: 0.8030
  6/280 [..............................] - ETA: 13s - loss: 0.2835 - accuracy: 0.8222.9009 - val_loss: 0.3872 - val_accuracy: 0.8523
 49/280 [====>.........................] - ETA: 11s - loss: 0.2903 - accuracy: 0.8852.9009 - val_loss: 0.3872 - val_accuracy: 0.8523
 81/280 [=======>......................] - ETA: 9s - loss: 0.2767 - accuracy: 0.9032 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
124/280 [============>.................] - ETA: 7s - loss: 0.2713 - accuracy: 0.9129 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
166/280 [================>.............] - ETA: 5s - loss: 0.2812 - accuracy: 0.9137 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
208/280 [=====================>........] - ETA: 3s - loss: 0.2860 - accuracy: 0.9143 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
252/280 [==========================>...] - ETA: 1s - loss: 0.2903 - accuracy: 0.9136 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
280/280 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.9126 .9009 - val_loss: 0.3872 - val_accuracy: 0.8523
  7/280 [..............................] - ETA: 12s - loss: 0.4135 - accuracy: 0.8816.9126 - val_loss: 0.5045 - val_accuracy: 0.7992
 50/280 [====>.........................] - ETA: 10s - loss: 0.3620 - accuracy: 0.8612.9126 - val_loss: 0.5045 - val_accuracy: 0.7992
 91/280 [========>.....................] - ETA: 9s - loss: 0.3423 - accuracy: 0.8709 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
135/280 [=============>................] - ETA: 6s - loss: 0.3258 - accuracy: 0.8799 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
179/280 [==================>...........] - ETA: 4s - loss: 0.3178 - accuracy: 0.8834 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
221/280 [======================>.......] - ETA: 2s - loss: 0.3121 - accuracy: 0.8863 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
263/280 [===========================>..] - ETA: 0s - loss: 0.3106 - accuracy: 0.8876 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
280/280 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8880 .9126 - val_loss: 0.5045 - val_accuracy: 0.7992
 17/280 [>.............................] - ETA: 12s - loss: 0.2570 - accuracy: 0.9499.8880 - val_loss: 0.5525 - val_accuracy: 0.7841
 59/280 [=====>........................] - ETA: 10s - loss: 0.3572 - accuracy: 0.8725.8880 - val_loss: 0.5525 - val_accuracy: 0.7841
102/280 [=========>....................] - ETA: 8s - loss: 0.3593 - accuracy: 0.8629 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
146/280 [==============>...............] - ETA: 6s - loss: 0.3573 - accuracy: 0.8611 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
188/280 [===================>..........] - ETA: 4s - loss: 0.3522 - accuracy: 0.8632 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
230/280 [=======================>......] - ETA: 2s - loss: 0.3474 - accuracy: 0.8655 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
274/280 [============================>.] - ETA: 0s - loss: 0.3448 - accuracy: 0.8666 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
280/280 [==============================] - ETA: 0s - loss: 0.3447 - accuracy: 0.8667 .8880 - val_loss: 0.5525 - val_accuracy: 0.7841
 27/280 [=>............................] - ETA: 11s - loss: 0.2270 - accuracy: 0.9397.8667 - val_loss: 0.4289 - val_accuracy: 0.8409
 71/280 [======>.......................] - ETA: 9s - loss: 0.2483 - accuracy: 0.9262 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
113/280 [===========>..................] - ETA: 7s - loss: 0.2657 - accuracy: 0.9147 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
156/280 [===============>..............] - ETA: 5s - loss: 0.2710 - accuracy: 0.9081 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
199/280 [====================>.........] - ETA: 3s - loss: 0.2743 - accuracy: 0.9049 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
242/280 [========================>.....] - ETA: 1s - loss: 0.2796 - accuracy: 0.9018 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
274/280 [============================>.] - ETA: 0s - loss: 0.2822 - accuracy: 0.9002 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
280/280 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.8999 .8667 - val_loss: 0.4289 - val_accuracy: 0.8409
 27/280 [=>............................] - ETA: 12s - loss: 0.2193 - accuracy: 0.9260.8999 - val_loss: 0.4636 - val_accuracy: 0.8182
 70/280 [======>.......................] - ETA: 9s - loss: 0.2199 - accuracy: 0.9204 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
113/280 [===========>..................] - ETA: 7s - loss: 0.2340 - accuracy: 0.9130 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
155/280 [===============>..............] - ETA: 5s - loss: 0.2400 - accuracy: 0.9120 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
197/280 [====================>.........] - ETA: 3s - loss: 0.2442 - accuracy: 0.9119 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
240/280 [========================>.....] - ETA: 1s - loss: 0.2473 - accuracy: 0.9121 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
279/280 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.9113 .8999 - val_loss: 0.4636 - val_accuracy: 0.8182
 38/280 [===>..........................] - ETA: 11s - loss: 0.2307 - accuracy: 0.9170.9113 - val_loss: 0.4013 - val_accuracy: 0.8295
 82/280 [=======>......................] - ETA: 9s - loss: 0.2481 - accuracy: 0.9119 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
124/280 [============>.................] - ETA: 7s - loss: 0.2593 - accuracy: 0.9068 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
168/280 [=================>............] - ETA: 5s - loss: 0.2645 - accuracy: 0.9051 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
210/280 [=====================>........] - ETA: 3s - loss: 0.2690 - accuracy: 0.9030 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
254/280 [==========================>...] - ETA: 1s - loss: 0.2717 - accuracy: 0.9019 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
280/280 [==============================] - ETA: 0s - loss: 0.2735 - accuracy: 0.9012 .9113 - val_loss: 0.4013 - val_accuracy: 0.8295
  8/280 [..............................] - ETA: 12s - loss: 0.1864 - accuracy: 0.9129.9012 - val_loss: 0.4818 - val_accuracy: 0.7955
 51/280 [====>.........................] - ETA: 10s - loss: 0.2782 - accuracy: 0.9030.9012 - val_loss: 0.4818 - val_accuracy: 0.7955
 94/280 [=========>....................] - ETA: 8s - loss: 0.2801 - accuracy: 0.9024 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
135/280 [=============>................] - ETA: 6s - loss: 0.2802 - accuracy: 0.9016 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
179/280 [==================>...........] - ETA: 4s - loss: 0.2778 - accuracy: 0.9024 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
221/280 [======================>.......] - ETA: 2s - loss: 0.2767 - accuracy: 0.9018 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
264/280 [===========================>..] - ETA: 0s - loss: 0.2759 - accuracy: 0.9015 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
279/280 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.9013 .9012 - val_loss: 0.4818 - val_accuracy: 0.7955
 19/280 [=>............................] - ETA: 12s - loss: 0.1735 - accuracy: 0.9278.9012 - val_loss: 0.4202 - val_accuracy: 0.8523
 62/280 [=====>........................] - ETA: 10s - loss: 0.2276 - accuracy: 0.9050.9012 - val_loss: 0.4202 - val_accuracy: 0.8523
104/280 [==========>...................] - ETA: 8s - loss: 0.2294 - accuracy: 0.9073 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
147/280 [==============>...............] - ETA: 6s - loss: 0.2352 - accuracy: 0.9064 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
191/280 [===================>..........] - ETA: 4s - loss: 0.2431 - accuracy: 0.9036 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
232/280 [=======================>......] - ETA: 2s - loss: 0.2483 - accuracy: 0.9018 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
275/280 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.9009 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
280/280 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.9008 .9012 - val_loss: 0.4202 - val_accuracy: 0.8523
 31/280 [==>...........................] - ETA: 11s - loss: 0.3321 - accuracy: 0.8822.9008 - val_loss: 0.4441 - val_accuracy: 0.8447
 72/280 [======>.......................] - ETA: 9s - loss: 0.3321 - accuracy: 0.8767 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
115/280 [===========>..................] - ETA: 7s - loss: 0.3260 - accuracy: 0.8756 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
158/280 [===============>..............] - ETA: 5s - loss: 0.3198 - accuracy: 0.8757 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
201/280 [====================>.........] - ETA: 3s - loss: 0.3127 - accuracy: 0.8774 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
242/280 [========================>.....] - ETA: 1s - loss: 0.3066 - accuracy: 0.8794 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
280/280 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.8810 .9008 - val_loss: 0.4441 - val_accuracy: 0.8447
 29/280 [==>...........................] - ETA: 11s - loss: 0.1876 - accuracy: 0.9387.8811 - val_loss: 0.4549 - val_accuracy: 0.8258
 70/280 [======>.......................] - ETA: 9s - loss: 0.2040 - accuracy: 0.9184 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
115/280 [===========>..................] - ETA: 7s - loss: 0.2164 - accuracy: 0.9117 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
158/280 [===============>..............] - ETA: 5s - loss: 0.2278 - accuracy: 0.9076 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
200/280 [====================>.........] - ETA: 3s - loss: 0.2355 - accuracy: 0.9048 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
244/280 [=========================>....] - ETA: 1s - loss: 0.2430 - accuracy: 0.9019 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
279/280 [============================>.] - ETA: 0s - loss: 0.2477 - accuracy: 0.9007 .8811 - val_loss: 0.4549 - val_accuracy: 0.8258
 41/280 [===>..........................] - ETA: 11s - loss: 0.2994 - accuracy: 0.8946.9006 - val_loss: 0.5365 - val_accuracy: 0.8106
 84/280 [========>.....................] - ETA: 9s - loss: 0.2926 - accuracy: 0.8979 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
128/280 [============>.................] - ETA: 7s - loss: 0.2925 - accuracy: 0.8963 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
170/280 [=================>............] - ETA: 5s - loss: 0.2868 - accuracy: 0.8971 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
213/280 [=====================>........] - ETA: 3s - loss: 0.2786 - accuracy: 0.8994 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
257/280 [==========================>...] - ETA: 1s - loss: 0.2730 - accuracy: 0.9007 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
279/280 [============================>.] - ETA: 0s - loss: 0.2711 - accuracy: 0.9012 .9006 - val_loss: 0.5365 - val_accuracy: 0.8106
 13/280 [>.............................] - ETA: 12s - loss: 0.1355 - accuracy: 0.9937.9012 - val_loss: 0.4392 - val_accuracy: 0.8485
 55/280 [====>.........................] - ETA: 10s - loss: 0.1663 - accuracy: 0.9692.9012 - val_loss: 0.4392 - val_accuracy: 0.8485
 98/280 [=========>....................] - ETA: 8s - loss: 0.1686 - accuracy: 0.9603 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
141/280 [==============>...............] - ETA: 6s - loss: 0.1813 - accuracy: 0.9529 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
185/280 [==================>...........] - ETA: 4s - loss: 0.1933 - accuracy: 0.9475 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
228/280 [=======================>......] - ETA: 2s - loss: 0.2019 - accuracy: 0.9432 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
270/280 [===========================>..] - ETA: 0s - loss: 0.2073 - accuracy: 0.9401 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
280/280 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.9394 .9012 - val_loss: 0.4392 - val_accuracy: 0.8485
 25/280 [=>............................] - ETA: 11s - loss: 0.2742 - accuracy: 0.9210.9393 - val_loss: 0.3826 - val_accuracy: 0.8636
 68/280 [======>.......................] - ETA: 9s - loss: 0.2568 - accuracy: 0.9184 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
110/280 [==========>...................] - ETA: 8s - loss: 0.2459 - accuracy: 0.9201 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
153/280 [===============>..............] - ETA: 5s - loss: 0.2404 - accuracy: 0.9199 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
197/280 [====================>.........] - ETA: 3s - loss: 0.2396 - accuracy: 0.9193 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
239/280 [========================>.....] - ETA: 1s - loss: 0.2404 - accuracy: 0.9181 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
280/280 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.9171 .9393 - val_loss: 0.3826 - val_accuracy: 0.8636
31/55 [===============>..............] - ETA: 0s - loss: 0.5317 - accuracy: 0.7742: 0.9171 - val_loss: 0.4205 - val_accuracy: 0.8258
55/55 [==============================] - 2s 35ms/step - loss: 0.5053 - accuracy: 0.7773171 - val_loss: 0.4205 - val_accuracy: 0.8258
55/55 [==============================] - 2s 35ms/step - loss: 0.5053 - accuracy: 0.7773171 - val_loss: 0.4205 - val_accuracy: 0.8258