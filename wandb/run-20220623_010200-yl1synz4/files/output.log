2022-06-23 01:02:04.813106: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 01:02:04.814082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-23 01:02:04.847628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 01:02:04.848141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 01:02:04.848175: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 01:02:04.851082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 01:02:04.851153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 01:02:04.853917: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 01:02:04.854389: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 01:02:04.857263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 01:02:04.858794: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 01:02:04.864881: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 01:02:04.875879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 01:02:04.876350: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-23 01:02:04.876447: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-23 01:02:05.052885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 01:02:05.053138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-23 01:02:05.053164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 01:02:05.053193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 01:02:05.053205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-23 01:02:05.053218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-23 01:02:05.053231: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-23 01:02:05.053241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-23 01:02:05.053254: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-23 01:02:05.053267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 01:02:05.054839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-23 01:02:05.054869: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-23 01:02:05.944722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-23 01:02:05.944764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-23 01:02:05.944780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-23 01:02:05.944788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-23 01:02:05.945816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-23 01:02:05.946898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-23 01:02:06.176243: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-23 01:02:06.176694: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-23 01:02:06.720809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-23 01:02:06.912514: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-23 01:02:07.486171: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-23 01:02:07.521292: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 64)      1792
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 64)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 64)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 64)      36928
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 64)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 64)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 128)     73856
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 128)       0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 128)       0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 16)        18448
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 16)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 16)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 16)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 16)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 68
=================================================================
Total params: 131,092
Trainable params: 131,092
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100






280/280 [==============================] - 21s 55ms/step - loss: 1.3783 - accuracy: 0.2956 - val_loss: 1.2678 - val_accuracy: 0.3788
Epoch 2/100






280/280 [==============================] - 15s 54ms/step - loss: 1.2468 - accuracy: 0.3936 - val_loss: 1.2682 - val_accuracy: 0.4091
Epoch 3/100







280/280 [==============================] - 15s 53ms/step - loss: 1.1789 - accuracy: 0.4564 - val_loss: 1.0183 - val_accuracy: 0.5871
Epoch 4/100







280/280 [==============================] - 15s 54ms/step - loss: 1.1209 - accuracy: 0.5459 - val_loss: 0.9236 - val_accuracy: 0.6174
Epoch 5/100






280/280 [==============================] - 15s 53ms/step - loss: 1.0290 - accuracy: 0.5611 - val_loss: 0.9049 - val_accuracy: 0.6326
Epoch 6/100






280/280 [==============================] - 15s 53ms/step - loss: 0.9595 - accuracy: 0.6183 - val_loss: 0.8166 - val_accuracy: 0.6250
Epoch 7/100







280/280 [==============================] - 15s 53ms/step - loss: 0.9184 - accuracy: 0.6493 - val_loss: 0.7768 - val_accuracy: 0.7197
Epoch 8/100







280/280 [==============================] - 15s 54ms/step - loss: 0.8594 - accuracy: 0.6601 - val_loss: 0.8039 - val_accuracy: 0.6250
Epoch 9/100






280/280 [==============================] - 15s 54ms/step - loss: 0.8064 - accuracy: 0.6937 - val_loss: 0.6840 - val_accuracy: 0.6780
Epoch 10/100






280/280 [==============================] - 15s 54ms/step - loss: 0.7757 - accuracy: 0.6920 - val_loss: 0.6252 - val_accuracy: 0.7348
Epoch 11/100







280/280 [==============================] - 15s 53ms/step - loss: 0.7649 - accuracy: 0.7042 - val_loss: 0.5785 - val_accuracy: 0.7424
Epoch 12/100






280/280 [==============================] - 15s 53ms/step - loss: 0.8242 - accuracy: 0.6921 - val_loss: 0.7779 - val_accuracy: 0.6932
Epoch 13/100






280/280 [==============================] - 15s 54ms/step - loss: 0.6965 - accuracy: 0.7339 - val_loss: 0.6199 - val_accuracy: 0.7159
Epoch 14/100






280/280 [==============================] - 15s 54ms/step - loss: 0.6678 - accuracy: 0.7430 - val_loss: 0.6251 - val_accuracy: 0.7008
Epoch 15/100







280/280 [==============================] - 15s 54ms/step - loss: 0.6169 - accuracy: 0.7541 - val_loss: 0.5603 - val_accuracy: 0.7652
Epoch 16/100






280/280 [==============================] - 15s 54ms/step - loss: 0.6434 - accuracy: 0.7542 - val_loss: 0.4812 - val_accuracy: 0.8144
Epoch 17/100






280/280 [==============================] - 15s 54ms/step - loss: 0.6042 - accuracy: 0.7609 - val_loss: 0.4990 - val_accuracy: 0.7955
Epoch 18/100







280/280 [==============================] - 15s 53ms/step - loss: 0.5764 - accuracy: 0.7626 - val_loss: 0.4978 - val_accuracy: 0.7538
Epoch 19/100






280/280 [==============================] - 15s 54ms/step - loss: 0.5502 - accuracy: 0.7778 - val_loss: 0.4176 - val_accuracy: 0.8182
Epoch 20/100







280/280 [==============================] - 15s 54ms/step - loss: 0.5259 - accuracy: 0.8065 - val_loss: 0.4042 - val_accuracy: 0.8295
Epoch 21/100






280/280 [==============================] - 15s 53ms/step - loss: 0.5329 - accuracy: 0.8090 - val_loss: 0.5097 - val_accuracy: 0.7689
Epoch 22/100






280/280 [==============================] - 15s 53ms/step - loss: 0.5194 - accuracy: 0.8161 - val_loss: 0.4523 - val_accuracy: 0.7992
Epoch 23/100






280/280 [==============================] - 15s 54ms/step - loss: 0.4744 - accuracy: 0.8237 - val_loss: 0.3859 - val_accuracy: 0.8333
Epoch 24/100







280/280 [==============================] - 15s 55ms/step - loss: 0.5192 - accuracy: 0.8133 - val_loss: 0.4050 - val_accuracy: 0.8144
Epoch 25/100






280/280 [==============================] - 15s 54ms/step - loss: 0.5193 - accuracy: 0.8033 - val_loss: 0.4409 - val_accuracy: 0.7803
Epoch 26/100







280/280 [==============================] - 15s 54ms/step - loss: 0.4492 - accuracy: 0.8367 - val_loss: 0.4420 - val_accuracy: 0.7992
Epoch 27/100






280/280 [==============================] - 15s 54ms/step - loss: 0.5117 - accuracy: 0.7961 - val_loss: 0.3966 - val_accuracy: 0.8295
Epoch 28/100






280/280 [==============================] - 15s 53ms/step - loss: 0.4509 - accuracy: 0.8298 - val_loss: 0.4139 - val_accuracy: 0.8144
Epoch 29/100






280/280 [==============================] - 15s 54ms/step - loss: 0.4824 - accuracy: 0.8169 - val_loss: 0.3467 - val_accuracy: 0.8485
Epoch 30/100
 46/280 [===>..........................] - ETA: 10s - loss: 0.5025 - accuracy: 0.7836
 92/280 [========>.....................] - ETA: 8s - loss: 0.4871 - accuracy: 0.7985
137/280 [=============>................] - ETA: 6s - loss: 0.4879 - accuracy: 0.8009
170/280 [=================>............] - ETA: 4s - loss: 0.4894 - accuracy: 0.8017
216/280 [======================>.......] - ETA: 2s - loss: 0.4881 - accuracy: 0.8040
261/280 [==========================>...] - ETA: 0s - loss: 0.4836 - accuracy: 0.8073
279/280 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.8091
 14/280 [>.............................] - ETA: 12s - loss: 0.5788 - accuracy: 0.7816.8093 - val_loss: 0.3345 - val_accuracy: 0.8561
 59/280 [=====>........................] - ETA: 9s - loss: 0.5452 - accuracy: 0.8015 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
103/280 [==========>...................] - ETA: 8s - loss: 0.4965 - accuracy: 0.8171 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
150/280 [===============>..............] - ETA: 5s - loss: 0.4686 - accuracy: 0.8256 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
196/280 [====================>.........] - ETA: 3s - loss: 0.4547 - accuracy: 0.8317 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
239/280 [========================>.....] - ETA: 1s - loss: 0.4456 - accuracy: 0.8354 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.4409 - accuracy: 0.8378 .8093 - val_loss: 0.3345 - val_accuracy: 0.8561
 39/280 [===>..........................] - ETA: 10s - loss: 0.3827 - accuracy: 0.8876.8378 - val_loss: 0.3647 - val_accuracy: 0.8485
 86/280 [========>.....................] - ETA: 8s - loss: 0.4009 - accuracy: 0.8764 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
132/280 [=============>................] - ETA: 6s - loss: 0.4070 - accuracy: 0.8740 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
177/280 [=================>............] - ETA: 4s - loss: 0.4079 - accuracy: 0.8710 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
222/280 [======================>.......] - ETA: 2s - loss: 0.4103 - accuracy: 0.8679 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
266/280 [===========================>..] - ETA: 0s - loss: 0.4135 - accuracy: 0.8654 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
280/280 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.8646 .8378 - val_loss: 0.3647 - val_accuracy: 0.8485
 20/280 [=>............................] - ETA: 12s - loss: 0.2235 - accuracy: 0.9250.8646 - val_loss: 0.3193 - val_accuracy: 0.8712
 64/280 [=====>........................] - ETA: 9s - loss: 0.3175 - accuracy: 0.8757 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
109/280 [==========>...................] - ETA: 7s - loss: 0.3421 - accuracy: 0.8697 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
154/280 [===============>..............] - ETA: 5s - loss: 0.3631 - accuracy: 0.8621 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
199/280 [====================>.........] - ETA: 3s - loss: 0.3774 - accuracy: 0.8564 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
244/280 [=========================>....] - ETA: 1s - loss: 0.3858 - accuracy: 0.8538 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.3914 - accuracy: 0.8525 .8646 - val_loss: 0.3193 - val_accuracy: 0.8712
280/280 [==============================] - 15s 54ms/step - loss: 0.3917 - accuracy: 0.8525 - val_loss: 0.4113 - val_accuracy: 0.8220
 44/280 [===>..........................] - ETA: 10s - loss: 0.4287 - accuracy: 0.8249.8525 - val_loss: 0.4113 - val_accuracy: 0.8220
 90/280 [========>.....................] - ETA: 8s - loss: 0.3815 - accuracy: 0.8550 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
137/280 [=============>................] - ETA: 6s - loss: 0.3813 - accuracy: 0.8596 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
182/280 [==================>...........] - ETA: 4s - loss: 0.3880 - accuracy: 0.8576 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
226/280 [=======================>......] - ETA: 2s - loss: 0.3903 - accuracy: 0.8569 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
260/280 [==========================>...] - ETA: 0s - loss: 0.3913 - accuracy: 0.8570 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
279/280 [============================>.] - ETA: 0s - loss: 0.3922 - accuracy: 0.8569 .8525 - val_loss: 0.4113 - val_accuracy: 0.8220
 14/280 [>.............................] - ETA: 12s - loss: 0.4434 - accuracy: 0.8706.8569 - val_loss: 0.4009 - val_accuracy: 0.8485
 59/280 [=====>........................] - ETA: 10s - loss: 0.3760 - accuracy: 0.8632.8569 - val_loss: 0.4009 - val_accuracy: 0.8485
105/280 [==========>...................] - ETA: 8s - loss: 0.3769 - accuracy: 0.8611 .8569 - val_loss: 0.4009 - val_accuracy: 0.8485
151/280 [===============>..............] - ETA: 5s - loss: 0.3779 - accuracy: 0.8606 .8569 - val_loss: 0.4009 - val_accuracy: 0.8485
197/280 [====================>.........] - ETA: 3s - loss: 0.3824 - accuracy: 0.8582 .8569 - val_loss: 0.4009 - val_accuracy: 0.8485
243/280 [=========================>....] - ETA: 1s - loss: 0.3834 - accuracy: 0.8578 .8569 - val_loss: 0.4009 - val_accuracy: 0.8485
280/280 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.8578 .8569 - val_loss: 0.4009 - val_accuracy: 0.8485
 42/280 [===>..........................] - ETA: 10s - loss: 0.2578 - accuracy: 0.9277.8578 - val_loss: 0.3296 - val_accuracy: 0.8712
 88/280 [========>.....................] - ETA: 8s - loss: 0.2956 - accuracy: 0.9089 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
133/280 [=============>................] - ETA: 6s - loss: 0.3114 - accuracy: 0.9034 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
177/280 [=================>............] - ETA: 4s - loss: 0.3212 - accuracy: 0.8987 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
224/280 [=======================>......] - ETA: 2s - loss: 0.3280 - accuracy: 0.8950 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
270/280 [===========================>..] - ETA: 0s - loss: 0.3339 - accuracy: 0.8914 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8908 .8578 - val_loss: 0.3296 - val_accuracy: 0.8712
 22/280 [=>............................] - ETA: 11s - loss: 0.5236 - accuracy: 0.8044.8907 - val_loss: 0.4123 - val_accuracy: 0.8258
 66/280 [======>.......................] - ETA: 9s - loss: 0.4660 - accuracy: 0.8057 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
114/280 [===========>..................] - ETA: 7s - loss: 0.4358 - accuracy: 0.8199 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
159/280 [================>.............] - ETA: 5s - loss: 0.4231 - accuracy: 0.8270 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
203/280 [====================>.........] - ETA: 3s - loss: 0.4147 - accuracy: 0.8325 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
248/280 [=========================>....] - ETA: 1s - loss: 0.4091 - accuracy: 0.8370 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
279/280 [============================>.] - ETA: 0s - loss: 0.4067 - accuracy: 0.8387 .8907 - val_loss: 0.4123 - val_accuracy: 0.8258
  3/280 [..............................] - ETA: 12s - loss: 0.4601 - accuracy: 0.7500.8388 - val_loss: 0.3549 - val_accuracy: 0.8220
 46/280 [===>..........................] - ETA: 10s - loss: 0.4159 - accuracy: 0.8161.8388 - val_loss: 0.3549 - val_accuracy: 0.8220
 92/280 [========>.....................] - ETA: 8s - loss: 0.3887 - accuracy: 0.8291 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
137/280 [=============>................] - ETA: 6s - loss: 0.3781 - accuracy: 0.8348 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
182/280 [==================>...........] - ETA: 4s - loss: 0.3795 - accuracy: 0.8386 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
228/280 [=======================>......] - ETA: 2s - loss: 0.3795 - accuracy: 0.8421 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
274/280 [============================>.] - ETA: 0s - loss: 0.3788 - accuracy: 0.8447 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
280/280 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8449 .8388 - val_loss: 0.3549 - val_accuracy: 0.8220
 29/280 [==>...........................] - ETA: 11s - loss: 0.4351 - accuracy: 0.8287.8449 - val_loss: 0.3360 - val_accuracy: 0.8485
 73/280 [======>.......................] - ETA: 9s - loss: 0.3806 - accuracy: 0.8515 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
106/280 [==========>...................] - ETA: 7s - loss: 0.3784 - accuracy: 0.8519 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
152/280 [===============>..............] - ETA: 5s - loss: 0.3742 - accuracy: 0.8549 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
196/280 [====================>.........] - ETA: 3s - loss: 0.3709 - accuracy: 0.8564 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
242/280 [========================>.....] - ETA: 1s - loss: 0.3675 - accuracy: 0.8582 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8597 .8449 - val_loss: 0.3360 - val_accuracy: 0.8485
 42/280 [===>..........................] - ETA: 10s - loss: 0.2727 - accuracy: 0.9351.8597 - val_loss: 0.5452 - val_accuracy: 0.7576
 88/280 [========>.....................] - ETA: 8s - loss: 0.3061 - accuracy: 0.9101 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
133/280 [=============>................] - ETA: 6s - loss: 0.3226 - accuracy: 0.8973 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
176/280 [=================>............] - ETA: 4s - loss: 0.3268 - accuracy: 0.8927 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
221/280 [======================>.......] - ETA: 2s - loss: 0.3273 - accuracy: 0.8894 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
266/280 [===========================>..] - ETA: 0s - loss: 0.3285 - accuracy: 0.8875 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
280/280 [==============================] - ETA: 0s - loss: 0.3294 - accuracy: 0.8870 .8597 - val_loss: 0.5452 - val_accuracy: 0.7576
 19/280 [=>............................] - ETA: 12s - loss: 0.2464 - accuracy: 0.9081.8869 - val_loss: 0.3952 - val_accuracy: 0.8409
 63/280 [=====>........................] - ETA: 10s - loss: 0.2813 - accuracy: 0.9098.8869 - val_loss: 0.3952 - val_accuracy: 0.8409
108/280 [==========>...................] - ETA: 7s - loss: 0.3064 - accuracy: 0.9019 .8869 - val_loss: 0.3952 - val_accuracy: 0.8409
152/280 [===============>..............] - ETA: 5s - loss: 0.3235 - accuracy: 0.8955 .8869 - val_loss: 0.3952 - val_accuracy: 0.8409
197/280 [====================>.........] - ETA: 3s - loss: 0.3289 - accuracy: 0.8934 .8869 - val_loss: 0.3952 - val_accuracy: 0.8409
243/280 [=========================>....] - ETA: 1s - loss: 0.3309 - accuracy: 0.8921 .8869 - val_loss: 0.3952 - val_accuracy: 0.8409
280/280 [==============================] - ETA: 0s - loss: 0.3328 - accuracy: 0.8905 .8869 - val_loss: 0.3952 - val_accuracy: 0.8409
 40/280 [===>..........................] - ETA: 11s - loss: 0.2611 - accuracy: 0.9011.8904 - val_loss: 0.3611 - val_accuracy: 0.8485
 84/280 [========>.....................] - ETA: 8s - loss: 0.2703 - accuracy: 0.9009 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
128/280 [============>.................] - ETA: 6s - loss: 0.2882 - accuracy: 0.8906 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
173/280 [=================>............] - ETA: 4s - loss: 0.2978 - accuracy: 0.8863 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
217/280 [======================>.......] - ETA: 2s - loss: 0.3042 - accuracy: 0.8832 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
264/280 [===========================>..] - ETA: 0s - loss: 0.3120 - accuracy: 0.8794 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.8785 .8904 - val_loss: 0.3611 - val_accuracy: 0.8485
 18/280 [>.............................] - ETA: 12s - loss: 0.5724 - accuracy: 0.7733.8784 - val_loss: 0.3697 - val_accuracy: 0.8333
 64/280 [=====>........................] - ETA: 9s - loss: 0.4350 - accuracy: 0.8505 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
110/280 [==========>...................] - ETA: 7s - loss: 0.3900 - accuracy: 0.8711 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
155/280 [===============>..............] - ETA: 5s - loss: 0.3735 - accuracy: 0.8790 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
200/280 [====================>.........] - ETA: 3s - loss: 0.3631 - accuracy: 0.8827 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
243/280 [=========================>....] - ETA: 1s - loss: 0.3569 - accuracy: 0.8841 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
280/280 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.8847 .8784 - val_loss: 0.3697 - val_accuracy: 0.8333
 42/280 [===>..........................] - ETA: 10s - loss: 0.3534 - accuracy: 0.8755.8847 - val_loss: 0.3264 - val_accuracy: 0.8750
 88/280 [========>.....................] - ETA: 8s - loss: 0.3303 - accuracy: 0.8806 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
132/280 [=============>................] - ETA: 6s - loss: 0.3291 - accuracy: 0.8794 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
175/280 [=================>............] - ETA: 4s - loss: 0.3249 - accuracy: 0.8812 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
210/280 [=====================>........] - ETA: 3s - loss: 0.3233 - accuracy: 0.8816 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
255/280 [==========================>...] - ETA: 1s - loss: 0.3214 - accuracy: 0.8819 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
279/280 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8817 .8847 - val_loss: 0.3264 - val_accuracy: 0.8750
  9/280 [..............................] - ETA: 12s - loss: 0.4956 - accuracy: 0.8569.8817 - val_loss: 0.3379 - val_accuracy: 0.8788
 53/280 [====>.........................] - ETA: 10s - loss: 0.3874 - accuracy: 0.8692.8817 - val_loss: 0.3379 - val_accuracy: 0.8788
 98/280 [=========>....................] - ETA: 8s - loss: 0.3538 - accuracy: 0.8793 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
143/280 [==============>...............] - ETA: 6s - loss: 0.3382 - accuracy: 0.8842 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
186/280 [==================>...........] - ETA: 4s - loss: 0.3320 - accuracy: 0.8856 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
231/280 [=======================>......] - ETA: 2s - loss: 0.3335 - accuracy: 0.8842 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
276/280 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8837 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
279/280 [============================>.] - ETA: 0s - loss: 0.3338 - accuracy: 0.8837 .8817 - val_loss: 0.3379 - val_accuracy: 0.8788
 30/280 [==>...........................] - ETA: 11s - loss: 0.3964 - accuracy: 0.8224.8837 - val_loss: 0.3061 - val_accuracy: 0.8712
 74/280 [======>.......................] - ETA: 9s - loss: 0.3654 - accuracy: 0.8489 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
119/280 [===========>..................] - ETA: 7s - loss: 0.3535 - accuracy: 0.8594 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
165/280 [================>.............] - ETA: 5s - loss: 0.3419 - accuracy: 0.8659 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
209/280 [=====================>........] - ETA: 3s - loss: 0.3352 - accuracy: 0.8698 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
254/280 [==========================>...] - ETA: 1s - loss: 0.3319 - accuracy: 0.8714 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.8721 .8837 - val_loss: 0.3061 - val_accuracy: 0.8712
  8/280 [..............................] - ETA: 11s - loss: 0.3592 - accuracy: 0.7961.8722 - val_loss: 0.4436 - val_accuracy: 0.8182
 53/280 [====>.........................] - ETA: 10s - loss: 0.4443 - accuracy: 0.8117.8722 - val_loss: 0.4436 - val_accuracy: 0.8182
 97/280 [=========>....................] - ETA: 8s - loss: 0.3965 - accuracy: 0.8361 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
142/280 [==============>...............] - ETA: 6s - loss: 0.3673 - accuracy: 0.8508 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
186/280 [==================>...........] - ETA: 4s - loss: 0.3534 - accuracy: 0.8591 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
230/280 [=======================>......] - ETA: 2s - loss: 0.3434 - accuracy: 0.8652 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
276/280 [============================>.] - ETA: 0s - loss: 0.3370 - accuracy: 0.8693 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
280/280 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.8695 .8722 - val_loss: 0.4436 - val_accuracy: 0.8182
 29/280 [==>...........................] - ETA: 11s - loss: 0.3335 - accuracy: 0.8813.8696 - val_loss: 0.4581 - val_accuracy: 0.7992
 73/280 [======>.......................] - ETA: 9s - loss: 0.3216 - accuracy: 0.8915 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
118/280 [===========>..................] - ETA: 7s - loss: 0.3228 - accuracy: 0.8891 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
163/280 [================>.............] - ETA: 5s - loss: 0.3185 - accuracy: 0.8895 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
209/280 [=====================>........] - ETA: 3s - loss: 0.3152 - accuracy: 0.8897 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
242/280 [========================>.....] - ETA: 1s - loss: 0.3156 - accuracy: 0.8893 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
279/280 [============================>.] - ETA: 0s - loss: 0.3154 - accuracy: 0.8890 .8696 - val_loss: 0.4581 - val_accuracy: 0.7992
280/280 [==============================] - 15s 54ms/step - loss: 0.3154 - accuracy: 0.8890 - val_loss: 0.3350 - val_accuracy: 0.8561
 42/280 [===>..........................] - ETA: 10s - loss: 0.2411 - accuracy: 0.9107.8890 - val_loss: 0.3350 - val_accuracy: 0.8561
 86/280 [========>.....................] - ETA: 8s - loss: 0.2519 - accuracy: 0.9046 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
133/280 [=============>................] - ETA: 6s - loss: 0.2618 - accuracy: 0.9014 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
178/280 [==================>...........] - ETA: 4s - loss: 0.2690 - accuracy: 0.9003 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
222/280 [======================>.......] - ETA: 2s - loss: 0.2748 - accuracy: 0.8990 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
267/280 [===========================>..] - ETA: 0s - loss: 0.2808 - accuracy: 0.8973 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.2821 - accuracy: 0.8970 .8890 - val_loss: 0.3350 - val_accuracy: 0.8561
 23/280 [=>............................] - ETA: 11s - loss: 0.2582 - accuracy: 0.9262.8969 - val_loss: 0.3282 - val_accuracy: 0.8788
 67/280 [======>.......................] - ETA: 9s - loss: 0.2685 - accuracy: 0.9256 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
113/280 [===========>..................] - ETA: 7s - loss: 0.2783 - accuracy: 0.9199 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
156/280 [===============>..............] - ETA: 5s - loss: 0.2862 - accuracy: 0.9172 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
202/280 [====================>.........] - ETA: 3s - loss: 0.2921 - accuracy: 0.9149 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
246/280 [=========================>....] - ETA: 1s - loss: 0.2929 - accuracy: 0.9142 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
279/280 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.9138 .8969 - val_loss: 0.3282 - val_accuracy: 0.8788
  1/280 [..............................] - ETA: 21s - loss: 0.0380 - accuracy: 1.0000.9137 - val_loss: 0.3057 - val_accuracy: 0.8636
 45/280 [===>..........................] - ETA: 10s - loss: 0.2231 - accuracy: 0.9216.9137 - val_loss: 0.3057 - val_accuracy: 0.8636
 89/280 [========>.....................] - ETA: 8s - loss: 0.2304 - accuracy: 0.9256 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
134/280 [=============>................] - ETA: 6s - loss: 0.2435 - accuracy: 0.9251 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
180/280 [==================>...........] - ETA: 4s - loss: 0.2544 - accuracy: 0.9235 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
225/280 [=======================>......] - ETA: 2s - loss: 0.2598 - accuracy: 0.9225 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
270/280 [===========================>..] - ETA: 0s - loss: 0.2642 - accuracy: 0.9214 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
280/280 [==============================] - ETA: 0s - loss: 0.2651 - accuracy: 0.9211 .9137 - val_loss: 0.3057 - val_accuracy: 0.8636
 22/280 [=>............................] - ETA: 11s - loss: 0.2575 - accuracy: 0.9323.9211 - val_loss: 0.3208 - val_accuracy: 0.8712
 69/280 [======>.......................] - ETA: 9s - loss: 0.2512 - accuracy: 0.9251 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
113/280 [===========>..................] - ETA: 7s - loss: 0.2573 - accuracy: 0.9164 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
158/280 [===============>..............] - ETA: 5s - loss: 0.2606 - accuracy: 0.9129 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
203/280 [====================>.........] - ETA: 3s - loss: 0.2618 - accuracy: 0.9111 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
248/280 [=========================>....] - ETA: 1s - loss: 0.2604 - accuracy: 0.9106 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.9101 .9211 - val_loss: 0.3208 - val_accuracy: 0.8712
  1/280 [..............................] - ETA: 24s - loss: 0.0206 - accuracy: 1.0000.9101 - val_loss: 0.3578 - val_accuracy: 0.8409
 47/280 [====>.........................] - ETA: 10s - loss: 0.1852 - accuracy: 0.9455.9101 - val_loss: 0.3578 - val_accuracy: 0.8409
 92/280 [========>.....................] - ETA: 8s - loss: 0.2034 - accuracy: 0.9404 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
139/280 [=============>................] - ETA: 6s - loss: 0.2133 - accuracy: 0.9372 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
173/280 [=================>............] - ETA: 4s - loss: 0.2187 - accuracy: 0.9341 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
217/280 [======================>.......] - ETA: 2s - loss: 0.2227 - accuracy: 0.9307 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
264/280 [===========================>..] - ETA: 0s - loss: 0.2286 - accuracy: 0.9269 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
280/280 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9257 .9101 - val_loss: 0.3578 - val_accuracy: 0.8409
 19/280 [=>............................] - ETA: 11s - loss: 0.4230 - accuracy: 0.7945.9256 - val_loss: 0.3522 - val_accuracy: 0.8447
 63/280 [=====>........................] - ETA: 9s - loss: 0.3138 - accuracy: 0.8531 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
108/280 [==========>...................] - ETA: 7s - loss: 0.2784 - accuracy: 0.8753 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
154/280 [===============>..............] - ETA: 5s - loss: 0.2628 - accuracy: 0.8866 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
197/280 [====================>.........] - ETA: 3s - loss: 0.2598 - accuracy: 0.8915 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
242/280 [========================>.....] - ETA: 1s - loss: 0.2595 - accuracy: 0.8940 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
280/280 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.8954 .9256 - val_loss: 0.3522 - val_accuracy: 0.8447
 40/280 [===>..........................] - ETA: 10s - loss: 0.2922 - accuracy: 0.8482.8955 - val_loss: 0.3115 - val_accuracy: 0.8712
 86/280 [========>.....................] - ETA: 8s - loss: 0.2780 - accuracy: 0.8670 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
132/280 [=============>................] - ETA: 6s - loss: 0.2678 - accuracy: 0.8788 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
177/280 [=================>............] - ETA: 4s - loss: 0.2619 - accuracy: 0.8864 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
222/280 [======================>.......] - ETA: 2s - loss: 0.2578 - accuracy: 0.8916 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
268/280 [===========================>..] - ETA: 0s - loss: 0.2567 - accuracy: 0.8941 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
279/280 [============================>.] - ETA: 0s - loss: 0.2571 - accuracy: 0.8943 .8955 - val_loss: 0.3115 - val_accuracy: 0.8712
 21/280 [=>............................] - ETA: 11s - loss: 0.1714 - accuracy: 0.9575.8944 - val_loss: 0.4375 - val_accuracy: 0.8371
 66/280 [======>.......................] - ETA: 9s - loss: 0.2133 - accuracy: 0.9326 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
113/280 [===========>..................] - ETA: 7s - loss: 0.2280 - accuracy: 0.9225 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
158/280 [===============>..............] - ETA: 5s - loss: 0.2406 - accuracy: 0.9164 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
204/280 [====================>.........] - ETA: 3s - loss: 0.2492 - accuracy: 0.9119 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
248/280 [=========================>....] - ETA: 1s - loss: 0.2535 - accuracy: 0.9093 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
280/280 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.9078 .8944 - val_loss: 0.4375 - val_accuracy: 0.8371
  3/280 [..............................] - ETA: 13s - loss: 0.1768 - accuracy: 1.0000.9078 - val_loss: 0.3741 - val_accuracy: 0.8409
 46/280 [===>..........................] - ETA: 10s - loss: 0.2491 - accuracy: 0.9055.9078 - val_loss: 0.3741 - val_accuracy: 0.8409
 93/280 [========>.....................] - ETA: 8s - loss: 0.2457 - accuracy: 0.9047 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
138/280 [=============>................] - ETA: 6s - loss: 0.2449 - accuracy: 0.9032 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
183/280 [==================>...........] - ETA: 4s - loss: 0.2459 - accuracy: 0.9026 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
227/280 [=======================>......] - ETA: 2s - loss: 0.2474 - accuracy: 0.9023 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
273/280 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9027 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.2478 - accuracy: 0.9027 .9078 - val_loss: 0.3741 - val_accuracy: 0.8409
 28/280 [==>...........................] - ETA: 11s - loss: 0.3548 - accuracy: 0.8761.9027 - val_loss: 0.3574 - val_accuracy: 0.8561
 62/280 [=====>........................] - ETA: 9s - loss: 0.3240 - accuracy: 0.8756 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
107/280 [==========>...................] - ETA: 7s - loss: 0.2943 - accuracy: 0.8837 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
153/280 [===============>..............] - ETA: 5s - loss: 0.2777 - accuracy: 0.8905 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
197/280 [====================>.........] - ETA: 3s - loss: 0.2702 - accuracy: 0.8938 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
242/280 [========================>.....] - ETA: 1s - loss: 0.2643 - accuracy: 0.8964 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.2613 - accuracy: 0.8980 .9027 - val_loss: 0.3574 - val_accuracy: 0.8561
 42/280 [===>..........................] - ETA: 10s - loss: 0.2822 - accuracy: 0.8989.8981 - val_loss: 0.3463 - val_accuracy: 0.8561
 88/280 [========>.....................] - ETA: 8s - loss: 0.2783 - accuracy: 0.8960 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
133/280 [=============>................] - ETA: 6s - loss: 0.2753 - accuracy: 0.8976 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
178/280 [==================>...........] - ETA: 4s - loss: 0.2713 - accuracy: 0.8991 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
222/280 [======================>.......] - ETA: 2s - loss: 0.2716 - accuracy: 0.8996 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
267/280 [===========================>..] - ETA: 0s - loss: 0.2728 - accuracy: 0.8996 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.2730 - accuracy: 0.8997 .8981 - val_loss: 0.3463 - val_accuracy: 0.8561
 21/280 [=>............................] - ETA: 12s - loss: 0.1086 - accuracy: 0.9914.8997 - val_loss: 0.3471 - val_accuracy: 0.8636
 66/280 [======>.......................] - ETA: 9s - loss: 0.1483 - accuracy: 0.9581 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
111/280 [==========>...................] - ETA: 7s - loss: 0.1619 - accuracy: 0.9508 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
158/280 [===============>..............] - ETA: 5s - loss: 0.1761 - accuracy: 0.9442 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
203/280 [====================>.........] - ETA: 3s - loss: 0.1856 - accuracy: 0.9391 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
249/280 [=========================>....] - ETA: 1s - loss: 0.1924 - accuracy: 0.9356 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
279/280 [============================>.] - ETA: 0s - loss: 0.1960 - accuracy: 0.9339 .8997 - val_loss: 0.3471 - val_accuracy: 0.8636
  3/280 [..............................] - ETA: 11s - loss: 0.2761 - accuracy: 0.8333.9338 - val_loss: 0.3311 - val_accuracy: 0.8523
 48/280 [====>.........................] - ETA: 10s - loss: 0.2918 - accuracy: 0.9103.9338 - val_loss: 0.3311 - val_accuracy: 0.8523
 94/280 [=========>....................] - ETA: 8s - loss: 0.2715 - accuracy: 0.9169 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
139/280 [=============>................] - ETA: 6s - loss: 0.2570 - accuracy: 0.9189 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
183/280 [==================>...........] - ETA: 4s - loss: 0.2527 - accuracy: 0.9174 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
227/280 [=======================>......] - ETA: 2s - loss: 0.2493 - accuracy: 0.9170 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
273/280 [============================>.] - ETA: 0s - loss: 0.2483 - accuracy: 0.9159 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
279/280 [============================>.] - ETA: 0s - loss: 0.2482 - accuracy: 0.9158 .9338 - val_loss: 0.3311 - val_accuracy: 0.8523
 27/280 [=>............................] - ETA: 11s - loss: 0.1749 - accuracy: 0.9273.9157 - val_loss: 0.3509 - val_accuracy: 0.8523
 72/280 [======>.......................] - ETA: 9s - loss: 0.1939 - accuracy: 0.9279 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
115/280 [===========>..................] - ETA: 7s - loss: 0.2013 - accuracy: 0.9277 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
160/280 [================>.............] - ETA: 5s - loss: 0.2073 - accuracy: 0.9260 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
206/280 [=====================>........] - ETA: 3s - loss: 0.2112 - accuracy: 0.9248 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
253/280 [==========================>...] - ETA: 1s - loss: 0.2153 - accuracy: 0.9237 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
279/280 [============================>.] - ETA: 0s - loss: 0.2180 - accuracy: 0.9228 .9157 - val_loss: 0.3509 - val_accuracy: 0.8523
 40/280 [===>..........................] - ETA: 10s - loss: 0.1612 - accuracy: 0.9123.9228 - val_loss: 0.3406 - val_accuracy: 0.8636
 85/280 [========>.....................] - ETA: 8s - loss: 0.2143 - accuracy: 0.8991 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
131/280 [=============>................] - ETA: 6s - loss: 0.2408 - accuracy: 0.8944 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
176/280 [=================>............] - ETA: 4s - loss: 0.2478 - accuracy: 0.8951 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
221/280 [======================>.......] - ETA: 2s - loss: 0.2501 - accuracy: 0.8965 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
265/280 [===========================>..] - ETA: 0s - loss: 0.2512 - accuracy: 0.8979 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
280/280 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.8984 .9228 - val_loss: 0.3406 - val_accuracy: 0.8636
 20/280 [=>............................] - ETA: 11s - loss: 0.0843 - accuracy: 0.9867.8984 - val_loss: 0.3838 - val_accuracy: 0.8409
 65/280 [=====>........................] - ETA: 9s - loss: 0.1602 - accuracy: 0.9425 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
109/280 [==========>...................] - ETA: 7s - loss: 0.1795 - accuracy: 0.9336 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
154/280 [===============>..............] - ETA: 5s - loss: 0.1926 - accuracy: 0.9273 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
198/280 [====================>.........] - ETA: 3s - loss: 0.1983 - accuracy: 0.9239 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
244/280 [=========================>....] - ETA: 1s - loss: 0.2032 - accuracy: 0.9211 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.2069 - accuracy: 0.9191 .8984 - val_loss: 0.3838 - val_accuracy: 0.8409
 43/280 [===>..........................] - ETA: 10s - loss: 0.2616 - accuracy: 0.8950.9190 - val_loss: 0.3838 - val_accuracy: 0.8485
 88/280 [========>.....................] - ETA: 8s - loss: 0.2482 - accuracy: 0.9011 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
131/280 [=============>................] - ETA: 6s - loss: 0.2370 - accuracy: 0.9062 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
177/280 [=================>............] - ETA: 4s - loss: 0.2308 - accuracy: 0.9100 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
221/280 [======================>.......] - ETA: 2s - loss: 0.2295 - accuracy: 0.9116 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
268/280 [===========================>..] - ETA: 0s - loss: 0.2276 - accuracy: 0.9134 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.2271 - accuracy: 0.9137 .9190 - val_loss: 0.3838 - val_accuracy: 0.8485
 21/280 [=>............................] - ETA: 11s - loss: 0.2144 - accuracy: 0.9257.9138 - val_loss: 0.3621 - val_accuracy: 0.8674
 65/280 [=====>........................] - ETA: 9s - loss: 0.2051 - accuracy: 0.9227 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
111/280 [==========>...................] - ETA: 7s - loss: 0.2103 - accuracy: 0.9220 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
155/280 [===============>..............] - ETA: 5s - loss: 0.2168 - accuracy: 0.9206 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
202/280 [====================>.........] - ETA: 3s - loss: 0.2185 - accuracy: 0.9201 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
245/280 [=========================>....] - ETA: 1s - loss: 0.2184 - accuracy: 0.9201 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
280/280 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9199 .9138 - val_loss: 0.3621 - val_accuracy: 0.8674
  1/280 [..............................] - ETA: 20s - loss: 0.3859 - accuracy: 0.7500.9199 - val_loss: 0.4058 - val_accuracy: 0.8561
 47/280 [====>.........................] - ETA: 10s - loss: 0.2120 - accuracy: 0.9470.9199 - val_loss: 0.4058 - val_accuracy: 0.8561
 90/280 [========>.....................] - ETA: 8s - loss: 0.2294 - accuracy: 0.9372 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
125/280 [============>.................] - ETA: 6s - loss: 0.2385 - accuracy: 0.9289 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
172/280 [=================>............] - ETA: 4s - loss: 0.2420 - accuracy: 0.9230 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
217/280 [======================>.......] - ETA: 2s - loss: 0.2430 - accuracy: 0.9190 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
260/280 [==========================>...] - ETA: 0s - loss: 0.2409 - accuracy: 0.9178 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9174 .9199 - val_loss: 0.4058 - val_accuracy: 0.8561
 17/280 [>.............................] - ETA: 11s - loss: 0.1426 - accuracy: 0.9656.9174 - val_loss: 0.3941 - val_accuracy: 0.8598
 61/280 [=====>........................] - ETA: 9s - loss: 0.1832 - accuracy: 0.9477 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
107/280 [==========>...................] - ETA: 7s - loss: 0.1916 - accuracy: 0.9377 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
154/280 [===============>..............] - ETA: 5s - loss: 0.1934 - accuracy: 0.9338 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
198/280 [====================>.........] - ETA: 3s - loss: 0.1941 - accuracy: 0.9318 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
243/280 [=========================>....] - ETA: 1s - loss: 0.1994 - accuracy: 0.9285 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
279/280 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.9271 .9174 - val_loss: 0.3941 - val_accuracy: 0.8598
 41/280 [===>..........................] - ETA: 10s - loss: 0.3493 - accuracy: 0.8823.9270 - val_loss: 0.3904 - val_accuracy: 0.8561
 88/280 [========>.....................] - ETA: 8s - loss: 0.3196 - accuracy: 0.8889 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
133/280 [=============>................] - ETA: 6s - loss: 0.2908 - accuracy: 0.8980 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
179/280 [==================>...........] - ETA: 4s - loss: 0.2768 - accuracy: 0.9005 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
223/280 [======================>.......] - ETA: 2s - loss: 0.2667 - accuracy: 0.9032 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
268/280 [===========================>..] - ETA: 0s - loss: 0.2591 - accuracy: 0.9055 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.2577 - accuracy: 0.9060 .9270 - val_loss: 0.3904 - val_accuracy: 0.8561
 23/280 [=>............................] - ETA: 11s - loss: 0.3239 - accuracy: 0.8765.9060 - val_loss: 0.4241 - val_accuracy: 0.8561
 67/280 [======>.......................] - ETA: 9s - loss: 0.2465 - accuracy: 0.9079 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
111/280 [==========>...................] - ETA: 7s - loss: 0.2165 - accuracy: 0.9188 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
156/280 [===============>..............] - ETA: 5s - loss: 0.2088 - accuracy: 0.9213 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
201/280 [====================>.........] - ETA: 3s - loss: 0.2050 - accuracy: 0.9223 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
248/280 [=========================>....] - ETA: 1s - loss: 0.2028 - accuracy: 0.9226 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
279/280 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9228 .9060 - val_loss: 0.4241 - val_accuracy: 0.8561
280/280 [==============================] - 15s 54ms/step - loss: 0.2022 - accuracy: 0.9228 - val_loss: 0.3863 - val_accuracy: 0.8636
53/55 [===========================>..] - ETA: 0s - loss: 0.4242 - accuracy: 0.8396: 0.9228 - val_loss: 0.3863 - val_accuracy: 0.8636
55/55 [==============================] - 2s 37ms/step - loss: 0.4341 - accuracy: 0.8364228 - val_loss: 0.3863 - val_accuracy: 0.8636
55/55 [==============================] - 2s 37ms/step - loss: 0.4341 - accuracy: 0.8364228 - val_loss: 0.3863 - val_accuracy: 0.8636