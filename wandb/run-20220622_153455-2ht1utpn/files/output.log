2022-06-22 15:35:00.512468: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 15:35:00.513650: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-22 15:35:00.558622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:35:00.558885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:35:00.558909: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:35:00.561608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:35:00.561644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 15:35:00.563998: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 15:35:00.564440: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 15:35:00.566908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 15:35:00.568152: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 15:35:00.572932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:35:00.573833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 15:35:00.574341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-22 15:35:00.574432: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 15:35:00.760086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:35:00.760380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:03:00.0 name: Quadro RTX 4000 computeCapability: 7.5
coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s
2022-06-22 15:35:00.760408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:35:00.760439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:35:00.760454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 15:35:00.760468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 15:35:00.760482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 15:35:00.760495: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 15:35:00.760508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 15:35:00.760523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:35:00.761343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 15:35:00.761374: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 15:35:01.544948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-22 15:35:01.544997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-22 15:35:01.545011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-22 15:35:01.545017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-22 15:35:01.546128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7232 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:02:00.0, compute capability: 7.5)
2022-06-22 15:35:01.546780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7240 MB memory) -> physical GPU (device: 1, name: Quadro RTX 4000, pci bus id: 0000:03:00.0, compute capability: 7.5)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-22 15:35:01.900493: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-22 15:35:01.900994: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3000010000 Hz
2022-06-22 15:35:02.581940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 15:35:02.928201: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 15:35:03.886237: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-22 15:35:03.914961: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 16)      448
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 16)      0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 16)      0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 32)      4640
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 32)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 32)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 64)      18496
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 64)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 128)       73856
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 128)       0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 128)       0
_________________________________________________________________
global_average_pooling2d (Gl (None, 128)               0
_________________________________________________________________
dense (Dense)                (None, 4)                 516
=================================================================
Total params: 97,956
Trainable params: 97,956
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50






70/70 [==============================] - 24s 257ms/step - loss: 1.4059 - accuracy: 0.2448 - val_loss: 1.2841 - val_accuracy: 0.3674
Epoch 2/50







70/70 [==============================] - 16s 222ms/step - loss: 1.2396 - accuracy: 0.4024 - val_loss: 1.1410 - val_accuracy: 0.5265
Epoch 3/50






70/70 [==============================] - 16s 223ms/step - loss: 1.1526 - accuracy: 0.4955 - val_loss: 1.0597 - val_accuracy: 0.4962
Epoch 4/50






70/70 [==============================] - 16s 222ms/step - loss: 1.1220 - accuracy: 0.5176 - val_loss: 0.9883 - val_accuracy: 0.5530
Epoch 5/50






70/70 [==============================] - 16s 222ms/step - loss: 1.0446 - accuracy: 0.5337 - val_loss: 0.9928 - val_accuracy: 0.6212
Epoch 6/50







70/70 [==============================] - 16s 223ms/step - loss: 1.0442 - accuracy: 0.5749 - val_loss: 1.0206 - val_accuracy: 0.5455
Epoch 7/50






70/70 [==============================] - 16s 221ms/step - loss: 1.0108 - accuracy: 0.5904 - val_loss: 0.9483 - val_accuracy: 0.6288
Epoch 8/50






70/70 [==============================] - 16s 223ms/step - loss: 0.9038 - accuracy: 0.6497 - val_loss: 0.9996 - val_accuracy: 0.5947
Epoch 9/50






70/70 [==============================] - 16s 222ms/step - loss: 0.9374 - accuracy: 0.6245 - val_loss: 0.8491 - val_accuracy: 0.6894
Epoch 10/50






70/70 [==============================] - 15s 219ms/step - loss: 0.9214 - accuracy: 0.6493 - val_loss: 0.9468 - val_accuracy: 0.6174
Epoch 11/50






70/70 [==============================] - 16s 222ms/step - loss: 0.9044 - accuracy: 0.6479 - val_loss: 0.8576 - val_accuracy: 0.6932
Epoch 12/50






70/70 [==============================] - 15s 220ms/step - loss: 0.7765 - accuracy: 0.7087 - val_loss: 0.8281 - val_accuracy: 0.6515
Epoch 13/50






70/70 [==============================] - 16s 222ms/step - loss: 0.8109 - accuracy: 0.6919 - val_loss: 0.8024 - val_accuracy: 0.7083
Epoch 14/50






70/70 [==============================] - 15s 221ms/step - loss: 0.7246 - accuracy: 0.7349 - val_loss: 0.8242 - val_accuracy: 0.7045
Epoch 15/50







70/70 [==============================] - 16s 222ms/step - loss: 0.7180 - accuracy: 0.7187 - val_loss: 0.7018 - val_accuracy: 0.7159
Epoch 16/50







70/70 [==============================] - 15s 220ms/step - loss: 0.6487 - accuracy: 0.7582 - val_loss: 0.6736 - val_accuracy: 0.7727
Epoch 17/50






70/70 [==============================] - 15s 221ms/step - loss: 0.6419 - accuracy: 0.7385 - val_loss: 0.7405 - val_accuracy: 0.6932
Epoch 18/50







70/70 [==============================] - 15s 220ms/step - loss: 0.6467 - accuracy: 0.7498 - val_loss: 0.6767 - val_accuracy: 0.7386
Epoch 19/50






70/70 [==============================] - 16s 222ms/step - loss: 0.6047 - accuracy: 0.7702 - val_loss: 0.7190 - val_accuracy: 0.7462
Epoch 20/50






70/70 [==============================] - 15s 221ms/step - loss: 0.6596 - accuracy: 0.7430 - val_loss: 0.7904 - val_accuracy: 0.7083
Epoch 21/50






70/70 [==============================] - 16s 221ms/step - loss: 0.6041 - accuracy: 0.7790 - val_loss: 0.7226 - val_accuracy: 0.7386
Epoch 22/50







70/70 [==============================] - 16s 223ms/step - loss: 0.6297 - accuracy: 0.7357 - val_loss: 0.6266 - val_accuracy: 0.7386
Epoch 23/50






70/70 [==============================] - 16s 221ms/step - loss: 0.6083 - accuracy: 0.7718 - val_loss: 0.6501 - val_accuracy: 0.7008
Epoch 24/50






70/70 [==============================] - 15s 220ms/step - loss: 0.5403 - accuracy: 0.7928 - val_loss: 0.7857 - val_accuracy: 0.6780
Epoch 25/50






70/70 [==============================] - 16s 223ms/step - loss: 0.5513 - accuracy: 0.7762 - val_loss: 0.5671 - val_accuracy: 0.7462
Epoch 26/50






70/70 [==============================] - 15s 220ms/step - loss: 0.5829 - accuracy: 0.7959 - val_loss: 0.5358 - val_accuracy: 0.7727
Epoch 27/50







70/70 [==============================] - 16s 223ms/step - loss: 0.5365 - accuracy: 0.7906 - val_loss: 0.7628 - val_accuracy: 0.7008
Epoch 28/50







70/70 [==============================] - 15s 220ms/step - loss: 0.4818 - accuracy: 0.8182 - val_loss: 0.5634 - val_accuracy: 0.7500
Epoch 29/50






70/70 [==============================] - 15s 221ms/step - loss: 0.5354 - accuracy: 0.8118 - val_loss: 0.4914 - val_accuracy: 0.8068
Epoch 30/50







70/70 [==============================] - 15s 221ms/step - loss: 0.5076 - accuracy: 0.8119 - val_loss: 0.4801 - val_accuracy: 0.8030
Epoch 31/50
22/70 [========>.....................] - ETA: 8s - loss: 0.4203 - accuracy: 0.8142
34/70 [=============>................] - ETA: 6s - loss: 0.4274 - accuracy: 0.8158
45/70 [==================>...........] - ETA: 4s - loss: 0.4411 - accuracy: 0.8125
56/70 [=======================>......] - ETA: 2s - loss: 0.4515 - accuracy: 0.8096
67/70 [===========================>..] - ETA: 0s - loss: 0.4616 - accuracy: 0.8068
70/70 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8061
 3/70 [>.............................] - ETA: 12s - loss: 0.4606 - accuracy: 0.85070.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
15/70 [=====>........................] - ETA: 9s - loss: 0.5155 - accuracy: 0.8233 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
26/70 [==========>...................] - ETA: 7s - loss: 0.5104 - accuracy: 0.8194 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
37/70 [==============>...............] - ETA: 5s - loss: 0.5004 - accuracy: 0.8204 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
48/70 [===================>..........] - ETA: 3s - loss: 0.4936 - accuracy: 0.8206 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
59/70 [========================>.....] - ETA: 1s - loss: 0.4879 - accuracy: 0.8210 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
70/70 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.8214 0.8058 - val_loss: 0.4945 - val_accuracy: 0.7765
 7/70 [==>...........................] - ETA: 11s - loss: 0.4288 - accuracy: 0.85990.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
18/70 [======>.......................] - ETA: 9s - loss: 0.4756 - accuracy: 0.8361 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
30/70 [===========>..................] - ETA: 7s - loss: 0.4866 - accuracy: 0.8264 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
41/70 [================>.............] - ETA: 5s - loss: 0.4874 - accuracy: 0.8241 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
52/70 [=====================>........] - ETA: 3s - loss: 0.4862 - accuracy: 0.8238 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
63/70 [==========================>...] - ETA: 1s - loss: 0.4822 - accuracy: 0.8249 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
70/70 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8253 0.8214 - val_loss: 0.5305 - val_accuracy: 0.7576
 8/70 [==>...........................] - ETA: 11s - loss: 0.4259 - accuracy: 0.86530.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
19/70 [=======>......................] - ETA: 9s - loss: 0.4576 - accuracy: 0.8316 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
30/70 [===========>..................] - ETA: 7s - loss: 0.4586 - accuracy: 0.8273 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
41/70 [================>.............] - ETA: 5s - loss: 0.4522 - accuracy: 0.8290 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
52/70 [=====================>........] - ETA: 3s - loss: 0.4509 - accuracy: 0.8289 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
64/70 [==========================>...] - ETA: 1s - loss: 0.4511 - accuracy: 0.8290 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
70/70 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.8285 0.8253 - val_loss: 0.4560 - val_accuracy: 0.7955
70/70 [==============================] - 15s 220ms/step - loss: 0.4523 - accuracy: 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
11/70 [===>..........................] - ETA: 10s - loss: 0.3860 - accuracy: 0.85800.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
22/70 [========>.....................] - ETA: 8s - loss: 0.4500 - accuracy: 0.8394 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
33/70 [=============>................] - ETA: 6s - loss: 0.4768 - accuracy: 0.8328 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
45/70 [==================>...........] - ETA: 4s - loss: 0.4869 - accuracy: 0.8296 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
56/70 [=======================>......] - ETA: 2s - loss: 0.4878 - accuracy: 0.8288 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
67/70 [===========================>..] - ETA: 0s - loss: 0.4852 - accuracy: 0.8290 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
70/70 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.8292 0.8285 - val_loss: 0.6390 - val_accuracy: 0.7235
 3/70 [>.............................] - ETA: 12s - loss: 0.5644 - accuracy: 0.77780.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
14/70 [=====>........................] - ETA: 10s - loss: 0.4895 - accuracy: 0.81750.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
26/70 [==========>...................] - ETA: 7s - loss: 0.4678 - accuracy: 0.8340 0.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
37/70 [==============>...............] - ETA: 5s - loss: 0.4573 - accuracy: 0.8407 0.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
48/70 [===================>..........] - ETA: 3s - loss: 0.4572 - accuracy: 0.8399 0.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
59/70 [========================>.....] - ETA: 1s - loss: 0.4595 - accuracy: 0.8387 0.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
70/70 [==============================] - ETA: 0s - loss: 0.4616 - accuracy: 0.8370 0.8293 - val_loss: 0.4601 - val_accuracy: 0.8258
 6/70 [=>............................] - ETA: 12s - loss: 0.3377 - accuracy: 0.89690.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
17/70 [======>.......................] - ETA: 9s - loss: 0.3630 - accuracy: 0.8841 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
28/70 [===========>..................] - ETA: 7s - loss: 0.3808 - accuracy: 0.8737 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
39/70 [===============>..............] - ETA: 5s - loss: 0.3933 - accuracy: 0.8672 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
50/70 [====================>.........] - ETA: 3s - loss: 0.4015 - accuracy: 0.8623 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
61/70 [=========================>....] - ETA: 1s - loss: 0.4063 - accuracy: 0.8594 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
70/70 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8572 0.8368 - val_loss: 0.4650 - val_accuracy: 0.8030
 8/70 [==>...........................] - ETA: 11s - loss: 0.4990 - accuracy: 0.83710.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
19/70 [=======>......................] - ETA: 9s - loss: 0.4625 - accuracy: 0.8467 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
30/70 [===========>..................] - ETA: 7s - loss: 0.4448 - accuracy: 0.8498 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
42/70 [=================>............] - ETA: 5s - loss: 0.4365 - accuracy: 0.8497 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
53/70 [=====================>........] - ETA: 3s - loss: 0.4406 - accuracy: 0.8459 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
64/70 [==========================>...] - ETA: 1s - loss: 0.4446 - accuracy: 0.8435 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
70/70 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.8428 0.8570 - val_loss: 0.4348 - val_accuracy: 0.8144
70/70 [==============================] - 16s 223ms/step - loss: 0.4460 - accuracy: 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
11/70 [===>..........................] - ETA: 10s - loss: 0.3713 - accuracy: 0.86490.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
22/70 [========>.....................] - ETA: 8s - loss: 0.4011 - accuracy: 0.8526 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
33/70 [=============>................] - ETA: 6s - loss: 0.4016 - accuracy: 0.8547 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
44/70 [=================>............] - ETA: 4s - loss: 0.4011 - accuracy: 0.8561 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
56/70 [=======================>......] - ETA: 2s - loss: 0.4019 - accuracy: 0.8559 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
67/70 [===========================>..] - ETA: 0s - loss: 0.4036 - accuracy: 0.8551 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
70/70 [==============================] - ETA: 0s - loss: 0.4044 - accuracy: 0.8546 0.8428 - val_loss: 0.4671 - val_accuracy: 0.7803
 1/70 [..............................] - ETA: 16s - loss: 0.4217 - accuracy: 0.87500.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
12/70 [====>.........................] - ETA: 10s - loss: 0.4635 - accuracy: 0.84090.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
23/70 [========>.....................] - ETA: 8s - loss: 0.4829 - accuracy: 0.8297 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
34/70 [=============>................] - ETA: 6s - loss: 0.4817 - accuracy: 0.8274 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
45/70 [==================>...........] - ETA: 4s - loss: 0.4804 - accuracy: 0.8259 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
56/70 [=======================>......] - ETA: 2s - loss: 0.4780 - accuracy: 0.8254 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
68/70 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.8248 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
70/70 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8248 0.8544 - val_loss: 0.6157 - val_accuracy: 0.7500
 4/70 [>.............................] - ETA: 12s - loss: 0.4706 - accuracy: 0.79170.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
15/70 [=====>........................] - ETA: 9s - loss: 0.4557 - accuracy: 0.8237 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
26/70 [==========>...................] - ETA: 8s - loss: 0.4391 - accuracy: 0.8340 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
37/70 [==============>...............] - ETA: 6s - loss: 0.4250 - accuracy: 0.8401 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
48/70 [===================>..........] - ETA: 4s - loss: 0.4136 - accuracy: 0.8453 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
59/70 [========================>.....] - ETA: 2s - loss: 0.4074 - accuracy: 0.8476 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
70/70 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8485 0.8247 - val_loss: 0.6451 - val_accuracy: 0.7235
 5/70 [=>............................] - ETA: 12s - loss: 0.4186 - accuracy: 0.82480.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
16/70 [=====>........................] - ETA: 10s - loss: 0.3956 - accuracy: 0.83190.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
27/70 [==========>...................] - ETA: 7s - loss: 0.3874 - accuracy: 0.8409 0.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
39/70 [===============>..............] - ETA: 5s - loss: 0.3889 - accuracy: 0.8401 0.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
50/70 [====================>.........] - ETA: 3s - loss: 0.3875 - accuracy: 0.8409 0.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
61/70 [=========================>....] - ETA: 1s - loss: 0.3870 - accuracy: 0.8423 0.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
70/70 [==============================] - ETA: 0s - loss: 0.3856 - accuracy: 0.8436 0.8486 - val_loss: 0.4142 - val_accuracy: 0.8295
 8/70 [==>...........................] - ETA: 11s - loss: 0.4191 - accuracy: 0.79400.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
19/70 [=======>......................] - ETA: 9s - loss: 0.4008 - accuracy: 0.8138 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
31/70 [============>.................] - ETA: 7s - loss: 0.4073 - accuracy: 0.8216 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
42/70 [=================>............] - ETA: 5s - loss: 0.4112 - accuracy: 0.8283 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
53/70 [=====================>........] - ETA: 3s - loss: 0.4082 - accuracy: 0.8345 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
64/70 [==========================>...] - ETA: 1s - loss: 0.4051 - accuracy: 0.8385 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
70/70 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.8401 0.8437 - val_loss: 0.6170 - val_accuracy: 0.7386
70/70 [==============================] - 16s 223ms/step - loss: 0.4031 - accuracy: 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
11/70 [===>..........................] - ETA: 11s - loss: 0.3431 - accuracy: 0.84630.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
22/70 [========>.....................] - ETA: 8s - loss: 0.3428 - accuracy: 0.8515 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
33/70 [=============>................] - ETA: 6s - loss: 0.3493 - accuracy: 0.8528 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
45/70 [==================>...........] - ETA: 4s - loss: 0.3543 - accuracy: 0.8542 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
56/70 [=======================>......] - ETA: 2s - loss: 0.3585 - accuracy: 0.8541 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
67/70 [===========================>..] - ETA: 0s - loss: 0.3613 - accuracy: 0.8543 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
70/70 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.8544 0.8404 - val_loss: 0.4484 - val_accuracy: 0.8220
 3/70 [>.............................] - ETA: 12s - loss: 0.2499 - accuracy: 0.93060.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
14/70 [=====>........................] - ETA: 10s - loss: 0.3580 - accuracy: 0.87170.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
25/70 [=========>....................] - ETA: 8s - loss: 0.3599 - accuracy: 0.8710 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
36/70 [==============>...............] - ETA: 6s - loss: 0.3631 - accuracy: 0.8692 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
46/70 [==================>...........] - ETA: 4s - loss: 0.3660 - accuracy: 0.8659 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
58/70 [=======================>......] - ETA: 2s - loss: 0.3666 - accuracy: 0.8643 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
69/70 [============================>.] - ETA: 0s - loss: 0.3678 - accuracy: 0.8635 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
70/70 [==============================] - ETA: 0s - loss: 0.3679 - accuracy: 0.8635 0.8544 - val_loss: 0.4647 - val_accuracy: 0.7992
 4/70 [>.............................] - ETA: 12s - loss: 0.2537 - accuracy: 0.94400.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
15/70 [=====>........................] - ETA: 10s - loss: 0.3371 - accuracy: 0.88890.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
27/70 [==========>...................] - ETA: 7s - loss: 0.3505 - accuracy: 0.8798 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
38/70 [===============>..............] - ETA: 5s - loss: 0.3542 - accuracy: 0.8769 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
49/70 [====================>.........] - ETA: 3s - loss: 0.3531 - accuracy: 0.8760 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
60/70 [========================>.....] - ETA: 1s - loss: 0.3529 - accuracy: 0.8748 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
69/70 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.8743 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
70/70 [==============================] - ETA: 0s - loss: 0.3530 - accuracy: 0.8742 0.8634 - val_loss: 0.4630 - val_accuracy: 0.8106
 5/70 [=>............................] - ETA: 11s - loss: 0.4921 - accuracy: 0.76710.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
17/70 [======>.......................] - ETA: 9s - loss: 0.4412 - accuracy: 0.8077 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
28/70 [===========>..................] - ETA: 7s - loss: 0.4276 - accuracy: 0.8225 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
39/70 [===============>..............] - ETA: 5s - loss: 0.4125 - accuracy: 0.8341 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
50/70 [====================>.........] - ETA: 3s - loss: 0.4022 - accuracy: 0.8412 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
61/70 [=========================>....] - ETA: 1s - loss: 0.3946 - accuracy: 0.8460 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
70/70 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.8493 0.8741 - val_loss: 0.6602 - val_accuracy: 0.7311
 8/70 [==>...........................] - ETA: 11s - loss: 0.3596 - accuracy: 0.83330.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
19/70 [=======>......................] - ETA: 9s - loss: 0.3211 - accuracy: 0.8645 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
31/70 [============>.................] - ETA: 7s - loss: 0.3152 - accuracy: 0.8699 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
42/70 [=================>............] - ETA: 5s - loss: 0.3191 - accuracy: 0.8687 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
53/70 [=====================>........] - ETA: 3s - loss: 0.3229 - accuracy: 0.8672 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
64/70 [==========================>...] - ETA: 1s - loss: 0.3257 - accuracy: 0.8663 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
70/70 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.8659 0.8496 - val_loss: 0.4653 - val_accuracy: 0.7992
 1/70 [..............................] - ETA: 17s - loss: 0.2637 - accuracy: 0.87500.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
12/70 [====>.........................] - ETA: 10s - loss: 0.3209 - accuracy: 0.87790.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
23/70 [========>.....................] - ETA: 8s - loss: 0.3123 - accuracy: 0.8867 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
34/70 [=============>................] - ETA: 6s - loss: 0.3099 - accuracy: 0.8864 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
45/70 [==================>...........] - ETA: 4s - loss: 0.3117 - accuracy: 0.8853 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
56/70 [=======================>......] - ETA: 2s - loss: 0.3145 - accuracy: 0.8842 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
67/70 [===========================>..] - ETA: 0s - loss: 0.3180 - accuracy: 0.8828 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
70/70 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8824 0.8659 - val_loss: 0.5216 - val_accuracy: 0.7879
 3/70 [>.............................] - ETA: 11s - loss: 0.4034 - accuracy: 0.89930.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
14/70 [=====>........................] - ETA: 10s - loss: 0.4110 - accuracy: 0.86200.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
26/70 [==========>...................] - ETA: 7s - loss: 0.3753 - accuracy: 0.8710 0.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
37/70 [==============>...............] - ETA: 5s - loss: 0.3661 - accuracy: 0.8725 0.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
48/70 [===================>..........] - ETA: 3s - loss: 0.3677 - accuracy: 0.8714 0.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
59/70 [========================>.....] - ETA: 1s - loss: 0.3679 - accuracy: 0.8715 0.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
70/70 [==============================] - ETA: 0s - loss: 0.3681 - accuracy: 0.8714 0.8822 - val_loss: 0.5869 - val_accuracy: 0.7424
 6/14 [===========>..................] - ETA: 1s - loss: 0.6131 - accuracy: 0.8333 0.8714 - val_loss: 0.4419 - val_accuracy: 0.8068
13/14 [==========================>...] - ETA: 0s - loss: 0.6174 - accuracy: 0.8173 0.8714 - val_loss: 0.4419 - val_accuracy: 0.8068
14/14 [==============================] - 4s 307ms/step - loss: 0.5853 - accuracy: 0.82734 - val_loss: 0.4419 - val_accuracy: 0.8068
14/14 [==============================] - 4s 307ms/step - loss: 0.5853 - accuracy: 0.82734 - val_loss: 0.4419 - val_accuracy: 0.8068