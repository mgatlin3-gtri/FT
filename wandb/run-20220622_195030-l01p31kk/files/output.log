2022-06-22 19:50:34.596228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 19:50:34.597195: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-06-22 19:50:34.629952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 19:50:34.630314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 19:50:34.630334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 19:50:34.632636: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 19:50:34.632692: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 19:50:34.634842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 19:50:34.635344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 19:50:34.637557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 19:50:34.638780: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 19:50:34.642979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 19:50:34.644063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 19:50:34.644420: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-22 19:50:34.644500: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-06-22 19:50:34.820107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:5e:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 19:50:34.820361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:86:00.0 name: NVIDIA GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2022-06-22 19:50:34.820385: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 19:50:34.820411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 19:50:34.820425: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-06-22 19:50:34.820436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-06-22 19:50:34.820449: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-06-22 19:50:34.820460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-06-22 19:50:34.820471: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-06-22 19:50:34.820482: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 19:50:34.821210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2022-06-22 19:50:34.821240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-06-22 19:50:35.566471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-22 19:50:35.566513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2022-06-22 19:50:35.566527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N Y
2022-06-22 19:50:35.566531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   Y N
2022-06-22 19:50:35.567595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10245 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:5e:00.0, compute capability: 6.1)
2022-06-22 19:50:35.568273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10255 MB memory) -> physical GPU (device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:86:00.0, compute capability: 6.1)
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-06-22 19:50:35.797013: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-06-22 19:50:35.797469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2600000000 Hz
2022-06-22 19:50:36.346013: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-06-22 19:50:36.549863: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-06-22 19:50:37.118858: W tensorflow/stream_executor/gpu/asm_compiler.cc:63] Running ptxas --version returned 256
2022-06-22 19:50:37.151529: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output:
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.
Found 1120 images belonging to 4 classes.
Found 264 images belonging to 4 classes.
Found 220 images belonging to 4 classes.
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d (Conv2D)              (None, 478, 638, 128)     3584
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 239, 319, 128)     0
_________________________________________________________________
dropout (Dropout)            (None, 239, 319, 128)     0
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 237, 317, 16)      18448
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 118, 158, 16)      0
_________________________________________________________________
dropout_1 (Dropout)          (None, 118, 158, 16)      0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 116, 156, 64)      9280
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 58, 78, 64)        0
_________________________________________________________________
dropout_2 (Dropout)          (None, 58, 78, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 56, 76, 64)        36928
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 28, 38, 64)        0
_________________________________________________________________
dropout_3 (Dropout)          (None, 28, 38, 64)        0
_________________________________________________________________
global_average_pooling2d (Gl (None, 64)                0
_________________________________________________________________
dropout_4 (Dropout)          (None, 64)                0
_________________________________________________________________
dense (Dense)                (None, 4)                 260
=================================================================
Total params: 68,500
Trainable params: 68,500
Non-trainable params: 0
_________________________________________________________________
Epoch 1/100
 15/280 [>.............................] - ETA: 14s - loss: 1.4127 - accuracy: 0.3157







280/280 [==============================] - 23s 64ms/step - loss: 1.3880 - accuracy: 0.2729 - val_loss: 1.2697 - val_accuracy: 0.2727
Epoch 2/100








280/280 [==============================] - 17s 62ms/step - loss: 1.3102 - accuracy: 0.3093 - val_loss: 1.1305 - val_accuracy: 0.4697
Epoch 3/100







280/280 [==============================] - 17s 62ms/step - loss: 1.1998 - accuracy: 0.4218 - val_loss: 1.0528 - val_accuracy: 0.5152
Epoch 4/100








280/280 [==============================] - 17s 61ms/step - loss: 1.1124 - accuracy: 0.5194 - val_loss: 1.0127 - val_accuracy: 0.5189
Epoch 5/100








280/280 [==============================] - 17s 60ms/step - loss: 0.9756 - accuracy: 0.6050 - val_loss: 0.8735 - val_accuracy: 0.7045
Epoch 6/100







280/280 [==============================] - 17s 60ms/step - loss: 0.9366 - accuracy: 0.6366 - val_loss: 0.8480 - val_accuracy: 0.6705
Epoch 7/100








280/280 [==============================] - 17s 62ms/step - loss: 0.8346 - accuracy: 0.6741 - val_loss: 0.8969 - val_accuracy: 0.6667
Epoch 8/100







280/280 [==============================] - 17s 61ms/step - loss: 0.8048 - accuracy: 0.6889 - val_loss: 0.7759 - val_accuracy: 0.6856
Epoch 9/100








280/280 [==============================] - 17s 61ms/step - loss: 0.7674 - accuracy: 0.6843 - val_loss: 0.6979 - val_accuracy: 0.7083
Epoch 10/100







280/280 [==============================] - 17s 62ms/step - loss: 0.6867 - accuracy: 0.7459 - val_loss: 0.6525 - val_accuracy: 0.7197
Epoch 11/100








280/280 [==============================] - 18s 63ms/step - loss: 0.6279 - accuracy: 0.7805 - val_loss: 0.8281 - val_accuracy: 0.7083
Epoch 12/100








280/280 [==============================] - 18s 64ms/step - loss: 0.6904 - accuracy: 0.7533 - val_loss: 0.5999 - val_accuracy: 0.7386
Epoch 13/100








280/280 [==============================] - 18s 62ms/step - loss: 0.6460 - accuracy: 0.7519 - val_loss: 0.5425 - val_accuracy: 0.7727
Epoch 14/100








280/280 [==============================] - 18s 63ms/step - loss: 0.6330 - accuracy: 0.7647 - val_loss: 0.5420 - val_accuracy: 0.7614
Epoch 15/100







280/280 [==============================] - 18s 63ms/step - loss: 0.5682 - accuracy: 0.7980 - val_loss: 0.5620 - val_accuracy: 0.7538
Epoch 16/100








280/280 [==============================] - 18s 64ms/step - loss: 0.5527 - accuracy: 0.7922 - val_loss: 0.5179 - val_accuracy: 0.7689
Epoch 17/100







280/280 [==============================] - 18s 63ms/step - loss: 0.5811 - accuracy: 0.7834 - val_loss: 0.4816 - val_accuracy: 0.8068
Epoch 18/100








280/280 [==============================] - 17s 62ms/step - loss: 0.5300 - accuracy: 0.7860 - val_loss: 0.4660 - val_accuracy: 0.8106
Epoch 19/100







280/280 [==============================] - 17s 61ms/step - loss: 0.5133 - accuracy: 0.8176 - val_loss: 0.4874 - val_accuracy: 0.8068
Epoch 20/100








280/280 [==============================] - 18s 63ms/step - loss: 0.4834 - accuracy: 0.7976 - val_loss: 0.4966 - val_accuracy: 0.7879
Epoch 21/100







280/280 [==============================] - 18s 63ms/step - loss: 0.4947 - accuracy: 0.8161 - val_loss: 0.4828 - val_accuracy: 0.8068
Epoch 22/100








280/280 [==============================] - 18s 63ms/step - loss: 0.4556 - accuracy: 0.8260 - val_loss: 0.4735 - val_accuracy: 0.8068
Epoch 23/100







280/280 [==============================] - 18s 63ms/step - loss: 0.4726 - accuracy: 0.8252 - val_loss: 0.5189 - val_accuracy: 0.7803
Epoch 24/100







280/280 [==============================] - 18s 63ms/step - loss: 0.4090 - accuracy: 0.8450 - val_loss: 0.4446 - val_accuracy: 0.8182
Epoch 25/100







280/280 [==============================] - 18s 63ms/step - loss: 0.4359 - accuracy: 0.8512 - val_loss: 0.4715 - val_accuracy: 0.8220
Epoch 26/100







280/280 [==============================] - 18s 63ms/step - loss: 0.4508 - accuracy: 0.8425 - val_loss: 0.4033 - val_accuracy: 0.8523
Epoch 27/100








280/280 [==============================] - 18s 63ms/step - loss: 0.4307 - accuracy: 0.8356 - val_loss: 0.4001 - val_accuracy: 0.8523
Epoch 28/100








280/280 [==============================] - 18s 63ms/step - loss: 0.4200 - accuracy: 0.8418 - val_loss: 0.3902 - val_accuracy: 0.8636
Epoch 29/100







280/280 [==============================] - 17s 62ms/step - loss: 0.3911 - accuracy: 0.8587 - val_loss: 0.5880 - val_accuracy: 0.7614
Epoch 30/100
 66/280 [======>.......................] - ETA: 11s - loss: 0.4327 - accuracy: 0.8562
105/280 [==========>...................] - ETA: 9s - loss: 0.4224 - accuracy: 0.8584
143/280 [==============>...............] - ETA: 7s - loss: 0.4204 - accuracy: 0.8542
181/280 [==================>...........] - ETA: 5s - loss: 0.4186 - accuracy: 0.8511
220/280 [======================>.......] - ETA: 3s - loss: 0.4167 - accuracy: 0.8497
258/280 [==========================>...] - ETA: 1s - loss: 0.4148 - accuracy: 0.8495
279/280 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.8492
 35/280 [==>...........................] - ETA: 13s - loss: 0.5253 - accuracy: 0.7790.8491 - val_loss: 0.5245 - val_accuracy: 0.7841
 74/280 [======>.......................] - ETA: 11s - loss: 0.4899 - accuracy: 0.8000.8491 - val_loss: 0.5245 - val_accuracy: 0.7841
112/280 [===========>..................] - ETA: 8s - loss: 0.4618 - accuracy: 0.8142 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
150/280 [===============>..............] - ETA: 6s - loss: 0.4410 - accuracy: 0.8240 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
188/280 [===================>..........] - ETA: 4s - loss: 0.4268 - accuracy: 0.8308 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
226/280 [=======================>......] - ETA: 2s - loss: 0.4206 - accuracy: 0.8341 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
265/280 [===========================>..] - ETA: 0s - loss: 0.4165 - accuracy: 0.8364 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
280/280 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8369 .8491 - val_loss: 0.5245 - val_accuracy: 0.7841
  9/280 [..............................] - ETA: 15s - loss: 0.4609 - accuracy: 0.8116.8369 - val_loss: 0.5023 - val_accuracy: 0.7841
 46/280 [===>..........................] - ETA: 12s - loss: 0.3790 - accuracy: 0.8571.8369 - val_loss: 0.5023 - val_accuracy: 0.7841
 84/280 [========>.....................] - ETA: 10s - loss: 0.3859 - accuracy: 0.8560.8369 - val_loss: 0.5023 - val_accuracy: 0.7841
121/280 [===========>..................] - ETA: 8s - loss: 0.3925 - accuracy: 0.8562 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
159/280 [================>.............] - ETA: 6s - loss: 0.3890 - accuracy: 0.8580 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
196/280 [====================>.........] - ETA: 4s - loss: 0.3885 - accuracy: 0.8572 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
235/280 [========================>.....] - ETA: 2s - loss: 0.3889 - accuracy: 0.8557 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
273/280 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8547 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
279/280 [============================>.] - ETA: 0s - loss: 0.3889 - accuracy: 0.8546 .8369 - val_loss: 0.5023 - val_accuracy: 0.7841
 18/280 [>.............................] - ETA: 14s - loss: 0.2465 - accuracy: 0.9007.8545 - val_loss: 0.4124 - val_accuracy: 0.8561
 57/280 [=====>........................] - ETA: 12s - loss: 0.3043 - accuracy: 0.8729.8545 - val_loss: 0.4124 - val_accuracy: 0.8561
 95/280 [=========>....................] - ETA: 9s - loss: 0.3225 - accuracy: 0.8684 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
133/280 [=============>................] - ETA: 7s - loss: 0.3362 - accuracy: 0.8635 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
161/280 [================>.............] - ETA: 6s - loss: 0.3446 - accuracy: 0.8607 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
199/280 [====================>.........] - ETA: 4s - loss: 0.3562 - accuracy: 0.8567 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
237/280 [========================>.....] - ETA: 2s - loss: 0.3651 - accuracy: 0.8538 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
274/280 [============================>.] - ETA: 0s - loss: 0.3726 - accuracy: 0.8520 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.8518 .8545 - val_loss: 0.4124 - val_accuracy: 0.8561
 20/280 [=>............................] - ETA: 13s - loss: 0.3028 - accuracy: 0.8747.8518 - val_loss: 0.4643 - val_accuracy: 0.8371
 59/280 [=====>........................] - ETA: 11s - loss: 0.3423 - accuracy: 0.8615.8518 - val_loss: 0.4643 - val_accuracy: 0.8371
 97/280 [=========>....................] - ETA: 9s - loss: 0.3779 - accuracy: 0.8504 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
135/280 [=============>................] - ETA: 7s - loss: 0.3830 - accuracy: 0.8501 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
173/280 [=================>............] - ETA: 5s - loss: 0.3857 - accuracy: 0.8494 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
212/280 [=====================>........] - ETA: 3s - loss: 0.3859 - accuracy: 0.8501 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
250/280 [=========================>....] - ETA: 1s - loss: 0.3838 - accuracy: 0.8521 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
279/280 [============================>.] - ETA: 0s - loss: 0.3818 - accuracy: 0.8535 .8518 - val_loss: 0.4643 - val_accuracy: 0.8371
 33/280 [==>...........................] - ETA: 13s - loss: 0.5782 - accuracy: 0.8256.8536 - val_loss: 0.7114 - val_accuracy: 0.7841
 71/280 [======>.......................] - ETA: 11s - loss: 0.4894 - accuracy: 0.8469.8536 - val_loss: 0.7114 - val_accuracy: 0.7841
108/280 [==========>...................] - ETA: 9s - loss: 0.4423 - accuracy: 0.8573 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
145/280 [==============>...............] - ETA: 7s - loss: 0.4124 - accuracy: 0.8657 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
183/280 [==================>...........] - ETA: 5s - loss: 0.4010 - accuracy: 0.8680 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
221/280 [======================>.......] - ETA: 3s - loss: 0.3967 - accuracy: 0.8676 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
259/280 [==========================>...] - ETA: 1s - loss: 0.3915 - accuracy: 0.8680 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
279/280 [============================>.] - ETA: 0s - loss: 0.3895 - accuracy: 0.8682 .8536 - val_loss: 0.7114 - val_accuracy: 0.7841
  8/280 [..............................] - ETA: 14s - loss: 0.2640 - accuracy: 0.8397.8682 - val_loss: 0.4207 - val_accuracy: 0.8485
 47/280 [====>.........................] - ETA: 12s - loss: 0.3622 - accuracy: 0.8490.8682 - val_loss: 0.4207 - val_accuracy: 0.8485
 86/280 [========>.....................] - ETA: 10s - loss: 0.3334 - accuracy: 0.8673.8682 - val_loss: 0.4207 - val_accuracy: 0.8485
115/280 [===========>..................] - ETA: 8s - loss: 0.3276 - accuracy: 0.8719 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
154/280 [===============>..............] - ETA: 6s - loss: 0.3265 - accuracy: 0.8742 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
193/280 [===================>..........] - ETA: 4s - loss: 0.3261 - accuracy: 0.8747 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
231/280 [=======================>......] - ETA: 2s - loss: 0.3288 - accuracy: 0.8739 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
270/280 [===========================>..] - ETA: 0s - loss: 0.3309 - accuracy: 0.8734 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
280/280 [==============================] - ETA: 0s - loss: 0.3317 - accuracy: 0.8732 .8682 - val_loss: 0.4207 - val_accuracy: 0.8485
 15/280 [>.............................] - ETA: 14s - loss: 0.2125 - accuracy: 0.9650.8732 - val_loss: 0.4326 - val_accuracy: 0.8333
 52/280 [====>.........................] - ETA: 12s - loss: 0.2643 - accuracy: 0.9297.8732 - val_loss: 0.4326 - val_accuracy: 0.8333
 90/280 [========>.....................] - ETA: 10s - loss: 0.2917 - accuracy: 0.9084.8732 - val_loss: 0.4326 - val_accuracy: 0.8333
129/280 [============>.................] - ETA: 8s - loss: 0.3085 - accuracy: 0.8965 .8732 - val_loss: 0.4326 - val_accuracy: 0.8333
167/280 [================>.............] - ETA: 6s - loss: 0.3210 - accuracy: 0.8880 .8732 - val_loss: 0.4326 - val_accuracy: 0.8333
206/280 [=====================>........] - ETA: 3s - loss: 0.3286 - accuracy: 0.8827 .8732 - val_loss: 0.4326 - val_accuracy: 0.8333
244/280 [=========================>....] - ETA: 1s - loss: 0.3341 - accuracy: 0.8795 .8732 - val_loss: 0.4326 - val_accuracy: 0.8333
279/280 [============================>.] - ETA: 0s - loss: 0.3383 - accuracy: 0.8769 .8732 - val_loss: 0.4326 - val_accuracy: 0.8333
 30/280 [==>...........................] - ETA: 13s - loss: 0.4005 - accuracy: 0.8562.8768 - val_loss: 0.4368 - val_accuracy: 0.8485
 69/280 [======>.......................] - ETA: 11s - loss: 0.3778 - accuracy: 0.8607.8768 - val_loss: 0.4368 - val_accuracy: 0.8485
108/280 [==========>...................] - ETA: 9s - loss: 0.3578 - accuracy: 0.8659 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
146/280 [==============>...............] - ETA: 7s - loss: 0.3508 - accuracy: 0.8662 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
184/280 [==================>...........] - ETA: 5s - loss: 0.3516 - accuracy: 0.8648 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
222/280 [======================>.......] - ETA: 3s - loss: 0.3547 - accuracy: 0.8624 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
261/280 [==========================>...] - ETA: 1s - loss: 0.3564 - accuracy: 0.8609 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.3569 - accuracy: 0.8607 .8768 - val_loss: 0.4368 - val_accuracy: 0.8485
 11/280 [>.............................] - ETA: 14s - loss: 0.2324 - accuracy: 0.9271    6 - val_loss: 0.4487 - val_accuracy: 0.8409
 48/280 [====>.........................] - ETA: 12s - loss: 0.2806 - accuracy: 0.9003    6 - val_loss: 0.4487 - val_accuracy: 0.8409
 88/280 [========>.....................] - ETA: 10s - loss: 0.3203 - accuracy: 0.8837    6 - val_loss: 0.4487 - val_accuracy: 0.8409
116/280 [===========>..................] - ETA: 8s - loss: 0.3272 - accuracy: 0.8791     6 - val_loss: 0.4487 - val_accuracy: 0.8409
155/280 [===============>..............] - ETA: 6s - loss: 0.3334 - accuracy: 0.8762     6 - val_loss: 0.4487 - val_accuracy: 0.8409
193/280 [===================>..........] - ETA: 4s - loss: 0.3388 - accuracy: 0.8737     6 - val_loss: 0.4487 - val_accuracy: 0.8409
231/280 [=======================>......] - ETA: 2s - loss: 0.3422 - accuracy: 0.8723     6 - val_loss: 0.4487 - val_accuracy: 0.8409
269/280 [===========================>..] - ETA: 0s - loss: 0.3425 - accuracy: 0.8719     6 - val_loss: 0.4487 - val_accuracy: 0.8409
279/280 [============================>.] - ETA: 0s - loss: 0.3422 - accuracy: 0.8720     6 - val_loss: 0.4487 - val_accuracy: 0.8409
 16/280 [>.............................] - ETA: 13s - loss: 0.3927 - accuracy: 0.8324.8720 - val_loss: 0.4324 - val_accuracy: 0.8485
 54/280 [====>.........................] - ETA: 12s - loss: 0.3962 - accuracy: 0.8371.8720 - val_loss: 0.4324 - val_accuracy: 0.8485
 90/280 [========>.....................] - ETA: 10s - loss: 0.3900 - accuracy: 0.8484.8720 - val_loss: 0.4324 - val_accuracy: 0.8485
128/280 [============>.................] - ETA: 8s - loss: 0.3826 - accuracy: 0.8543 .8720 - val_loss: 0.4324 - val_accuracy: 0.8485
165/280 [================>.............] - ETA: 6s - loss: 0.3800 - accuracy: 0.8562 .8720 - val_loss: 0.4324 - val_accuracy: 0.8485
203/280 [====================>.........] - ETA: 4s - loss: 0.3781 - accuracy: 0.8580 .8720 - val_loss: 0.4324 - val_accuracy: 0.8485
241/280 [========================>.....] - ETA: 2s - loss: 0.3749 - accuracy: 0.8603 .8720 - val_loss: 0.4324 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.3721 - accuracy: 0.8620 .8720 - val_loss: 0.4324 - val_accuracy: 0.8485
 26/280 [=>............................] - ETA: 13s - loss: 0.2637 - accuracy: 0.9420.8620 - val_loss: 0.4316 - val_accuracy: 0.8371
 64/280 [=====>........................] - ETA: 11s - loss: 0.2941 - accuracy: 0.9096.8620 - val_loss: 0.4316 - val_accuracy: 0.8371
102/280 [=========>....................] - ETA: 9s - loss: 0.3131 - accuracy: 0.8963 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
140/280 [==============>...............] - ETA: 7s - loss: 0.3246 - accuracy: 0.8924 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
178/280 [==================>...........] - ETA: 5s - loss: 0.3328 - accuracy: 0.8888 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
216/280 [======================>.......] - ETA: 3s - loss: 0.3348 - accuracy: 0.8875 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
246/280 [=========================>....] - ETA: 1s - loss: 0.3353 - accuracy: 0.8863 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
279/280 [============================>.] - ETA: 0s - loss: 0.3347 - accuracy: 0.8857 .8620 - val_loss: 0.4316 - val_accuracy: 0.8371
 27/280 [=>............................] - ETA: 13s - loss: 0.2400 - accuracy: 0.8825.8857 - val_loss: 0.4284 - val_accuracy: 0.8674
 64/280 [=====>........................] - ETA: 11s - loss: 0.2658 - accuracy: 0.8886.8857 - val_loss: 0.4284 - val_accuracy: 0.8674
102/280 [=========>....................] - ETA: 9s - loss: 0.2827 - accuracy: 0.8880 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
140/280 [==============>...............] - ETA: 7s - loss: 0.2909 - accuracy: 0.8868 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
178/280 [==================>...........] - ETA: 5s - loss: 0.2977 - accuracy: 0.8851 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
217/280 [======================>.......] - ETA: 3s - loss: 0.3050 - accuracy: 0.8829 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
255/280 [==========================>...] - ETA: 1s - loss: 0.3090 - accuracy: 0.8820 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
279/280 [============================>.] - ETA: 0s - loss: 0.3106 - accuracy: 0.8816 .8857 - val_loss: 0.4284 - val_accuracy: 0.8674
  1/280 [..............................] - ETA: 26s - loss: 0.0898 - accuracy: 1.0000.8815 - val_loss: 0.4458 - val_accuracy: 0.8258
 39/280 [===>..........................] - ETA: 12s - loss: 0.2221 - accuracy: 0.9240.8815 - val_loss: 0.4458 - val_accuracy: 0.8258
 77/280 [=======>......................] - ETA: 10s - loss: 0.2395 - accuracy: 0.9128.8815 - val_loss: 0.4458 - val_accuracy: 0.8258
115/280 [===========>..................] - ETA: 8s - loss: 0.2551 - accuracy: 0.9058 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
152/280 [===============>..............] - ETA: 6s - loss: 0.2668 - accuracy: 0.9016 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
189/280 [===================>..........] - ETA: 4s - loss: 0.2739 - accuracy: 0.8994 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
227/280 [=======================>......] - ETA: 2s - loss: 0.2791 - accuracy: 0.8977 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
265/280 [===========================>..] - ETA: 0s - loss: 0.2842 - accuracy: 0.8967 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
279/280 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.8964 .8815 - val_loss: 0.4458 - val_accuracy: 0.8258
 12/280 [>.............................] - ETA: 14s - loss: 0.2764 - accuracy: 0.8812.8963 - val_loss: 0.4315 - val_accuracy: 0.8485
 50/280 [====>.........................] - ETA: 12s - loss: 0.2455 - accuracy: 0.9064.8963 - val_loss: 0.4315 - val_accuracy: 0.8485
 88/280 [========>.....................] - ETA: 10s - loss: 0.2697 - accuracy: 0.8998.8963 - val_loss: 0.4315 - val_accuracy: 0.8485
126/280 [============>.................] - ETA: 8s - loss: 0.2785 - accuracy: 0.8991 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
164/280 [================>.............] - ETA: 6s - loss: 0.2831 - accuracy: 0.8988 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
202/280 [====================>.........] - ETA: 4s - loss: 0.2838 - accuracy: 0.8985 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
231/280 [=======================>......] - ETA: 2s - loss: 0.2855 - accuracy: 0.8974 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
269/280 [===========================>..] - ETA: 0s - loss: 0.2886 - accuracy: 0.8960 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.2892 - accuracy: 0.8957 .8963 - val_loss: 0.4315 - val_accuracy: 0.8485
 14/280 [>.............................] - ETA: 14s - loss: 0.2270 - accuracy: 0.9134.8956 - val_loss: 0.4346 - val_accuracy: 0.8561
 51/280 [====>.........................] - ETA: 12s - loss: 0.2319 - accuracy: 0.9079.8956 - val_loss: 0.4346 - val_accuracy: 0.8561
 89/280 [========>.....................] - ETA: 10s - loss: 0.2593 - accuracy: 0.8955.8956 - val_loss: 0.4346 - val_accuracy: 0.8561
128/280 [============>.................] - ETA: 8s - loss: 0.2720 - accuracy: 0.8907 .8956 - val_loss: 0.4346 - val_accuracy: 0.8561
166/280 [================>.............] - ETA: 6s - loss: 0.2831 - accuracy: 0.8882 .8956 - val_loss: 0.4346 - val_accuracy: 0.8561
204/280 [====================>.........] - ETA: 4s - loss: 0.2907 - accuracy: 0.8877 .8956 - val_loss: 0.4346 - val_accuracy: 0.8561
242/280 [========================>.....] - ETA: 2s - loss: 0.2955 - accuracy: 0.8879 .8956 - val_loss: 0.4346 - val_accuracy: 0.8561
280/280 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.8880 .8956 - val_loss: 0.4346 - val_accuracy: 0.8561
 27/280 [=>............................] - ETA: 13s - loss: 0.3118 - accuracy: 0.8515.8880 - val_loss: 0.5126 - val_accuracy: 0.8220
 65/280 [=====>........................] - ETA: 11s - loss: 0.2875 - accuracy: 0.8698.8880 - val_loss: 0.5126 - val_accuracy: 0.8220
103/280 [==========>...................] - ETA: 9s - loss: 0.2826 - accuracy: 0.8760 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
141/280 [==============>...............] - ETA: 7s - loss: 0.2877 - accuracy: 0.8765 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
179/280 [==================>...........] - ETA: 5s - loss: 0.2925 - accuracy: 0.8766 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
217/280 [======================>.......] - ETA: 3s - loss: 0.2955 - accuracy: 0.8775 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
254/280 [==========================>...] - ETA: 1s - loss: 0.2980 - accuracy: 0.8779 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
279/280 [============================>.] - ETA: 0s - loss: 0.3004 - accuracy: 0.8779 .8880 - val_loss: 0.5126 - val_accuracy: 0.8220
280/280 [==============================] - 18s 63ms/step - loss: 0.3005 - accuracy: 0.8779 - val_loss: 0.5115 - val_accuracy: 0.8447
 37/280 [==>...........................] - ETA: 13s - loss: 0.2389 - accuracy: 0.8979.8779 - val_loss: 0.5115 - val_accuracy: 0.8447
 76/280 [=======>......................] - ETA: 10s - loss: 0.2482 - accuracy: 0.9066.8779 - val_loss: 0.5115 - val_accuracy: 0.8447
105/280 [==========>...................] - ETA: 9s - loss: 0.2533 - accuracy: 0.9087 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
142/280 [==============>...............] - ETA: 7s - loss: 0.2611 - accuracy: 0.9096 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
181/280 [==================>...........] - ETA: 5s - loss: 0.2729 - accuracy: 0.9067 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
219/280 [======================>.......] - ETA: 3s - loss: 0.2804 - accuracy: 0.9052 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
257/280 [==========================>...] - ETA: 1s - loss: 0.2842 - accuracy: 0.9048 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
279/280 [============================>.] - ETA: 0s - loss: 0.2854 - accuracy: 0.9048 .8779 - val_loss: 0.5115 - val_accuracy: 0.8447
  4/280 [..............................] - ETA: 14s - loss: 0.1879 - accuracy: 1.0000.9047 - val_loss: 0.4665 - val_accuracy: 0.8485
 42/280 [===>..........................] - ETA: 12s - loss: 0.2544 - accuracy: 0.9122.9047 - val_loss: 0.4665 - val_accuracy: 0.8485
 79/280 [=======>......................] - ETA: 10s - loss: 0.2353 - accuracy: 0.9169.9047 - val_loss: 0.4665 - val_accuracy: 0.8485
117/280 [===========>..................] - ETA: 8s - loss: 0.2395 - accuracy: 0.9142 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
154/280 [===============>..............] - ETA: 6s - loss: 0.2447 - accuracy: 0.9132 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
192/280 [===================>..........] - ETA: 4s - loss: 0.2502 - accuracy: 0.9117 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
230/280 [=======================>......] - ETA: 2s - loss: 0.2573 - accuracy: 0.9093 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
268/280 [===========================>..] - ETA: 0s - loss: 0.2631 - accuracy: 0.9068 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
279/280 [============================>.] - ETA: 0s - loss: 0.2647 - accuracy: 0.9061 .9047 - val_loss: 0.4665 - val_accuracy: 0.8485
16/55 [=======>......................] - ETA: 1s - loss: 0.8410 - accuracy: 0.7656: 0.9060 - val_loss: 0.5434 - val_accuracy: 0.8106
55/55 [==============================] - 2s 39ms/step - loss: 0.8063 - accuracy: 0.7455060 - val_loss: 0.5434 - val_accuracy: 0.8106
55/55 [==============================] - 2s 39ms/step - loss: 0.8063 - accuracy: 0.7455060 - val_loss: 0.5434 - val_accuracy: 0.8106
55/55 [==============================] - 2s 39ms/step - loss: 0.8063 - accuracy: 0.7455060 - val_loss: 0.5434 - val_accuracy: 0.8106